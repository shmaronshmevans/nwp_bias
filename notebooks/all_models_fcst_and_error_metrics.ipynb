{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59afe6a7-273b-4196-bc50-e16e57cad1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a828a57-3f27-41e9-ae70-46e48e666a11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_nysm_data(year):\n",
    "    path_to_data = \"/home/aevans/nwp_bias/data/nysm/\"\n",
    "    nysm_1H_obs = pd.read_parquet(f\"{path_to_data}nysm_1H_obs_{year}.parquet\")\n",
    "    nysm_3H_obs = pd.read_parquet(f\"{path_to_data}nysm_3H_obs_{year}.parquet\")\n",
    "    return nysm_1H_obs, nysm_3H_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eafbb1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_oksm_data(year):\n",
    "    path_to_data = \"/home/aevans/nwp_bias/data/oksm/\"\n",
    "    oksm_1H_obs = pd.read_parquet(f\"{path_to_data}oksm_1H_obs_{year}.parquet\")\n",
    "    oksm_3H_obs = pd.read_parquet(f\"{path_to_data}oksm_3H_obs_{year}.parquet\")\n",
    "    return oksm_1H_obs, oksm_3H_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40bdabee-2148-46e0-9c04-9ed044f81a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errors(model_data, nysm_obs, model, obs):\n",
    "    model_error = model_data[model] - nysm_obs[obs]\n",
    "    model_error = model_error.to_frame().rename(columns={0: f\"{model}_error\"})\n",
    "    return model_error\n",
    "\n",
    "\n",
    "def get_rmse(model_data, nysm_obs, model, obs):\n",
    "    rmse = ((model_data[model] - nysm_obs[obs]) ** 2).mean() ** 0.5\n",
    "    model_data[f\"{model}_rmse\"] = rmse\n",
    "    return model_data[f\"{model}_rmse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b1501c8-f294-49f9-b395-aaf373b90836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fcast_and_error_metrics_df(model, model_data, nysm_obs):\n",
    "    if model == \"HRRR\":\n",
    "        pres = \"mslma\"\n",
    "    else:\n",
    "        pres = \"prmsl\"\n",
    "\n",
    "    model_data = model_data.copy()\n",
    "    if pres in model_data.keys():\n",
    "        model_data.loc[:, pres] = model_data[pres].div(100.0)  # convert Pa to hPa\n",
    "    model_data_subset = model_data.reset_index().set_index(\n",
    "        [\"station\", \"valid_time\", \"time\"]\n",
    "    )[\n",
    "        [\n",
    "            \"t2m\",\n",
    "            \"d2m\",\n",
    "            \"u_total\",\n",
    "            \"u_dir\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "            \"new_tp\",\n",
    "            pres,\n",
    "            \"orog\",\n",
    "        ]\n",
    "    ]\n",
    "    model_data_subset = model_data_subset.sort_values(\n",
    "        by=[\"station\", \"valid_time\", \"time\"]\n",
    "    )\n",
    "    nysm_obs_nonan = nysm_obs.dropna(\n",
    "        subset=[\n",
    "            \"tair\",\n",
    "            \"td\",\n",
    "            \"relh\",\n",
    "            \"wspd_sonic\",\n",
    "            \"wmax_sonic\",\n",
    "            \"wdir_sonic\",\n",
    "            \"precip_total\",\n",
    "            \"pres\",\n",
    "        ]\n",
    "    ).rename_axis(index={nysm_obs.index.names[1]: \"valid_time\"})\n",
    "\n",
    "    # compute the error\n",
    "    model_obs_var_pairs = {\n",
    "        \"t2m\": \"tair\",\n",
    "        \"d2m\": \"td\",\n",
    "        \"u_total\": \"wspd_sonic\",\n",
    "        \"u_dir\": \"wdir_sonic\",\n",
    "        \"new_tp\": \"precip_total\",\n",
    "        pres: \"pres\",\n",
    "    }\n",
    "    model_error_save = []\n",
    "\n",
    "    for key, value in model_obs_var_pairs.items():\n",
    "        model_error_save.append(\n",
    "            get_errors(model_data_subset, nysm_obs_nonan, key, value)\n",
    "        )\n",
    "        model_error = pd.concat(model_error_save, axis=1, sort=False)\n",
    "\n",
    "    model_fcast_and_error_df = (\n",
    "        pd.concat([model_data_subset, model_error], axis=1, sort=False)\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"time\": \"init_time\",\n",
    "                \"t2m\": f\"t2m_{model}\",\n",
    "                \"d2m\": f\"d2m_{model}\",\n",
    "                \"new_tp\": f\"new_tp_{model}\",\n",
    "                \"u_total\": f\"u_total_{model}\",\n",
    "                \"u_dir\": f\"u_dir_{model}\",\n",
    "                pres: f\"{pres}_{model}\",\n",
    "            }\n",
    "        )\n",
    "        .dropna()\n",
    "    )\n",
    "    # put the observations into the dataframe\n",
    "    for key, value in model_obs_var_pairs.items():\n",
    "        model_fcast_and_error_df[f\"{key}_nysm\"] = (\n",
    "            model_fcast_and_error_df[f\"{key}_{model}\"]\n",
    "            - model_fcast_and_error_df[f\"{key}_error\"]\n",
    "        )\n",
    "\n",
    "    return model_fcast_and_error_df\n",
    "\n",
    "\n",
    "def build_fcast_and_error_metrics_df_ok(model, model_data, nysm_obs):\n",
    "    if model == \"HRRR\":\n",
    "        pres = \"mslma\"\n",
    "    else:\n",
    "        pres = \"prmsl\"\n",
    "\n",
    "    model_data = model_data.copy()\n",
    "    if pres in model_data.keys():\n",
    "        model_data.loc[:, pres] = model_data[pres].div(100.0)  # convert Pa to hPa\n",
    "    model_data_subset = model_data.reset_index().set_index(\n",
    "        [\"station\", \"valid_time\", \"time\"]\n",
    "    )[\n",
    "        [\n",
    "            \"t2m\",\n",
    "            \"d2m\",\n",
    "            \"u_total\",\n",
    "            \"u_dir\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "            \"new_tp\",\n",
    "            pres,\n",
    "            \"orog\",\n",
    "        ]\n",
    "    ]\n",
    "    model_data_subset = model_data_subset.sort_values(\n",
    "        by=[\"station\", \"valid_time\", \"time\"]\n",
    "    )\n",
    "    nysm_obs_nonan = nysm_obs.dropna().rename_axis(\n",
    "        index={nysm_obs.index.names[1]: \"valid_time\"}\n",
    "    )\n",
    "\n",
    "    # compute the error\n",
    "    model_obs_var_pairs = {\n",
    "        \"t2m\": \"tair\",\n",
    "        \"d2m\": \"td\",\n",
    "        \"u_total\": \"wspd_sonic\",\n",
    "        \"u_dir\": \"wdir_sonic\",\n",
    "        \"new_tp\": \"precip_total\",\n",
    "        pres: \"pres\",\n",
    "    }\n",
    "    model_error_save = []\n",
    "\n",
    "    for key, value in model_obs_var_pairs.items():\n",
    "        model_error_save.append(\n",
    "            get_errors(model_data_subset, nysm_obs_nonan, key, value)\n",
    "        )\n",
    "        model_error = pd.concat(model_error_save, axis=1, sort=False)\n",
    "\n",
    "    model_fcast_and_error_df = (\n",
    "        pd.concat([model_data_subset, model_error], axis=1, sort=False)\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"time\": \"init_time\",\n",
    "                \"t2m\": f\"t2m_{model}\",\n",
    "                \"d2m\": f\"d2m_{model}\",\n",
    "                \"new_tp\": f\"new_tp_{model}\",\n",
    "                \"u_total\": f\"u_total_{model}\",\n",
    "                \"u_dir\": f\"u_dir_{model}\",\n",
    "                pres: f\"{pres}_{model}\",\n",
    "            }\n",
    "        )\n",
    "        .dropna()\n",
    "    )\n",
    "\n",
    "    # put the observations into the dataframe\n",
    "    for key, value in model_obs_var_pairs.items():\n",
    "        model_fcast_and_error_df[f\"{key}_oksm\"] = (\n",
    "            model_fcast_and_error_df[f\"{key}_{model}\"]\n",
    "            - model_fcast_and_error_df[f\"{key}_error\"]\n",
    "        )\n",
    "\n",
    "    return model_fcast_and_error_df\n",
    "\n",
    "\n",
    "def add_in_fcast_times(model_fcast_and_error_df):\n",
    "    # break down into days & hours of lead time\n",
    "    model_fcast_and_error_df = model_fcast_and_error_df.reset_index()\n",
    "    lead_time_delta = (\n",
    "        model_fcast_and_error_df[\"valid_time\"] - model_fcast_and_error_df[\"time\"]\n",
    "    )\n",
    "    model_fcast_and_error_df[\"lead_time_DAY\"] = lead_time_delta.dt.days\n",
    "    model_fcast_and_error_df[\"lead_time_HOUR\"] = divmod(\n",
    "        lead_time_delta.dt.seconds, 3600\n",
    "    )[0]\n",
    "    model_fcast_and_error_df[\"lead_time_ONLY_HOURS\"] = (\n",
    "        24.0 * model_fcast_and_error_df[\"lead_time_DAY\"]\n",
    "    ) + model_fcast_and_error_df[\"lead_time_HOUR\"]\n",
    "    return model_fcast_and_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5821bc6f-6121-4d58-80d9-cf68eddefaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model, init, month, year, state, mask_water=True):\n",
    "    \"\"\"\n",
    "    This function matches observation and forecast times to calculate error (forecast - observation) for all specified variables.\n",
    "\n",
    "    The following parameters need to be passed into main():\n",
    "\n",
    "    model (str) - HRRR, NAM, GFS\n",
    "    init(str) - initilization time for model, '00' or '12' UTC\n",
    "    month (str) - integer corresponding to calendar month (e.g. '01' is January, '02' is Februrary, etc.)\n",
    "    year (str) - the year of interest (e.g., '2020')\n",
    "    mask_water (bool) - true to mask out grid cells over water before interpolation/nearest-neighbor,\n",
    "                        false to leave all grid cells available for interpolation/nearest-neighbor\n",
    "    \"\"\"\n",
    "\n",
    "    if state == \"NY\":\n",
    "        path_to_data_ny = f\"/home/aevans/ai2es/processed_data/{model}/ny/\"\n",
    "\n",
    "        # ny\n",
    "        if mask_water:\n",
    "            print(\"using data over land only\")\n",
    "            df_model_nysm_sites = pd.read_parquet(\n",
    "                f\"{path_to_data_ny}{model}_{init}z_{month}-{year}_interp_to_nysm_sites_mask_water.parquet\"\n",
    "            )\n",
    "        else:\n",
    "            df_model_nysm_sites = pd.read_parquet(\n",
    "                f\"{path_to_data_ny}{model}_{init}z_{month}-{year}_interp_to_nysm_sites.parquet\"\n",
    "            )\n",
    "        df_model_nysm_sites = df_model_nysm_sites.reset_index().set_index(\n",
    "            [\"station\", \"valid_time\"]\n",
    "        )\n",
    "        model_list_ny = [df_model_nysm_sites]\n",
    "\n",
    "        nysm_1H_obs, nysm_3H_obs = load_nysm_data(year)\n",
    "\n",
    "        if model == \"GFS\":\n",
    "            nysm_obs_list = [nysm_3H_obs]\n",
    "        elif model == \"HRRR\":\n",
    "            nysm_obs_list = [nysm_1H_obs]\n",
    "        elif model == \"NAM\":\n",
    "            nysm_obs_list = [nysm_1H_obs, nysm_3H_obs]\n",
    "            # NY\n",
    "            df_model_nysm_sites_le_36 = df_model_nysm_sites[\n",
    "                df_model_nysm_sites[\"lead time\"] <= 36.0\n",
    "            ]\n",
    "            df_model_nysm_sites_gt_36 = df_model_nysm_sites[\n",
    "                df_model_nysm_sites[\"lead time\"] > 36.0\n",
    "            ]\n",
    "            model_list_ny = [df_model_nysm_sites_le_36, df_model_nysm_sites_gt_36]\n",
    "\n",
    "        df_save_ny = []\n",
    "\n",
    "        # NY\n",
    "        for nysm_obs, model_df in zip(nysm_obs_list, model_list_ny):\n",
    "            model_fcast_and_error_df = build_fcast_and_error_metrics_df(\n",
    "                model, model_df, nysm_obs\n",
    "            )\n",
    "            model_fcast_and_error_df = add_in_fcast_times(model_fcast_and_error_df)\n",
    "            model_fcast_and_error_df = model_fcast_and_error_df.set_index(\n",
    "                [\"station\", \"valid_time\", \"time\"]\n",
    "            )\n",
    "            df_save_ny.append(model_fcast_and_error_df)\n",
    "        model_fcast_and_error_df = pd.concat(df_save_ny, sort=False)\n",
    "\n",
    "    if state == \"OK\":\n",
    "        path_to_data_ok = f\"/home/aevans/ai2es/processed_data/{model}/ok/\"\n",
    "\n",
    "        # OK\n",
    "        if mask_water:\n",
    "            print(\"using data over land only\")\n",
    "            df_model_oksm_sites = pd.read_parquet(\n",
    "                f\"{path_to_data_ok}{model}_{init}z_{month}-{year}_interp_to_oksm_sites_mask_water.parquet\"\n",
    "            )\n",
    "        else:\n",
    "            df_model_oksm_sites = pd.read_parquet(\n",
    "                f\"{path_to_data_ok}{model}_{init}z_{month}-{year}_interp_to_oksm_sites.parquet\"\n",
    "            )\n",
    "        df_model_oksm_sites = df_model_oksm_sites.reset_index().set_index(\n",
    "            [\"station\", \"valid_time\"]\n",
    "        )\n",
    "        model_list_ok = [df_model_oksm_sites]\n",
    "\n",
    "        oksm_1H_obs, oksm_3H_obs = load_oksm_data(year)\n",
    "\n",
    "        if model == \"GFS\":\n",
    "            oksm_obs_list = [oksm_3H_obs]\n",
    "        elif model == \"HRRR\":\n",
    "            oksm_obs_list = [oksm_1H_obs]\n",
    "        elif model == \"NAM\":\n",
    "            oksm_obs_list = [oksm_1H_obs, oksm_3H_obs]\n",
    "            # need to make sure I'm computing error with appropriate 1H and 3H observations, so need to split up\n",
    "            # the model data to do so dynamically\n",
    "            # OK\n",
    "            df_model_oksm_sites_le_36 = df_model_oksm_sites[\n",
    "                df_model_oksm_sites[\"lead time\"] <= 36.0\n",
    "            ]\n",
    "            df_model_oksm_sites_gt_36 = df_model_oksm_sites[\n",
    "                df_model_oksm_sites[\"lead time\"] > 36.0\n",
    "            ]\n",
    "            model_list_ok = [df_model_oksm_sites_le_36, df_model_oksm_sites_gt_36]\n",
    "\n",
    "        df_save_ok = []\n",
    "\n",
    "        # OK\n",
    "        for oksm_obs, model_df_ok in zip(oksm_obs_list, model_list_ok):\n",
    "            model_fcast_and_error_df = build_fcast_and_error_metrics_df_ok(\n",
    "                model, model_df_ok, oksm_obs\n",
    "            )\n",
    "            model_fcast_and_error_df = add_in_fcast_times(model_fcast_and_error_df)\n",
    "            model_fcast_and_error_df = model_fcast_and_error_df.set_index(\n",
    "                [\"station\", \"valid_time\", \"time\"]\n",
    "            )\n",
    "            df_save_ok.append(model_fcast_and_error_df)\n",
    "        model_fcast_and_error_df = pd.concat(df_save_ok, sort=False)\n",
    "\n",
    "    return model_fcast_and_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d9934ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "January\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "February\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "March\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "April\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "May\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "June\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "July\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "August\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "September\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "October\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "November\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "December\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "2019\n",
      "January\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "February\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "March\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "April\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "May\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "June\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "July\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "August\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "September\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "October\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "November\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "December\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "2020\n",
      "January\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "February\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "March\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "April\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "May\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "June\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "July\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "August\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "September\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "October\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "November\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "December\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "2021\n",
      "January\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "February\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "March\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "April\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "May\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "June\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "July\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "August\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "September\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "October\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "November\n",
      "NAM\n",
      "using data over land only\n",
      " \n",
      "December\n",
      "NAM\n",
      "using data over land only\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Observations, forecasts, and forecast error calculated within these main function calls are all saved to the same parquet file.\n",
    "for year in np.arange(2018, 2022):\n",
    "    init = \"12\"  # enter init time here\n",
    "    nam_fcast_and_error_df_save = []\n",
    "    gfs_fcast_and_error_df_save = []\n",
    "    hrrr_fcast_and_error_df_save = []\n",
    "\n",
    "    print(year)\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        print(calendar.month_name[month])\n",
    "        print(\"NAM\")\n",
    "        nam_fcast_and_error_df_save.append(\n",
    "            main(\"NAM\", init, str(month).zfill(2), year, \"NY\")\n",
    "        )\n",
    "        # print('HRRR')\n",
    "        # hrrr_fcast_and_error_df_save.append(main('HRRR', init, str(month).zfill(2), year, 'OK'))\n",
    "        # print('GFS')\n",
    "        # gfs_fcast_and_error_df_save.append(main('GFS', init, str(month).zfill(2), year, 'OK'))\n",
    "        print(\" \")\n",
    "\n",
    "    nam_fcast_and_error_df = pd.concat(nam_fcast_and_error_df_save)\n",
    "    # gfs_fcast_and_error_df = pd.concat(gfs_fcast_and_error_df_save)\n",
    "    # hrrr_fcast_and_error_df = pd.concat(hrrr_fcast_and_error_df_save)\n",
    "\n",
    "    savedir = \"/home/aevans/ai2es/processed_data/frcst_err/\"\n",
    "    nam_fcast_and_error_df.to_parquet(\n",
    "        f\"{savedir}nam_fcast_and_error_df_{init}z_{year}_mask_water_ok.parquet\"\n",
    "    )\n",
    "    # gfs_fcast_and_error_df.to_parquet(f'{savedir}gfs_fcast_and_error_df_{init}z_{year}_mask_water_ok.parquet')\n",
    "    # hrrr_fcast_and_error_df.to_parquet(f'{savedir}hrrr_fcast_and_error_df_{init}z_{year}_mask_water_ok.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52084b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "January\n",
      "NAM\n",
      "using data over land only\n",
      "February\n",
      "NAM\n",
      "using data over land only\n",
      "March\n",
      "NAM\n",
      "using data over land only\n",
      "April\n",
      "NAM\n",
      "using data over land only\n",
      "May\n",
      "NAM\n",
      "using data over land only\n",
      "June\n",
      "NAM\n",
      "using data over land only\n",
      "July\n",
      "NAM\n",
      "using data over land only\n",
      "August\n",
      "NAM\n",
      "using data over land only\n",
      "September\n",
      "NAM\n",
      "using data over land only\n",
      "October\n",
      "NAM\n",
      "using data over land only\n",
      "November\n",
      "NAM\n",
      "using data over land only\n",
      "December\n",
      "NAM\n",
      "using data over land only\n",
      "2019\n",
      "January\n",
      "NAM\n",
      "using data over land only\n",
      "February\n",
      "NAM\n",
      "using data over land only\n",
      "March\n",
      "NAM\n",
      "using data over land only\n",
      "April\n",
      "NAM\n",
      "using data over land only\n",
      "May\n",
      "NAM\n",
      "using data over land only\n",
      "June\n",
      "NAM\n",
      "using data over land only\n",
      "July\n",
      "NAM\n",
      "using data over land only\n",
      "August\n",
      "NAM\n",
      "using data over land only\n",
      "September\n",
      "NAM\n",
      "using data over land only\n",
      "October\n",
      "NAM\n",
      "using data over land only\n",
      "November\n",
      "NAM\n",
      "using data over land only\n",
      "December\n",
      "NAM\n",
      "using data over land only\n",
      "2020\n",
      "January\n",
      "NAM\n",
      "using data over land only\n",
      "February\n",
      "NAM\n",
      "using data over land only\n",
      "March\n",
      "NAM\n",
      "using data over land only\n",
      "April\n",
      "NAM\n",
      "using data over land only\n",
      "May\n",
      "NAM\n",
      "using data over land only\n",
      "June\n",
      "NAM\n",
      "using data over land only\n",
      "July\n",
      "NAM\n",
      "using data over land only\n",
      "August\n",
      "NAM\n",
      "using data over land only\n",
      "September\n",
      "NAM\n",
      "using data over land only\n",
      "October\n",
      "NAM\n",
      "using data over land only\n",
      "November\n",
      "NAM\n",
      "using data over land only\n",
      "December\n",
      "NAM\n",
      "using data over land only\n",
      "2021\n",
      "January\n",
      "NAM\n",
      "using data over land only\n",
      "February\n",
      "NAM\n",
      "using data over land only\n",
      "March\n",
      "NAM\n",
      "using data over land only\n",
      "April\n",
      "NAM\n",
      "using data over land only\n",
      "May\n",
      "NAM\n",
      "using data over land only\n",
      "June\n",
      "NAM\n",
      "using data over land only\n",
      "July\n",
      "NAM\n",
      "using data over land only\n",
      "August\n",
      "NAM\n",
      "using data over land only\n",
      "September\n",
      "NAM\n",
      "using data over land only\n",
      "October\n",
      "NAM\n",
      "using data over land only\n",
      "November\n",
      "NAM\n",
      "using data over land only\n",
      "December\n",
      "NAM\n",
      "using data over land only\n"
     ]
    }
   ],
   "source": [
    "# Observations, forecasts, and forecast error calculated within these main function calls are all saved to the same parquet file.\n",
    "for year in np.arange(2018, 2022):\n",
    "    init = \"00\"  # enter init time here\n",
    "    nam_fcast_and_error_df_save = []\n",
    "    gfs_fcast_and_error_df_save = []\n",
    "    hrrr_fcast_and_error_df_save = []\n",
    "\n",
    "    print(year)\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        print(calendar.month_name[month])\n",
    "        print(\"NAM\")\n",
    "        nam_fcast_and_error_df_save.append(\n",
    "            main(\"NAM\", init, str(month).zfill(2), year, \"NY\")\n",
    "        )\n",
    "        # print('HRRR')\n",
    "        # hrrr_fcast_and_error_df_save.append(main('HRRR', init, str(month).zfill(2), year, 'OK'))\n",
    "        # print('GFS')\n",
    "        # gfs_fcast_and_error_df_save.append(main('GFS', init, str(month).zfill(2), year, 'OK'))\n",
    "        # print(\" \")\n",
    "\n",
    "    nam_fcast_and_error_df = pd.concat(nam_fcast_and_error_df_save)\n",
    "    # gfs_fcast_and_error_df = pd.concat(gfs_fcast_and_error_df_save)\n",
    "    # hrrr_fcast_and_error_df = pd.concat(hrrr_fcast_and_error_df_save)\n",
    "\n",
    "    savedir = \"/home/aevans/ai2es/processed_data/frcst_err/\"\n",
    "    nam_fcast_and_error_df.to_parquet(\n",
    "        f\"{savedir}nam_fcast_and_error_df_{init}z_{year}_mask_water_ok.parquet\"\n",
    "    )\n",
    "    # gfs_fcast_and_error_df.to_parquet(f'{savedir}gfs_fcast_and_error_df_{init}z_{year}_mask_water_ok.parquet')\n",
    "    # hrrr_fcast_and_error_df.to_parquet(f'{savedir}hrrr_fcast_and_error_df_{init}z_{year}_mask_water_ok.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "44818f36aeaf89db1a1d21a2bee6031a28b4e41595a65903b38b9b0c4417365f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
