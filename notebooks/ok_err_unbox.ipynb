{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import calendar\n",
    "import time\n",
    "from matplotlib import colors\n",
    "from sklearn import preprocessing\n",
    "import cartopy.crs as crs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_rmse_months_clim_divs(\n",
    "    model, fcast_and_error_df, max_fhour, var, units, minmax\n",
    "):\n",
    "    fcast_and_error_df = fcast_and_error_df.copy()\n",
    "    fcast_and_error_df = fcast_and_error_df[\n",
    "        fcast_and_error_df[\"lead_time_ONLY_HOURS\"] <= max_fhour\n",
    "    ]\n",
    "    fcast_and_error_df[f\"{var}_sq\"] = fcast_and_error_df[var] ** 2\n",
    "    rmse_months = (\n",
    "        fcast_and_error_df.groupby([fcast_and_error_df.time.dt.month, \"station\"])[\n",
    "            f\"{var}_sq\"\n",
    "        ]\n",
    "        .mean()\n",
    "        .apply(np.sqrt)\n",
    "    )\n",
    "    rmse_months_stns = (\n",
    "        fcast_and_error_df.groupby([fcast_and_error_df.time.dt.month, \"station\"])[\n",
    "            f\"{var}_sq\"\n",
    "        ]\n",
    "        .mean()\n",
    "        .apply(np.sqrt)\n",
    "    )\n",
    "    rmse_stns = (\n",
    "        fcast_and_error_df.groupby([\"station\"])[f\"{var}_sq\"].mean().apply(np.sqrt)\n",
    "    )\n",
    "\n",
    "    new_column_order = [\n",
    "        \"Coastal\",\n",
    "        \"Champlain Valley\",\n",
    "        \"St. Lawrence Valley\",\n",
    "        \"Hudson Valley\",\n",
    "        \"Great Lakes\",\n",
    "        \"Mohawk Valley\",\n",
    "        \"Central Lakes\",\n",
    "        \"Eastern Plateau\",\n",
    "        \"Northern Plateau\",\n",
    "        \"Western Plateau\",\n",
    "    ]\n",
    "    return rmse_months, rmse_stns, rmse_months_stns\n",
    "\n",
    "\n",
    "def get_monthly_rmse_data(fhour_end, var):\n",
    "    (\n",
    "        gfs_rmse_months,\n",
    "        gfs_rmse_stns,\n",
    "        gfs_rmse_months_stns,\n",
    "    ) = get_model_rmse_months_clim_divs(\n",
    "        \"GFS\",\n",
    "        gfs_fcast_and_error_df,\n",
    "        fhour_end,\n",
    "        var,\n",
    "        var_dict.get(var),\n",
    "        var_val_range.get(var),\n",
    "    )\n",
    "    (\n",
    "        nam_rmse_months,\n",
    "        nam_rmse_stns,\n",
    "        nam_rmse_months_stns,\n",
    "    ) = get_model_rmse_months_clim_divs(\n",
    "        \"NAM\",\n",
    "        nam_fcast_and_error_df,\n",
    "        fhour_end,\n",
    "        var,\n",
    "        var_dict.get(var),\n",
    "        var_val_range.get(var),\n",
    "    )\n",
    "\n",
    "    gfs_rmse_months = gfs_rmse_months.reset_index()\n",
    "    nam_rmse_months = nam_rmse_months.reset_index()\n",
    "\n",
    "    gfs_rmse_months[\"NWP Model\"] = \"GFS\"\n",
    "    nam_rmse_months[\"NWP Model\"] = \"NAM\"\n",
    "\n",
    "    print(\"GFS\", gfs_rmse_months[f\"{var}_sq\"].mean())\n",
    "    print(\"NAM\", nam_rmse_months[f\"{var}_sq\"].mean())\n",
    "\n",
    "    if fhour_end <= 18:\n",
    "        (\n",
    "            hrrr_rmse_months,\n",
    "            hrrr_rmse_stns,\n",
    "            hrrr_rmse_months_stns,\n",
    "        ) = get_model_rmse_months_clim_divs(\n",
    "            \"HRRR\",\n",
    "            hrrr_fcast_and_error_df,\n",
    "            fhour_end,\n",
    "            var,\n",
    "            var_dict.get(var),\n",
    "            var_val_range.get(var),\n",
    "        )\n",
    "        hrrr_rmse_months = hrrr_rmse_months.reset_index()\n",
    "        hrrr_rmse_months[\"NWP Model\"] = \"HRRR\"\n",
    "        print(\"HRRR\", hrrr_rmse_months[f\"{var}_sq\"].mean())\n",
    "        rmse_to_plot = pd.concat([gfs_rmse_months, nam_rmse_months, hrrr_rmse_months])\n",
    "    else:\n",
    "        rmse_to_plot = pd.concat([gfs_rmse_months, nam_rmse_months])\n",
    "\n",
    "    rmse_to_plot = rmse_to_plot[rmse_to_plot[\"t2m_error_sq\"] <= 15]\n",
    "    return rmse_to_plot\n",
    "\n",
    "\n",
    "def plot_rmse_boxplots(df, fhour_end, var):\n",
    "    rmse_to_plot = df\n",
    "    palette_DJF = {\"GFS\": \"dodgerblue\", \"NAM\": \"dodgerblue\", \"HRRR\": \"dodgerblue\"}\n",
    "    palette_MAM = {\"GFS\": \"darkorchid\", \"NAM\": \"darkorchid\", \"HRRR\": \"darkorchid\"}\n",
    "    palette_JJA = {\"GFS\": \"darkgreen\", \"NAM\": \"darkgreen\", \"HRRR\": \"darkgreen\"}\n",
    "    palette_SON = {\"GFS\": \"coral\", \"NAM\": \"coral\", \"HRRR\": \"coral\"}\n",
    "    h_ind = 3\n",
    "    if fhour_end > 18:\n",
    "        palette_DJF.pop(\"HRRR\", None)\n",
    "        palette_MAM.pop(\"HRRR\", None)\n",
    "        palette_JJA.pop(\"HRRR\", None)\n",
    "        palette_SON.pop(\"HRRR\", None)\n",
    "        h_ind = h_ind - 1\n",
    "\n",
    "    plt.figure(figsize=(12, 5), dpi=100)\n",
    "    ax = sns.boxplot(\n",
    "        x=\"station\",\n",
    "        y=f\"{var}_sq\",\n",
    "        data=rmse_to_plot,\n",
    "        hue=\"NWP Model\",\n",
    "        width=0.7,\n",
    "        zorder=4,\n",
    "        palette=\"binary\",\n",
    "        medianprops=dict(color=\"white\"),\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        x=\"station\",\n",
    "        y=f\"{var}_sq\",\n",
    "        data=rmse_to_plot[rmse_to_plot[\"time\"].isin([12, 1, 2])],\n",
    "        hue=\"NWP Model\",\n",
    "        size=5,\n",
    "        dodge=True,\n",
    "        zorder=5,\n",
    "        palette=palette_DJF,\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        x=\"station\",\n",
    "        y=f\"{var}_sq\",\n",
    "        data=rmse_to_plot[rmse_to_plot[\"time\"].isin([3, 4, 5])],\n",
    "        hue=\"NWP Model\",\n",
    "        size=5,\n",
    "        dodge=True,\n",
    "        zorder=5,\n",
    "        palette=palette_MAM,\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        x=\"station\",\n",
    "        y=f\"{var}_sq\",\n",
    "        data=rmse_to_plot[rmse_to_plot[\"time\"].isin([6, 7, 8])],\n",
    "        hue=\"NWP Model\",\n",
    "        size=5,\n",
    "        dodge=True,\n",
    "        zorder=5,\n",
    "        palette=palette_JJA,\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        x=\"station\",\n",
    "        y=f\"{var}_sq\",\n",
    "        data=rmse_to_plot[rmse_to_plot[\"time\"].isin([9, 10, 11])],\n",
    "        hue=\"NWP Model\",\n",
    "        size=5,\n",
    "        dodge=True,\n",
    "        zorder=5,\n",
    "        palette=palette_SON,\n",
    "    )\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    l = plt.legend(\n",
    "        handles[0:h_ind] + handles[h_ind::h_ind],\n",
    "        labels[0:h_ind] + [\"DJF\", \"MAM\", \"JJA\", \"SON\"],\n",
    "        loc=2,\n",
    "        borderaxespad=0.0,\n",
    "    )\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid(True, alpha=0.4, zorder=1)\n",
    "    plt.ylabel(f\"RMSE t2m\")\n",
    "    plt.ylim(ymax=5.0, ymin=1.2)\n",
    "    plt.xlabel(\"Station\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(init):\n",
    "    years = [\"2018\", \"2019\", \"2020\", \"2021\"]\n",
    "    savedir = \"/home/aevans/ai2es/processed_data/frcst_err/\"\n",
    "\n",
    "    nam_fcast_and_error = []\n",
    "    gfs_fcast_and_error = []\n",
    "    hrrr_fcast_and_error = []\n",
    "\n",
    "    for year in years:\n",
    "        nam_fcast_and_error.append(\n",
    "            pd.read_parquet(\n",
    "                f\"{savedir}nam_fcast_and_error_df_{init}z_{year}_mask_water_ok.parquet\"\n",
    "            )\n",
    "        )\n",
    "        gfs_fcast_and_error.append(\n",
    "            pd.read_parquet(\n",
    "                f\"{savedir}gfs_fcast_and_error_df_{init}z_{year}_mask_water_ok.parquet\"\n",
    "            )\n",
    "        )\n",
    "        hrrr_fcast_and_error.append(\n",
    "            pd.read_parquet(\n",
    "                f\"{savedir}hrrr_fcast_and_error_df_{init}z_{year}_mask_water_ok.parquet\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    nam_fcast_and_error_df = pd.concat(nam_fcast_and_error)\n",
    "    gfs_fcast_and_error_df = pd.concat(gfs_fcast_and_error)\n",
    "    hrrr_fcast_and_error_df = pd.concat(hrrr_fcast_and_error)\n",
    "\n",
    "    # need to remove the random forecasts that have forecast hours 0\n",
    "    # these are random because they only exist in the files that Ryan T. provided\n",
    "    gfs_fcast_and_error_df = gfs_fcast_and_error_df[\n",
    "        gfs_fcast_and_error_df[\"lead_time_ONLY_HOURS\"] != 0.0\n",
    "    ]\n",
    "    nam_fcast_and_error_df = nam_fcast_and_error_df[\n",
    "        nam_fcast_and_error_df[\"lead_time_ONLY_HOURS\"] != 0.0\n",
    "    ]\n",
    "    hrrr_fcast_and_error_df = hrrr_fcast_and_error_df[\n",
    "        hrrr_fcast_and_error_df[\"lead_time_ONLY_HOURS\"] != 0.0\n",
    "    ]\n",
    "    return gfs_fcast_and_error_df, nam_fcast_and_error_df, hrrr_fcast_and_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_plot(df, month, up):\n",
    "    projPC = crs.PlateCarree()\n",
    "    latN = 37.5\n",
    "    latS = 33\n",
    "    lonW = -103.4\n",
    "    lonE = -94.4\n",
    "    cLat = (latN + latS) / 2\n",
    "    cLon = (lonW + lonE) / 2\n",
    "    projLcc = crs.LambertConformal(central_longitude=cLon, central_latitude=cLat)\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(12, 9), subplot_kw={\"projection\": crs.PlateCarree()}\n",
    "    )\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=projPC)\n",
    "    ax.add_feature(cfeature.LAND)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=\"--\")\n",
    "    ax.add_feature(cfeature.LAKES, alpha=0.5)\n",
    "    ax.add_feature(cfeature.STATES)\n",
    "    ax.xticklabels_top = False\n",
    "    ax.ylabels_right = False\n",
    "    ax.gridlines(\n",
    "        crs=crs.PlateCarree(),\n",
    "        draw_labels=True,\n",
    "        linewidth=2,\n",
    "        color=\"black\",\n",
    "        alpha=0.5,\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "    plotter = ax.scatter(\n",
    "        x=df[\"lon\"],\n",
    "        y=df[\"lat\"],\n",
    "        c=df[\"t2m_error_sq\"],\n",
    "        s=df[\"t2m_error_sq\"] * 50,\n",
    "        marker=\"o\",\n",
    "        edgecolor=\"black\",\n",
    "        cmap=\"jet\",\n",
    "        transform=crs.PlateCarree(),\n",
    "    )\n",
    "    titl_Str = f\"t2m_Forecast Error {up} {month}\"\n",
    "    ax.set_title(titl_Str, size=16)\n",
    "    ax.set_xlabel(\"Longitude\", size=14)\n",
    "    ax.set_ylabel(\"Latitude\", size=14)\n",
    "    ax.tick_params(axis=\"x\", labelsize=12)\n",
    "    ax.tick_params(axis=\"y\", labelsize=12)\n",
    "    ax.grid()\n",
    "    fig.colorbar(plotter, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_plot(tops, bottoms, month):\n",
    "    projPC = crs.PlateCarree()\n",
    "    latN = 37.5\n",
    "    latS = 33\n",
    "    lonW = -103.4\n",
    "    lonE = -94.4\n",
    "    cLat = (latN + latS) / 2\n",
    "    cLon = (lonW + lonE) / 2\n",
    "    projLcc = crs.LambertConformal(central_longitude=cLon, central_latitude=cLat)\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(12, 9), subplot_kw={\"projection\": crs.PlateCarree()}\n",
    "    )\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=projPC)\n",
    "    ax.add_feature(cfeature.LAND)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=\"--\")\n",
    "    ax.add_feature(cfeature.LAKES, alpha=0.5)\n",
    "    ax.add_feature(cfeature.STATES)\n",
    "    ax.xticklabels_top = False\n",
    "    ax.ylabels_right = False\n",
    "    ax.gridlines(\n",
    "        crs=crs.PlateCarree(),\n",
    "        draw_labels=True,\n",
    "        linewidth=2,\n",
    "        color=\"black\",\n",
    "        alpha=0.5,\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "    plotter = ax.scatter(\n",
    "        x=tops[\"lon\"],\n",
    "        y=tops[\"lat\"],\n",
    "        c=\"g\",\n",
    "        s=50,\n",
    "        marker=\"v\",\n",
    "        edgecolor=\"black\",\n",
    "        transform=crs.PlateCarree(),\n",
    "    )\n",
    "    plotter2 = ax.scatter(\n",
    "        x=bottoms[\"lon\"],\n",
    "        y=bottoms[\"lat\"],\n",
    "        c=\"orange\",\n",
    "        s=50,\n",
    "        marker=\"o\",\n",
    "        edgecolor=\"black\",\n",
    "        transform=crs.PlateCarree(),\n",
    "    )\n",
    "    ax.set_title(f\"Best/Worst Sites by Error {month}\", size=16)\n",
    "    ax.set_xlabel(\"Longitude\", size=14)\n",
    "    ax.set_ylabel(\"Latitude\", size=14)\n",
    "    ax.tick_params(axis=\"x\", labelsize=12)\n",
    "    ax.tick_params(axis=\"y\", labelsize=12)\n",
    "    ax.grid()\n",
    "    # fig.colorbar(plotter, ax=ax)\n",
    "    # fig.colorbar(plotter2, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_plot_top(df):\n",
    "    projPC = crs.PlateCarree()\n",
    "    latN = 37.5\n",
    "    latS = 33\n",
    "    lonW = -103.4\n",
    "    lonE = -94.4\n",
    "    cLat = (latN + latS) / 2\n",
    "    cLon = (lonW + lonE) / 2\n",
    "    projLcc = crs.LambertConformal(central_longitude=cLon, central_latitude=cLat)\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(12, 9), subplot_kw={\"projection\": crs.PlateCarree()}\n",
    "    )\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=projPC)\n",
    "    ax.add_feature(cfeature.LAND)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=\"--\")\n",
    "    ax.add_feature(cfeature.LAKES, alpha=0.5)\n",
    "    ax.add_feature(cfeature.STATES)\n",
    "    ax.xticklabels_top = False\n",
    "    ax.ylabels_right = False\n",
    "    ax.gridlines(\n",
    "        crs=crs.PlateCarree(),\n",
    "        draw_labels=True,\n",
    "        linewidth=2,\n",
    "        color=\"black\",\n",
    "        alpha=0.5,\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "    plotter = ax.scatter(\n",
    "        x=df[\"lon\"],\n",
    "        y=df[\"lat\"],\n",
    "        c=\"g\",\n",
    "        s=50,\n",
    "        marker=\"o\",\n",
    "        edgecolor=\"black\",\n",
    "        transform=crs.PlateCarree(),\n",
    "    )\n",
    "    ax.set_title(f\"Top 10% Sites by t2m Error\", size=16)\n",
    "    ax.set_xlabel(\"Longitude\", size=14)\n",
    "    ax.set_ylabel(\"Latitude\", size=14)\n",
    "    ax.tick_params(axis=\"x\", labelsize=12)\n",
    "    ax.tick_params(axis=\"y\", labelsize=12)\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_plot_bott(df):\n",
    "    projPC = crs.PlateCarree()\n",
    "    latN = 37.5\n",
    "    latS = 33\n",
    "    lonW = -103.4\n",
    "    lonE = -94.4\n",
    "    cLat = (latN + latS) / 2\n",
    "    cLon = (lonW + lonE) / 2\n",
    "    projLcc = crs.LambertConformal(central_longitude=cLon, central_latitude=cLat)\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(12, 9), subplot_kw={\"projection\": crs.PlateCarree()}\n",
    "    )\n",
    "    ax.set_extent([lonW, lonE, latS, latN], crs=projPC)\n",
    "    ax.add_feature(cfeature.LAND)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=\"--\")\n",
    "    ax.add_feature(cfeature.LAKES, alpha=0.5)\n",
    "    ax.add_feature(cfeature.STATES)\n",
    "    ax.xticklabels_top = False\n",
    "    ax.ylabels_right = False\n",
    "    ax.gridlines(\n",
    "        crs=crs.PlateCarree(),\n",
    "        draw_labels=True,\n",
    "        linewidth=2,\n",
    "        color=\"black\",\n",
    "        alpha=0.5,\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "    plotter = ax.scatter(\n",
    "        x=df[\"lon\"],\n",
    "        y=df[\"lat\"],\n",
    "        c=\"orange\",\n",
    "        s=50,\n",
    "        marker=\"o\",\n",
    "        edgecolor=\"black\",\n",
    "        transform=crs.PlateCarree(),\n",
    "    )\n",
    "    ax.set_title(f\"Bottom 10% Sites by t2m Error\", size=16)\n",
    "    ax.set_xlabel(\"Longitude\", size=14)\n",
    "    ax.set_ylabel(\"Latitude\", size=14)\n",
    "    ax.tick_params(axis=\"x\", labelsize=12)\n",
    "    ax.tick_params(axis=\"y\", labelsize=12)\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_rmse_heatmap_fhours_clim_divs(\n",
    "    model, fcast_and_error_df, var, units, minmax, stations\n",
    "):\n",
    "    fcast_and_error_df = fcast_and_error_df.copy()\n",
    "    fcast_and_error_df[f\"{var}_sq\"] = fcast_and_error_df[var] ** 2\n",
    "    fcast_and_error_df = fcast_and_error_df[fcast_and_error_df[\"t2m_error_sq\"] <= 18]\n",
    "    fcast_and_error_df = fcast_and_error_df[fcast_and_error_df[\"lead_time_HOUR\"] < 25]\n",
    "    fcast_and_error_df = fcast_and_error_df[fcast_and_error_df[\"lead_time_HOUR\"] != 0]\n",
    "    fcast_and_error_df = fcast_and_error_df[fcast_and_error_df[\"lead_time_DAY\"] == 0]\n",
    "    rmse = (\n",
    "        fcast_and_error_df.groupby([\"lead_time_HOUR\", \"station\"])[f\"{var}_sq\"]\n",
    "        .mean()\n",
    "        .apply(np.sqrt)\n",
    "    )\n",
    "\n",
    "    rmse_unstacked = rmse.unstack()[stations].T\n",
    "    rmse_unstacked = rmse_unstacked.drop_duplicates()\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    ax = sns.heatmap(\n",
    "        rmse_unstacked,\n",
    "        annot=True,\n",
    "        linewidths=0.5,\n",
    "        cmap=cm.YlGnBu,\n",
    "        vmin=minmax[0],\n",
    "        vmax=minmax[1],\n",
    "        cbar_kws={\"label\": f\"RMSE [{units}]\"},\n",
    "    )\n",
    "    ax.set_xlabel(\"Forecast Hour\")\n",
    "    ax.set_title(f\"{model}, {var.replace('_error','')}, Root Mean Square Error\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_plot_df(tippity_df, keys):\n",
    "    plot_df = pd.DataFrame()\n",
    "    stat_ls = []\n",
    "    lat_ls = []\n",
    "    lon_ls = []\n",
    "    for i, _ in enumerate(tippity_df[\"station\"]):\n",
    "        if tippity_df[\"station\"].iloc[i] in keys:\n",
    "            stations = tippity_df[\"station\"].iloc[i]\n",
    "            lats = tippity_df[\"lat\"].iloc[i]\n",
    "            lons = tippity_df[\"lon\"].iloc[i]\n",
    "            stat_ls.append(stations)\n",
    "            lat_ls.append(lats)\n",
    "            lon_ls.append(lons)\n",
    "    plot_df[\"stations\"] = stat_ls\n",
    "    plot_df[\"lat\"] = lat_ls\n",
    "    plot_df[\"lon\"] = lon_ls\n",
    "\n",
    "    return plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict = {\n",
    "    \"d2m_error\": \"$^{\\circ}$C\",\n",
    "    \"u_dir_error\": \"$^{\\circ}$\",\n",
    "    \"u_total_error\": \"m s$^{-1}$\",\n",
    "    \"t2m_error\": \"$^{\\circ}$C\",\n",
    "    \"new_tp_error\": \"mm\",\n",
    "    \"prmsl_error\": \"hPa\",\n",
    "}\n",
    "\n",
    "var_val_range = {\n",
    "    \"d2m_error\": [1.0, 4.0],\n",
    "    \"u_dir_error\": [40, 100],\n",
    "    \"u_total_error\": [1, 3.5],\n",
    "    \"t2m_error\": [1.5, 3.5],\n",
    "    \"new_tp_error\": [0, 3.5],\n",
    "    \"prmsl_error\": [-20, 100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = \"12\"\n",
    "\n",
    "gfs_fcast_and_error_df, nam_fcast_and_error_df, hrrr_fcast_and_error_df = read_data(\n",
    "    init\n",
    ")\n",
    "gfs_fcast_and_error_df = gfs_fcast_and_error_df.reset_index()\n",
    "nam_fcast_and_error_df = nam_fcast_and_error_df.reset_index()\n",
    "hrrr_fcast_and_error_df = hrrr_fcast_and_error_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nam_fcast_and_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs_fcast_and_error_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nam_fcast_and_error_df[20:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_to_plot = get_monthly_rmse_data(18, \"t2m_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_to_plot = rmse_to_plot.sort_values(by=[\"t2m_error_sq\"])\n",
    "rmse_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(rmse_to_plot[\"station\"], rmse_to_plot[\"t2m_error_sq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_to_plot[\"t2m_error_sq\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diction = pd.read_csv(\"/home/aevans/landtype/notebooks/oksm_coords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_stations = diction[\"station\"]\n",
    "ok_lats = diction[\"latitude\"]\n",
    "ok_lons = diction[\"longitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latdict = dict(zip(diction.station, diction.latitude))\n",
    "londict = dict(zip(diction.station, diction.longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_to_plot[\"lon\"] = rmse_to_plot[\"station\"].map(londict)\n",
    "rmse_to_plot[\"lat\"] = rmse_to_plot[\"station\"].map(latdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_hrrr = rmse_to_plot[rmse_to_plot[\"NWP Model\"] == \"HRRR\"]\n",
    "rmse_hrrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops_ls = []\n",
    "bottoms_ls = []\n",
    "\n",
    "\n",
    "for i in np.arange(1, 13):\n",
    "    # sort by month\n",
    "    df_err = rmse_hrrr.where(rmse_hrrr[\"time\"] == i).dropna()\n",
    "\n",
    "    # get top and bottom\n",
    "    top10 = df_err[:13]\n",
    "    bottom10 = df_err[-13:]\n",
    "    top10.to_csv(\n",
    "        f\"/home/aevans/nwp_bias/data/unboxing_df/top/t{init}/ok/t{init}z_topcsv_{i}_hrrr.csv\"\n",
    "    )\n",
    "    bottom10.to_csv(\n",
    "        f\"/home/aevans/nwp_bias/data/unboxing_df/bottom/t{init}/ok/t{init}z_bottcsv_{i}_hrrr.csv\"\n",
    "    )\n",
    "\n",
    "    # plot\n",
    "    count_plot(top10, bottom10, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tippity_df = pd.DataFrame()\n",
    "for i in np.arange(1, 13):\n",
    "    df = pd.read_csv(\n",
    "        f\"/home/aevans/nwp_bias/data/unboxing_df/top/t{init}/ok/t{init}z_topcsv_{i}_hrrr.csv\"\n",
    "    )\n",
    "    tippity_df = pd.concat([df, tippity_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rockbott_df = pd.DataFrame()\n",
    "for i in np.arange(1, 13):\n",
    "    df = pd.read_csv(\n",
    "        f\"/home/aevans/nwp_bias/data/unboxing_df/bottom/t{init}/ok/t{init}z_bottcsv_{i}_hrrr.csv\"\n",
    "    )\n",
    "    rockbott_df = pd.concat([df, rockbott_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rockbott_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = tippity_df[\"station\"].value_counts()[:13].keys()\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame()\n",
    "stat_ls = []\n",
    "lat_ls = []\n",
    "lon_ls = []\n",
    "for i, _ in enumerate(tippity_df[\"station\"]):\n",
    "    if tippity_df[\"station\"].iloc[i] in keys:\n",
    "        stations = tippity_df[\"station\"].iloc[i]\n",
    "        lats = tippity_df[\"lat\"].iloc[i]\n",
    "        lons = tippity_df[\"lon\"].iloc[i]\n",
    "        stat_ls.append(stations)\n",
    "        lat_ls.append(lats)\n",
    "        lon_ls.append(lons)\n",
    "plot_df[\"stations\"] = stat_ls\n",
    "plot_df[\"lat\"] = lat_ls\n",
    "plot_df[\"lon\"] = lon_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = rockbott_df[\"station\"].value_counts()[:13].keys()\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_bott = format_plot_df(rockbott_df, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_bott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot_top(plot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot_bott(plot_df_bott)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_gfs = rmse_to_plot[rmse_to_plot[\"NWP Model\"] == \"GFS\"]\n",
    "rmse_gfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(1, 13):\n",
    "    # sort by month\n",
    "    df_err = rmse_gfs.where(rmse_gfs[\"time\"] == i).dropna()\n",
    "\n",
    "    # get top and bottom\n",
    "    top10 = df_err[:13]\n",
    "    bottom10 = df_err[-13:]\n",
    "    top10.to_csv(\n",
    "        f\"/home/aevans/nwp_bias/data/unboxing_df/top/t{init}/ok/t{init}z_topcsv_{i}_gfs.csv\"\n",
    "    )\n",
    "    bottom10.to_csv(\n",
    "        f\"/home/aevans/nwp_bias/data/unboxing_df/bottom/t{init}/ok/t{init}z_bottcsv_{i}_gfs.csv\"\n",
    "    )\n",
    "\n",
    "    # plot\n",
    "    count_plot(top10, bottom10, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tippity_df_gfs = pd.DataFrame()\n",
    "for i in np.arange(1, 13):\n",
    "    df = pd.read_csv(\n",
    "        f\"/home/aevans/nwp_bias/data/unboxing_df/top/t{init}/ok/t{init}z_topcsv_{i}_gfs.csv\"\n",
    "    )\n",
    "    tippity_df_gfs = pd.concat([df, tippity_df_gfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rockbott_df_gfs = pd.DataFrame()\n",
    "for i in np.arange(1, 13):\n",
    "    df = pd.read_csv(\n",
    "        f\"/home/aevans/nwp_bias/data/unboxing_df/bottom/t{init}/ok/t{init}z_bottcsv_{i}_gfs.csv\"\n",
    "    )\n",
    "    rockbott_df_gfs = pd.concat([df, rockbott_df_gfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = tippity_df_gfs[\"station\"].value_counts()[:13].keys()\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_top_gfs = format_plot_df(tippity_df_gfs, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = rockbott_df_gfs[\"station\"].value_counts()[:13].keys()\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_bott_gfs = format_plot_df(rockbott_df_gfs, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot_top(plot_df_top_gfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot_bott(plot_df_bott_gfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_nam = rmse_to_plot[rmse_to_plot[\"NWP Model\"] == \"NAM\"]\n",
    "rmse_nam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(1, 13):\n",
    "    # sort by month\n",
    "    df_err = rmse_nam.where(rmse_nam[\"time\"] == i).dropna()\n",
    "\n",
    "    # get top and bottom\n",
    "    top10 = df_err[:13]\n",
    "    bottom10 = df_err[-13:]\n",
    "    top10.to_csv(\n",
    "        f\"/home/aevans/nwp_bias/data/unboxing_df/top/t{init}/ok/t{init}z_topcsv_{i}_nam.csv\"\n",
    "    )\n",
    "    bottom10.to_csv(\n",
    "        f\"/home/aevans/nwp_bias/data/unboxing_df/bottom/t{init}/ok/t{init}z_bottcsv_{i}_nam.csv\"\n",
    "    )\n",
    "\n",
    "    # plot\n",
    "    count_plot(top10, bottom10, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tippity_df_nam = pd.DataFrame()\n",
    "for i in np.arange(1, 13):\n",
    "    df = pd.read_csv(\n",
    "        f\"/home/aevans/nwp_bias/data/unboxing_df/top/t{init}/ok/t{init}z_topcsv_{i}_gfs.csv\"\n",
    "    )\n",
    "    tippity_df_nam = pd.concat([df, tippity_df_nam])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rockbott_df_nam = pd.DataFrame()\n",
    "for i in np.arange(1, 13):\n",
    "    df = pd.read_csv(\n",
    "        f\"/home/aevans/nwp_bias/data/unboxing_df/bottom/t{init}/ok/t{init}z_bottcsv_{i}_gfs.csv\"\n",
    "    )\n",
    "    rockbott_df_nam = pd.concat([df, rockbott_df_nam])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = tippity_df_nam[\"station\"].value_counts()[:13].keys()\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_top_nam = format_plot_df(tippity_df_nam, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = rockbott_df_nam[\"station\"].value_counts()[:13].keys()\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_bott_nam = format_plot_df(rockbott_df_nam, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot_top(plot_df_top_nam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot_bott(plot_df_bott_nam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = pd.DataFrame()\n",
    "tops = pd.concat([tippity_df, tops])\n",
    "tops = pd.concat([tippity_df_gfs, tops])\n",
    "tops = pd.concat([tippity_df_nam, tops])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_keys = tops[\"station\"].value_counts()[:13].keys()\n",
    "top_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_tops = format_plot_df(tops, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot_top(plot_df_tops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "botts = pd.DataFrame()\n",
    "botts = pd.concat([rockbott_df, botts])\n",
    "botts = pd.concat([rockbott_df_gfs, botts])\n",
    "botts = pd.concat([rockbott_df_nam, botts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = botts[\"station\"].value_counts()[:13].keys()\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_botts = format_plot_df(botts, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_plot_bott(plot_df_botts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bott_bott = get_monthly_rmse_data(18, \"t2m_error\")\n",
    "bott_bott = bott_bott[bott_bott[\"station\"].isin(keys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_top = get_monthly_rmse_data(18, \"t2m_error\")\n",
    "top_top = top_top[top_top[\"station\"].isin(top_keys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rmse_boxplots(bott_bott, 18, \"t2m_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rmse_boxplots(top_top, 18, \"t2m_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"t2m_error\"\n",
    "units = \"$^{\\circ}$C\"\n",
    "plot_model_rmse_heatmap_fhours_clim_divs(\n",
    "    \"GFS\", gfs_fcast_and_error_df, var, units, var_val_range.get(var), keys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_rmse_heatmap_fhours_clim_divs(\n",
    "    \"NAM\", nam_fcast_and_error_df, var, units, var_val_range.get(var), keys\n",
    ")\n",
    "plot_model_rmse_heatmap_fhours_clim_divs(\n",
    "    \"HRRR\", hrrr_fcast_and_error_df, var, units, var_val_range.get(var), keys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44818f36aeaf89db1a1d21a2bee6031a28b4e41595a65903b38b9b0c4417365f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
