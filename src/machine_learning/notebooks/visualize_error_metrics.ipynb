{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import statistics as st\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_LSTM = \"/home/aevans/nwp_bias/src/machine_learning/data/AMS_2025/20241220/VOOR/VOOR_fh1_u_total_NAM_ml_output_linear.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station = \"VOOR\"\n",
    "fh = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_parquet(\n",
    "    \"/home/aevans/nwp_bias/src/machine_learning/data/lstm_eval_csvs/20250107/VOOR/01_07_2025_14:53:35_full_VOOR.parquet\"\n",
    ")\n",
    "for k in full_df.columns:\n",
    "    print(k)\n",
    "full_df[\"true_diff\"] = full_df[f\"u_total_VOOR\"] - full_df[f\"wspd_sonic_mean_VOOR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_path = \"/home/aevans/nwp_bias/src/machine_learning/data/parent_models/HRRR/s2s/Central Lakes_t2m_HRRR_lookup_linear.csv\"\n",
    "\n",
    "lookup_path_quad = \"/home/aevans/nwp_bias/src/machine_learning/data/parent_models/HRRR/s2s/Central Lakes_t2m_HRRR_lookup_quad.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf = pd.read_parquet(model_path_LSTM)\n",
    "# ldf = ldf.sort_index()\n",
    "# ldf['Model forecast'] = ldf['Model forecast']*-1\n",
    "ldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(1, 60):\n",
    "    df = ldf.copy()\n",
    "    df[\"Model forecast\"] = df[\"Model forecast\"].shift(i).fillna(0)\n",
    "    df[\"diff\"] = df.iloc[:, 0] - df.iloc[:, 1]\n",
    "    mean = st.mean(abs(df[\"diff\"]))\n",
    "    mean_s = st.mean(df[\"diff\"] ** 2)\n",
    "\n",
    "    print(\"FH\", i)\n",
    "    print(mean, mean_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ldf['Model forecast'] = ldf['Model forecast'].shift(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.dropna(inplace=True)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in full_df.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ldf[\"valid_time\"] = full_df[\"valid_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_fold(df, fold):\n",
    "    length = len(df)\n",
    "    test_len = int(length * 0.2)\n",
    "    df_train = pd.DataFrame()\n",
    "\n",
    "    for n in np.arange(0, 5):\n",
    "        if n != fold:\n",
    "            df1 = df.iloc[int(0.2 * n * length) : int(0.2 * (n + 1) * length)]\n",
    "            df_train = pd.concat([df_train, df1])\n",
    "        else:\n",
    "            df_test = df.iloc[int(0.2 * n * length) : int(0.2 * (n + 1) * length)]\n",
    "            f = int(len(df_test) * 0.5)\n",
    "            df_val = df_test.iloc[:f]\n",
    "            df_test = df_test[-f:]\n",
    "\n",
    "    return df_train[\"valid_time\"], df_test[\"valid_time\"], df_val[\"valid_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf[\"valid_time\"] = pd.to_datetime(ldf[\"valid_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, df_val = which_fold(ldf, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_start = df_test.iloc[0]\n",
    "test_set_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_finish = df_test.iloc[-1]\n",
    "test_set_finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_filter(ldf, time1, time2):\n",
    "    ldf = ldf[ldf[\"valid_time\"] > time1]\n",
    "    ldf = ldf[ldf[\"valid_time\"] < time2]\n",
    "\n",
    "    return ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def met_output(df, station, fh):\n",
    "    fig, ax = plt.subplots(figsize=(24, 6))\n",
    "    x = df[\"valid_time\"]\n",
    "\n",
    "    # Convert datetime values to numerical values\n",
    "    x_numeric = mdates.date2num(x)\n",
    "\n",
    "    # Assuming your timestamps are in a datetime64 format\n",
    "    day_mask = (x.dt.hour >= 6) & (\n",
    "        x.dt.hour < 18\n",
    "    )  # Adjust the hours based on your day/night definition\n",
    "\n",
    "    plt.plot(\n",
    "        np.array(x),\n",
    "        np.array(df[f\"u_total_{station}\"]),\n",
    "        c=\"mediumseagreen\",\n",
    "        linewidth=3,\n",
    "        label=\"NAM Prediction\",\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        np.array(x),\n",
    "        np.array(df[\"reforecast\"]),\n",
    "        c=\"red\",\n",
    "        linewidth=3,\n",
    "        linestyle=\"--\",  # Dashed line\n",
    "        label=\"LSTM Reforecast\",\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        np.array(x),\n",
    "        np.array(df[f\"wspd_sonic_mean_{station}\"]),\n",
    "        c=\"black\",\n",
    "        linewidth=1,\n",
    "        alpha=0.9,\n",
    "        label=\"NYSM Observation\",\n",
    "    )\n",
    "\n",
    "    # Fill daytime hours with white color\n",
    "    ax.fill_between(\n",
    "        x_numeric, 0, 10, where=day_mask, color=\"white\", alpha=0.5, label=\"Daytime\"\n",
    "    )\n",
    "\n",
    "    # Fill nighttime hours with grey color\n",
    "    ax.fill_between(\n",
    "        x_numeric, 0, 10, where=~day_mask, color=\"grey\", alpha=0.2, label=\"Nighttime\"\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"NAM Prediction v NYSM Observation: {station}: FH{fh}\", fontsize=28)\n",
    "    # plt.ylim(-5, 5.)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = datetime(2024, 4, 1, 0, 0, 0)\n",
    "time2 = datetime(2024, 4, 30, 23, 0, 0)\n",
    "\n",
    "ldf = date_filter(ldf, time1, time2)\n",
    "full_df = date_filter(full_df, time1, time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def create_heatmap(df, x_column=\"target_error_lead_0\", y_column=\"Model forecast\"):\n",
    "    # Round values\n",
    "    df[x_column] = np.round(df[x_column] / 1.0) * 1.0\n",
    "    df[y_column] = np.round(df[y_column] / 1.0) * 1.0\n",
    "\n",
    "    # Pivot the DataFrame to create a matrix suitable for the heatmap\n",
    "    heatmap_data = pd.pivot_table(\n",
    "        df, index=y_column, columns=x_column, aggfunc=\"size\", fill_value=0\n",
    "    )\n",
    "\n",
    "    # Calculate percentages\n",
    "    total = heatmap_data.sum()\n",
    "    heatmap_data_percent = (heatmap_data / total) * 100\n",
    "\n",
    "    # Create the heatmap using seaborn\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    sns.heatmap(\n",
    "        heatmap_data_percent,\n",
    "        vmax=100,\n",
    "        cmap=\"Reds\",\n",
    "        annot=True,\n",
    "        fmt=\".1f\",  # Format as percentage with one decimal place\n",
    "        cbar_kws={\"label\": \"Percentage (%)\"},  # Add color bar label\n",
    "    )\n",
    "\n",
    "    # Set the labels and title\n",
    "    plt.xlabel(\"Target\")\n",
    "    plt.ylabel(\"LSTM\")\n",
    "    plt.title(\"Heatmap of Target vs LSTM\")\n",
    "\n",
    "    # Show the heatmap\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "def create_scatterplot(df, x_column=\"target_error_lead_0\", y_column=\"Model forecast\"):\n",
    "    # Calculate point density\n",
    "    xy = np.vstack([df[x_column], df[y_column]])\n",
    "    z = gaussian_kde(xy)(xy)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    # Create the scatterplot\n",
    "    scatter = plt.scatter(\n",
    "        df[x_column],\n",
    "        df[y_column],\n",
    "        c=z,\n",
    "        cmap=\"YlOrRd\",\n",
    "        s=100,\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.3,\n",
    "    )\n",
    "\n",
    "    # Add color bar with label\n",
    "    cbar = plt.colorbar(scatter)\n",
    "    cbar.set_label(\"Point Density\")\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.xlabel(\"Target\", fontsize=18)\n",
    "    plt.xlim(-6, 6)\n",
    "    plt.ylim(-6, 6)\n",
    "    plt.ylabel(\"LSTM\", fontsize=18)\n",
    "    plt.title(\"Scatterplot with Density and Colorbar\", fontsize=24)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_scatterplot_heatmap(\n",
    "    df, x_column=\"target_error_lead_0\", y_column=\"Model forecast\", gridsize=100\n",
    "):\n",
    "    plt.figure(figsize=(16, 12))\n",
    "\n",
    "    # Create a 2D histogram (binning) to calculate point concentration\n",
    "    hb = plt.hexbin(\n",
    "        df[x_column], df[y_column], gridsize=gridsize, cmap=\"viridis\", mincnt=1\n",
    "    )\n",
    "\n",
    "    # Add color bar with label\n",
    "    cbar = plt.colorbar(hb)\n",
    "    cbar.set_label(\"Number of Points\")\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.xlabel(\"Target\", fontsize=18)\n",
    "    plt.ylabel(\"LSTM\", fontsize=18)\n",
    "    plt.xlim(-6, 6)\n",
    "    plt.ylim(-6, 6)\n",
    "    plt.title(\"Scatterplot Heatmap with Point Frequency\", fontsize=24)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_hexbin_heatmap(\n",
    "    df, x_column=\"target_error_lead_0\", y_column=\"Model forecast\"\n",
    "):\n",
    "    plt.figure(figsize=(16, 12))\n",
    "\n",
    "    # Create hexbin plot with continuous color density\n",
    "    hexplot = plt.hexbin(\n",
    "        df[x_column], df[y_column], gridsize=50, cmap=\"cividis\", mincnt=1\n",
    "    )\n",
    "\n",
    "    # Add color bar with label\n",
    "    cbar = plt.colorbar(hexplot)\n",
    "    cbar.set_label(\"Count in Bin\")\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.xlabel(\"Target\", fontsize=18)\n",
    "    plt.ylabel(\"LSTM\", fontsize=18)\n",
    "    plt.xlim(-10, 10)\n",
    "    plt.ylim(-10, 10)\n",
    "    plt.title(\"Hexbin Scatterplot Heatmap with Colorbar\", fontsize=24)\n",
    "    # Add gridlines\n",
    "    plt.grid(visible=True, which=\"both\", color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_regression(x, y):\n",
    "    X = x[:, np.newaxis]\n",
    "    quantiles = [0.10, 0.5, 0.90]\n",
    "    predictions = {}\n",
    "    out_bounds_predictions = np.zeros_like(y, dtype=np.bool_)\n",
    "    for quantile in quantiles:\n",
    "        qr = QuantileRegressor(quantile=quantile, alpha=0, solver=solver)\n",
    "        y_pred = qr.fit(X, y).predict(X)\n",
    "        predictions[quantile] = y_pred\n",
    "\n",
    "    predictions_df = pd.DataFrame()\n",
    "    predictions_df[\"target\"] = x\n",
    "\n",
    "    for q in quantiles:\n",
    "        predictions_df[q] = predictions.get(q)\n",
    "\n",
    "    return qr, y_pred, predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def ml_output(df, full_df, fold, station, test_set_start, test_set_finish, fh):\n",
    "    fig, ax = plt.subplots(figsize=(24, 6))\n",
    "    x = df[\"valid_time\"]\n",
    "\n",
    "    # Convert datetime values to numerical values\n",
    "    x_numeric = mdates.date2num(x)\n",
    "\n",
    "    # Assuming your timestamps are in a datetime64 format\n",
    "    day_mask = (x.dt.hour >= 6) & (\n",
    "        x.dt.hour < 18\n",
    "    )  # Adjust the hours based on your day/night definition\n",
    "\n",
    "    plt.plot(\n",
    "        np.array(x),\n",
    "        np.array(df[\"target_error_lead_0\"]),\n",
    "        c=\"black\",\n",
    "        linewidth=1,\n",
    "        label=\"Target\",\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        np.array(x),\n",
    "        np.array(df[\"Model forecast\"]),\n",
    "        c=\"red\",\n",
    "        linewidth=3,\n",
    "        alpha=0.7,\n",
    "        label=\"LSTM Output\",\n",
    "    )\n",
    "\n",
    "    # plt.axvline(\n",
    "    #     x=test_set_start,\n",
    "    #     c=\"green\",\n",
    "    #     linestyle=\"--\",\n",
    "    #     linewidth=2.0,\n",
    "    #     label=\"Test Set Start\",\n",
    "    # )\n",
    "    # plt.axvline(\n",
    "    #     x=test_set_finish,\n",
    "    #     c=\"red\",\n",
    "    #     linestyle=\"--\",\n",
    "    #     linewidth=2.0,\n",
    "    #     label=\"Test Set Finish\",\n",
    "    # )\n",
    "\n",
    "    # Fill daytime hours with white color\n",
    "    ax.fill_between(\n",
    "        x_numeric, -6, 6, where=day_mask, color=\"white\", alpha=0.5, label=\"Daytime\"\n",
    "    )\n",
    "\n",
    "    # Fill nighttime hours with grey color\n",
    "    ax.fill_between(\n",
    "        x_numeric, -6, 6, where=~day_mask, color=\"grey\", alpha=0.2, label=\"Nighttime\"\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"NAM Wind Error LSTM Output v Target: {station}: FH{fh}\", fontsize=28)\n",
    "    # plt.ylim(-5, 5.)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_linear_coefficients(df):\n",
    "    \"\"\"\n",
    "    Adjusts the 'Model forecast' column of the input DataFrame by aligning it with\n",
    "    the statistics of the 'target_error_lead_0' column. The alignment involves\n",
    "    subtracting the difference in means and scaling based on the maximum absolute values\n",
    "    of both columns. The result is that the 'Model forecast' is transformed to better fit\n",
    "    the target error profile.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame with 'target_error_lead_0' and 'Model forecast' columns.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The modified DataFrame with updated 'Model forecast' values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the mean of 'target_error_lead_0' and 'Model forecast'\n",
    "    mean1 = st.mean(df[\"target_error_lead_0\"])\n",
    "    mean2 = st.mean(df[\"Model forecast\"])\n",
    "\n",
    "    # Find the row with the maximum absolute value in 'target_error_lead_0'\n",
    "    max1_index = df[\"target_error_lead_0\"].abs().idxmax()\n",
    "    # Retrieve the row that contains this maximum absolute value\n",
    "    max_row = df.loc[max1_index]\n",
    "\n",
    "    # Find the row with the maximum absolute value in 'target_error_lead_0'\n",
    "    min1_index = df[\"target_error_lead_0\"].abs().idxmin()\n",
    "    # Retrieve the row that contains this maximum absolute value\n",
    "    min_row = df.loc[min1_index]\n",
    "\n",
    "    # Find the maximum absolute value of 'target_error_lead_0' and 'Model forecast'\n",
    "    max1 = abs(max_row[\"target_error_lead_0\"])\n",
    "    max2 = abs(max_row[\"Model forecast\"])\n",
    "\n",
    "    # Find the maximum absolute value of 'target_error_lead_0' and 'Model forecast'\n",
    "    min1 = abs(min_row[\"target_error_lead_0\"])\n",
    "    min2 = abs(min_row[\"Model forecast\"])\n",
    "\n",
    "    # Calculate the difference in means between 'Model forecast' and 'target_error_lead_0'\n",
    "    diff = mean2 - mean1\n",
    "\n",
    "    # # Recalculate the maximum absolute value after adjustment\n",
    "    # max1 = abs(max(df['target_error_lead_0']))\n",
    "    # max2 = abs(max(df['Model forecast']))\n",
    "\n",
    "    # Scale the 'Model forecast' by the ratio of maximum absolute values\n",
    "    multiply1 = max1 / max2\n",
    "\n",
    "    multiply2 = min1 / min2\n",
    "\n",
    "    multiply = (multiply1 + multiply2) / 2.0\n",
    "\n",
    "    # Return the modified DataFrame\n",
    "    return diff, multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refit_output(df, diff, multiply):\n",
    "    # Adjust the 'Model forecast' by subtracting the difference in means\n",
    "    df[\"Model forecast\"] = df[\"Model forecast\"] - diff\n",
    "    df[\"Model forecast\"] = df[\"Model forecast\"] * multiply\n",
    "\n",
    "    # Calculate the median of 'target_error_lead_0' and 'Model forecast'\n",
    "    mean3 = st.median(df[\"target_error_lead_0\"])\n",
    "    mean4 = st.median(df[\"Model forecast\"])\n",
    "\n",
    "    # Center both 'target_error_lead_0' and 'Model forecast' by subtracting their medians\n",
    "    df[\"target_error_lead_0\"] = df[\"target_error_lead_0\"] - mean3\n",
    "    df[\"Model forecast\"] = df[\"Model forecast\"] - mean4\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_diffs = full_df[\"true_diff\"].values.tolist()\n",
    "# del true_diffs[-1]\n",
    "true_diffs.append(0)\n",
    "ldf[\"true_diff\"] = true_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_index = ldf['true_diff'].idxmax()\n",
    "# beta = ldf['target_error_lead_0'].loc[max_index] / ldf['true_diff'].loc[max_index]\n",
    "\n",
    "beta = max(ldf[\"true_diff\"]) / max(ldf[\"target_error_lead_0\"])\n",
    "\n",
    "print(beta)\n",
    "\n",
    "for c in ldf.columns:\n",
    "    print(c)\n",
    "    if c == \"true_diff\" or c == \"valid_time\":\n",
    "        continue\n",
    "    else:\n",
    "        ldf[c] = beta * ldf[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf[\"diff\"] = ldf.iloc[:, 0] - ldf.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = ldf[\"Model forecast\"].values.tolist()  # Convert to a Python list\n",
    "# differences.append(0)\n",
    "del differences[-1]\n",
    "full_df[\"diff\"] = differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = st.mean(abs(ldf[\"diff\"]))\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_s = st.mean(ldf[\"diff\"] ** 2)\n",
    "mean_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ml_output(ldf, full_df, 4, station, test_set_start, test_set_finish, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\"reforecast\"] = full_df[f\"u_total_{station}\"] - full_df[\"diff\"]\n",
    "full_df[\"reforecast\"] = full_df[\"reforecast\"].apply(lambda x: max(x, 0))\n",
    "met_output(full_df, \"VOOR\", fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in full_df.columns:\n",
    "    if re.search(\n",
    "        f\"{station}|valid|Model forecast|Abs_err\",\n",
    "        k,\n",
    "    ):\n",
    "        continue\n",
    "    else:\n",
    "        full_df = full_df.drop(columns=[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_len = int(len(full_df['valid_time'])*0.2)\n",
    "# full_df = full_df.iloc[0:test_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_month(df, col):\n",
    "    df = df[df[col] > -999]\n",
    "    GB = df.groupby([(df.valid_time.dt.month), (df.valid_time.dt.year)])[col].mean()\n",
    "    the_list = GB.tolist()\n",
    "    fig, ax = plt.subplots(figsize=(21, 6))\n",
    "    x = np.arange(1, len(the_list) + 1)\n",
    "    plt.bar(x, the_list)\n",
    "    ax.set_xticklabels([2018, 2019, 2020, 2021, 2022, 2023])\n",
    "    ax.set_xticks(np.arange(1, len(the_list) + 1, int((len(the_list) + 1) / 6)))\n",
    "    return the_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_hexbin_heatmap(ldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_scatterplot_heatmap(ldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_heatmap(ldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_by_month = groupby_month(ldf, \"diff\")\n",
    "err_by_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_time(df, col):\n",
    "    df = df[df[col] > -999]\n",
    "    GB = df.groupby([(df.valid_time.dt.hour)])[col].mean()\n",
    "    the_list = GB.tolist()\n",
    "    fig, ax = plt.subplots(figsize=(21, 6))\n",
    "    x = np.arange(0, len(the_list))\n",
    "    plt.bar(x, the_list, color=\"g\")\n",
    "    return the_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_by_time = groupby_time(ldf, \"diff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "\n",
    "def groupby_month_total(df, col):\n",
    "    df = df[df[col] > -999]\n",
    "    GB = df.groupby([(df.valid_time.dt.month)])[col].mean()\n",
    "    the_list = GB.tolist()\n",
    "    fig, ax = plt.subplots(figsize=(21, 6))\n",
    "    x = np.arange(0, len(the_list))\n",
    "\n",
    "    # Get a colormap\n",
    "    cmap = plt.get_cmap(\"RdBu\")\n",
    "    # Normalize your data to map to the colormap\n",
    "    norm = plt.Normalize(min(the_list), max(the_list))\n",
    "    colors = cmap(norm(the_list))\n",
    "\n",
    "    # Create a bar chart\n",
    "    plt.bar(x, the_list, color=colors)\n",
    "    ax.set_xticks(x)  # Set x-ticks to be at the positions of the months\n",
    "    month_labels = [calendar.month_name[month] for month in GB.index]\n",
    "    ax.set_xticklabels(month_labels)  # Label x-ticks with month numbers\n",
    "\n",
    "    plt.show()\n",
    "    return the_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_month_total(ldf, \"diff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myround(x, base):\n",
    "    return base * round(x / base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get unique values\n",
    "def unique(list1):\n",
    "    # initialize a null list\n",
    "    unique_list = []\n",
    "\n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_bucket(full_df, met_col, rounded_base):\n",
    "    temps = []\n",
    "    for i, _ in enumerate(full_df[met_col]):\n",
    "        rounded = myround(full_df[met_col].iloc[i], rounded_base)\n",
    "        temps.append(rounded)\n",
    "\n",
    "    unique_temps = unique(temps)\n",
    "\n",
    "    zeros = np.zeros(len(unique_temps))\n",
    "    rs = np.resize(zeros, (len(unique_temps), len(unique_temps)))\n",
    "\n",
    "    temp_df = pd.DataFrame(\n",
    "        data=rs, index=[np.arange(len(unique_temps))], columns=sorted(unique_temps)\n",
    "    )\n",
    "\n",
    "    for i, _ in enumerate(full_df[met_col]):\n",
    "        rounded = myround(full_df[met_col].iloc[i], rounded_base)\n",
    "        err = full_df[\"Abs_err\"].iloc[i]\n",
    "        temp_df[rounded].iloc[0] = abs(err) + abs(temp_df[rounded].iloc[0])\n",
    "        temp_df[rounded].iloc[-1] += 1\n",
    "\n",
    "    instances = temp_df.iloc[-1]\n",
    "    temp_df = temp_df.iloc[0]\n",
    "\n",
    "    return temp_df, instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_buckets(temp_df, instances, var_name, cmap, width):\n",
    "    my_cmap = plt.get_cmap(cmap)\n",
    "    averages = temp_df / instances\n",
    "    y = averages\n",
    "    rescale = lambda y: (y - np.min(y)) / (np.max(y) - np.min(y))\n",
    "    the_list = averages.tolist()\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(21, 6), facecolor=\"slategrey\", constrained_layout=True\n",
    "    )\n",
    "    bars = plt.bar(temp_df.keys(), the_list, color=my_cmap(rescale(y)), width=width)\n",
    "    ax.set_title(\"Absolute Error of LSTM\", fontsize=28, c=\"white\")\n",
    "    ax.set_xlabel(var_name, fontsize=18, c=\"white\")\n",
    "    ax.set_ylabel(\"Mean Absolute Error\", fontsize=18, c=\"white\")\n",
    "    # Iterating over the bars one-by-one\n",
    "    # Annotate each bar with its value\n",
    "    # Annotate each bar with the number of instances\n",
    "    for bar, value, instance_count in zip(bars, the_list, instances):\n",
    "        yval = value + 0.01  # Adjust the vertical position of the label\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            yval,\n",
    "            f\"n={instance_count}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            color=\"black\",\n",
    "            fontsize=12,\n",
    "            rotation=90,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in full_df.keys():\n",
    "#     print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diector = sorted(os.listdir('/home/aevans/nwp_bias/src/machine_learning/data/lstm_eval_csvs/20231129/'))\n",
    "\n",
    "# for d in diector:\n",
    "#         full_df = pd.read_parquet(\n",
    "#         f\"/home/aevans/nwp_bias/src/machine_learning/data/lstm_eval_csvs/20231129/{d}\"\n",
    "#     )\n",
    "#         for k in full_df.columns:\n",
    "#             if re.search(\n",
    "#                 f\"{station}\",\n",
    "#                 k,\n",
    "#             ):\n",
    "#                 print(\"Succes!!\")\n",
    "#                 print(d)\n",
    "#             else:\n",
    "#                 continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index for both DataFrames to ensure alignment\n",
    "full_df = full_df.reset_index(drop=True)\n",
    "ldf = ldf.reset_index(drop=True)\n",
    "full_df[\"Abs_err\"] = ldf[\"diff\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df, instances = err_bucket(full_df, f\"tair_{station}\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_buckets(temp_df, instances, \"Temperature (C)\", \"Wistia\", 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relh_df, instances = err_bucket(full_df, f\"relh_{station}\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_buckets(relh_df, instances, \"Relative Humidity (%)\", \"copper\", 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df, instances = err_bucket(full_df, f\"srad_{station}\", 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_buckets(new_df, instances, \"Solar Radiation (W / m*m)\", \"copper\", 50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_df, instances = err_bucket(full_df, f\"pres_{station}\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The mean pressure at {station} is {full_df[f\"pres_{station}\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_buckets(pres_df, instances, \"Surface Pressure (mb)\", \"copper\", 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_small(full_df, met_col, rounded_base):\n",
    "    temps = []\n",
    "    for i, _ in enumerate(full_df[met_col]):\n",
    "        if full_df[met_col].iloc[i] < 1.0 and full_df[met_col].iloc[i] >= 0:\n",
    "            rounded = round(full_df[met_col].iloc[i], rounded_base)\n",
    "            temps.append(rounded)\n",
    "        else:\n",
    "            rounded = myround(full_df[met_col].iloc[i], 1)\n",
    "            temps.append(rounded)\n",
    "\n",
    "    unique_temps = unique(temps)\n",
    "\n",
    "    zeros = np.zeros(len(unique_temps))\n",
    "    rs = np.resize(zeros, (len(unique_temps), len(unique_temps)))\n",
    "    temp_df = pd.DataFrame(\n",
    "        data=rs, index=[np.arange(len(unique_temps))], columns=sorted(unique_temps)\n",
    "    )\n",
    "\n",
    "    for i, _ in enumerate(full_df[met_col]):\n",
    "        if full_df[met_col].iloc[i] < 1.0 and full_df[met_col].iloc[i] >= 0:\n",
    "            rounded = round(full_df[met_col].iloc[i], rounded_base)\n",
    "        else:\n",
    "            rounded = float(myround(full_df[met_col].iloc[i], base=1))\n",
    "        err = float(full_df[\"Abs_err\"].iloc[i])\n",
    "        temp_df[rounded].iloc[0] = abs(err) + abs(temp_df[rounded].iloc[0])\n",
    "        temp_df[rounded].iloc[-1] += 1\n",
    "\n",
    "    instances = temp_df.iloc[-1]\n",
    "    temp_df = temp_df.iloc[0]\n",
    "    temp_df = temp_df.loc[~(temp_df == 0)]\n",
    "    instances = instances.loc[~(instances == 0)]\n",
    "    return temp_df, instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_df, instances = err_bucket(full_df, f\"precip_total_{station}\", 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_buckets(rain_df, instances, \"Precipitation [mm/hr]\", \"winter\", 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_df, instances = round_small(full_df, f\"snow_depth_{station}\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_df = snow_df.iloc[1:]\n",
    "instances = instances.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_buckets(snow_df, instances, \"Accumulated Snow (m)\", \"cool\", 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmax, instances = err_bucket(full_df, f\"wmax_sonic_{station}\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_buckets(wmax, instances, \"Wind Max (m/s)\", \"copper\", 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdir, instances = err_bucket(full_df, f\"wdir_sonic_{station}\", 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_buckets(wdir, instances, \"Wind Dir (degrees)\", \"copper\", 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44818f36aeaf89db1a1d21a2bee6031a28b4e41595a65903b38b9b0c4417365f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
