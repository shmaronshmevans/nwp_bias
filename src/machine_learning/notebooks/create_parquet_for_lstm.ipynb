{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "# instead of creating a package using setup.py or building from a docker/singularity file,\n",
    "# import the sister directory of src code to be called on in notebook.\n",
    "# This keeps the notebook free from code to only hold visualizations and is easier to test\n",
    "# It also helps keep the state of variables clean such that cells aren't run out of order with a mysterious state\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import log_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import os\n",
    "import datetime as dt\n",
    "import xarray as xr\n",
    "import glob\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flag(hrrr_df):\n",
    "    stations_ls = hrrr_df[\"station\"].unique()\n",
    "    one_hour = dt.timedelta(hours=1)\n",
    "    flag_ls = []\n",
    "\n",
    "    for station in stations_ls:\n",
    "        df = hrrr_df[hrrr_df[\"station\"] == station]\n",
    "        time_ls = df[\"valid_time\"].tolist()\n",
    "        for now, then in zip(time_ls, time_ls[1:]):\n",
    "            if now + one_hour == then:\n",
    "                flag_ls.append(False)\n",
    "            else:\n",
    "                flag_ls.append(True)\n",
    "\n",
    "    flag_ls.append(False)\n",
    "    hrrr_df[\"flag\"] = flag_ls\n",
    "\n",
    "    return hrrr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hrrr_data():\n",
    "    \"\"\"\n",
    "    Reads and concatenates parquet files containing forecast and error data for HRRR weather models\n",
    "    for the years 2018 to 2022.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: of hrrr weather forecast information for each NYSM site.\n",
    "    \"\"\"\n",
    "\n",
    "    years = [\"2018\", \"2019\"]\n",
    "    savedir = \"/home/aevans/ai2es/processed_data/HRRR/ny/\"\n",
    "\n",
    "    # create empty lists to hold dataframes for each model\n",
    "    hrrr_fcast_and_error = []\n",
    "\n",
    "    # loop over years and read in parquet files for each model\n",
    "    for year in years:\n",
    "        for month in np.arange(1, 13):\n",
    "            str_month = str(month).zfill(2)\n",
    "            if (\n",
    "                os.path.exists(\n",
    "                    f\"{savedir}HRRR_{year}_{str_month}_direct_compare_to_nysm_sites_mask_water.parquet\"\n",
    "                )\n",
    "                == True\n",
    "            ):\n",
    "                hrrr_fcast_and_error.append(\n",
    "                    pd.read_parquet(\n",
    "                        f\"{savedir}HRRR_{year}_{str_month}_direct_compare_to_nysm_sites_mask_water.parquet\"\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    # concatenate dataframes for each model\n",
    "    hrrr_fcast_and_error_df = pd.concat(hrrr_fcast_and_error)\n",
    "    hrrr_fcast_and_error_df = hrrr_fcast_and_error_df.reset_index().dropna()\n",
    "\n",
    "    # return dataframes for each model\n",
    "    return hrrr_fcast_and_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gfs_data(fh):\n",
    "    \"\"\"\n",
    "    Reads and concatenates parquet files containing forecast and error data for HRRR weather models\n",
    "    for the years 2018 to 2022.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: of hrrr weather forecast information for each NYSM site.\n",
    "    \"\"\"\n",
    "\n",
    "    years = [\"2018\", \"2019\"]\n",
    "    savedir = f\"/home/aevans/nwp_bias/src/machine_learning/data/gfs_data/fh{fh}/\"\n",
    "\n",
    "    # create empty lists to hold dataframes for each model\n",
    "    gfs_fcast_and_error = []\n",
    "\n",
    "    # loop over years and read in parquet files for each model\n",
    "    for year in years:\n",
    "        for month in np.arange(1, 13):\n",
    "            str_month = str(month).zfill(2)\n",
    "            if (\n",
    "                os.path.exists(\n",
    "                    f\"{savedir}GFS_{year}_{str_month}_direct_compare_to_nysm_sites_mask_water.parquet\"\n",
    "                )\n",
    "                == True\n",
    "            ):\n",
    "                gfs_fcast_and_error.append(\n",
    "                    pd.read_parquet(\n",
    "                        f\"{savedir}GFS_{year}_{str_month}_direct_compare_to_nysm_sites_mask_water.parquet\"\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    # concatenate dataframes for each model\n",
    "    gfs_fcast_and_error_df = pd.concat(gfs_fcast_and_error)\n",
    "\n",
    "    # return dataframes for each model\n",
    "    return gfs_fcast_and_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tabular(hrrr_df, geo_df, suffix):\n",
    "    geo_keys = geo_df.keys()\n",
    "\n",
    "    for i, _ in enumerate(geo_df[\"station\"]):\n",
    "        for k in geo_keys:\n",
    "            hrrr_df.loc[\n",
    "                hrrr_df[\"station\"] == geo_df[\"station\"].iloc[i], f\"{k}_{suffix}\"\n",
    "            ] = geo_df[k].iloc[i]\n",
    "\n",
    "    return hrrr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data, col, max_val):\n",
    "    data[col + \"_sin\"] = np.sin(2 * np.pi * data[col] / max_val)\n",
    "    data[col + \"_cos\"] = np.cos(2 * np.pi * data[col] / max_val)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flag():\n",
    "    stations_ls = hrrr_df[\"station\"].unique()\n",
    "    one_hour = dt.timedelta(hours=1)\n",
    "    flag_ls = []\n",
    "\n",
    "    for station in stations_ls:\n",
    "        df = hrrr_df[hrrr_df[\"station\"] == station]\n",
    "        time_ls = df[\"valid_time\"].tolist()\n",
    "        for now, then in zip(time_ls, time_ls[1:]):\n",
    "            if now + one_hour == then:\n",
    "                flag_ls.append(False)\n",
    "            else:\n",
    "                flag_ls.append(True)\n",
    "\n",
    "    flag_ls.append(False)\n",
    "    hrrr_df[\"flag\"] = flag_ls\n",
    "\n",
    "    return hrrr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nysm_data():\n",
    "    # these parquet files are created by running \"get_resampled_nysm_data.ipynb\"\n",
    "    nysm_path = \"/home/aevans/nwp_bias/data/nysm/\"\n",
    "\n",
    "    nysm_1H = []\n",
    "    for year in np.arange(2018, 2020):\n",
    "        df = pd.read_parquet(f\"{nysm_path}nysm_1H_obs_{year}.parquet\")\n",
    "        df.reset_index(inplace=True)\n",
    "        nysm_1H.append(df)\n",
    "    nysm_1H_obs = pd.concat(nysm_1H)\n",
    "    nysm_1H_obs = nysm_1H_obs.dropna()\n",
    "    return nysm_1H_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\n",
    "    \"/home/aevans/nwp_bias/src/machine_learning/data/gfs_data/fh096/GFS_2018_04_direct_compare_to_nysm_sites_mask_water.parquet\"\n",
    ")\n",
    "df = df[df[\"station\"] == \"ADDI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>t2m</th>\n",
       "      <th>sh2</th>\n",
       "      <th>d2m</th>\n",
       "      <th>r2</th>\n",
       "      <th>u10</th>\n",
       "      <th>v10</th>\n",
       "      <th>u_total</th>\n",
       "      <th>...</th>\n",
       "      <th>cin</th>\n",
       "      <th>dswrf</th>\n",
       "      <th>dlwrf</th>\n",
       "      <th>gh</th>\n",
       "      <th>station</th>\n",
       "      <th>valid_time</th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>lead time</th>\n",
       "      <th>landn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-05 00:00:00</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>42.040359</td>\n",
       "      <td>-77.237259</td>\n",
       "      <td>-1.752735</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>-6.954848</td>\n",
       "      <td>67.564892</td>\n",
       "      <td>5.995449</td>\n",
       "      <td>-2.795196</td>\n",
       "      <td>6.619442</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.468936</td>\n",
       "      <td>318.268707</td>\n",
       "      <td>270.169617</td>\n",
       "      <td>5356.411487</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>2018-04-05 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05 06:00:00</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>42.040359</td>\n",
       "      <td>-77.237259</td>\n",
       "      <td>-5.363739</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>-11.119905</td>\n",
       "      <td>64.677582</td>\n",
       "      <td>5.555916</td>\n",
       "      <td>-3.149315</td>\n",
       "      <td>6.388231</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>213.278107</td>\n",
       "      <td>5322.060792</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>2018-04-05 06:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05 12:00:00</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>42.040359</td>\n",
       "      <td>-77.237259</td>\n",
       "      <td>-4.024001</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>-10.930130</td>\n",
       "      <td>59.089184</td>\n",
       "      <td>5.982168</td>\n",
       "      <td>-1.221361</td>\n",
       "      <td>6.114904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.730127</td>\n",
       "      <td>9.009796</td>\n",
       "      <td>213.887024</td>\n",
       "      <td>5274.619798</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>2018-04-05 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05 18:00:00</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>42.040359</td>\n",
       "      <td>-77.237259</td>\n",
       "      <td>1.377793</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>-10.085236</td>\n",
       "      <td>42.544949</td>\n",
       "      <td>8.165777</td>\n",
       "      <td>1.145828</td>\n",
       "      <td>8.254450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444458</td>\n",
       "      <td>493.516998</td>\n",
       "      <td>264.384003</td>\n",
       "      <td>5311.288021</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>2018-04-05 18:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06 00:00:00</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>42.040359</td>\n",
       "      <td>-77.237259</td>\n",
       "      <td>-0.905446</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>-8.681306</td>\n",
       "      <td>55.739490</td>\n",
       "      <td>3.067875</td>\n",
       "      <td>-0.107490</td>\n",
       "      <td>3.070001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490723</td>\n",
       "      <td>430.501312</td>\n",
       "      <td>222.139862</td>\n",
       "      <td>5358.655597</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>2018-04-06 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03 18:00:00</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>42.040359</td>\n",
       "      <td>-77.237259</td>\n",
       "      <td>21.573272</td>\n",
       "      <td>0.012757</td>\n",
       "      <td>17.143937</td>\n",
       "      <td>75.596592</td>\n",
       "      <td>5.580210</td>\n",
       "      <td>5.001514</td>\n",
       "      <td>7.504849</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.715625</td>\n",
       "      <td>482.678619</td>\n",
       "      <td>369.579315</td>\n",
       "      <td>5783.877796</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>2018-05-03 18:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-04 00:00:00</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>42.040359</td>\n",
       "      <td>-77.237259</td>\n",
       "      <td>17.415724</td>\n",
       "      <td>0.012409</td>\n",
       "      <td>16.692720</td>\n",
       "      <td>95.259930</td>\n",
       "      <td>4.672379</td>\n",
       "      <td>0.472822</td>\n",
       "      <td>4.718947</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.032837</td>\n",
       "      <td>122.151764</td>\n",
       "      <td>394.838562</td>\n",
       "      <td>5778.286235</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>2018-05-04 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-04 06:00:00</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>42.040359</td>\n",
       "      <td>-77.237259</td>\n",
       "      <td>14.796630</td>\n",
       "      <td>0.010754</td>\n",
       "      <td>14.438827</td>\n",
       "      <td>97.633713</td>\n",
       "      <td>1.222315</td>\n",
       "      <td>1.447019</td>\n",
       "      <td>1.917787</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.723877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>338.283325</td>\n",
       "      <td>5753.355619</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>2018-05-04 06:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-04 12:00:00</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>42.040359</td>\n",
       "      <td>-77.237259</td>\n",
       "      <td>16.759781</td>\n",
       "      <td>0.011877</td>\n",
       "      <td>15.879318</td>\n",
       "      <td>95.194820</td>\n",
       "      <td>3.955989</td>\n",
       "      <td>4.084792</td>\n",
       "      <td>5.884556</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.076504</td>\n",
       "      <td>3.098694</td>\n",
       "      <td>377.799011</td>\n",
       "      <td>5745.660430</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>2018-05-04 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-04 18:00:00</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>42.040359</td>\n",
       "      <td>-77.237259</td>\n",
       "      <td>22.060593</td>\n",
       "      <td>0.012266</td>\n",
       "      <td>16.373825</td>\n",
       "      <td>70.388214</td>\n",
       "      <td>8.462535</td>\n",
       "      <td>5.378139</td>\n",
       "      <td>10.028723</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.316101</td>\n",
       "      <td>407.866577</td>\n",
       "      <td>376.242157</td>\n",
       "      <td>5732.136821</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>2018-05-04 18:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          time   latitude  longitude        t2m       sh2  \\\n",
       "2018-04-05 00:00:00 2018-04-01  42.040359 -77.237259  -1.752735  0.002370   \n",
       "2018-04-05 06:00:00 2018-04-01  42.040359 -77.237259  -5.363739  0.001702   \n",
       "2018-04-05 12:00:00 2018-04-01  42.040359 -77.237259  -4.024001  0.001730   \n",
       "2018-04-05 18:00:00 2018-04-01  42.040359 -77.237259   1.377793  0.001858   \n",
       "2018-04-06 00:00:00 2018-04-01  42.040359 -77.237259  -0.905446  0.002078   \n",
       "...                        ...        ...        ...        ...       ...   \n",
       "2018-05-03 18:00:00 2018-04-01  42.040359 -77.237259  21.573272  0.012757   \n",
       "2018-05-04 00:00:00 2018-04-01  42.040359 -77.237259  17.415724  0.012409   \n",
       "2018-05-04 06:00:00 2018-04-01  42.040359 -77.237259  14.796630  0.010754   \n",
       "2018-05-04 12:00:00 2018-04-01  42.040359 -77.237259  16.759781  0.011877   \n",
       "2018-05-04 18:00:00 2018-04-01  42.040359 -77.237259  22.060593  0.012266   \n",
       "\n",
       "                           d2m         r2       u10       v10    u_total  ...  \\\n",
       "2018-04-05 00:00:00  -6.954848  67.564892  5.995449 -2.795196   6.619442  ...   \n",
       "2018-04-05 06:00:00 -11.119905  64.677582  5.555916 -3.149315   6.388231  ...   \n",
       "2018-04-05 12:00:00 -10.930130  59.089184  5.982168 -1.221361   6.114904  ...   \n",
       "2018-04-05 18:00:00 -10.085236  42.544949  8.165777  1.145828   8.254450  ...   \n",
       "2018-04-06 00:00:00  -8.681306  55.739490  3.067875 -0.107490   3.070001  ...   \n",
       "...                        ...        ...       ...       ...        ...  ...   \n",
       "2018-05-03 18:00:00  17.143937  75.596592  5.580210  5.001514   7.504849  ...   \n",
       "2018-05-04 00:00:00  16.692720  95.259930  4.672379  0.472822   4.718947  ...   \n",
       "2018-05-04 06:00:00  14.438827  97.633713  1.222315  1.447019   1.917787  ...   \n",
       "2018-05-04 12:00:00  15.879318  95.194820  3.955989  4.084792   5.884556  ...   \n",
       "2018-05-04 18:00:00  16.373825  70.388214  8.462535  5.378139  10.028723  ...   \n",
       "\n",
       "                           cin       dswrf       dlwrf           gh  station  \\\n",
       "2018-04-05 00:00:00  -1.468936  318.268707  270.169617  5356.411487     ADDI   \n",
       "2018-04-05 06:00:00  -0.113953    0.000000  213.278107  5322.060792     ADDI   \n",
       "2018-04-05 12:00:00  -0.730127    9.009796  213.887024  5274.619798     ADDI   \n",
       "2018-04-05 18:00:00   0.444458  493.516998  264.384003  5311.288021     ADDI   \n",
       "2018-04-06 00:00:00   0.490723  430.501312  222.139862  5358.655597     ADDI   \n",
       "...                        ...         ...         ...          ...      ...   \n",
       "2018-05-03 18:00:00  -0.715625  482.678619  369.579315  5783.877796     ADDI   \n",
       "2018-05-04 00:00:00 -10.032837  122.151764  394.838562  5778.286235     ADDI   \n",
       "2018-05-04 06:00:00 -32.723877    0.000000  338.283325  5753.355619     ADDI   \n",
       "2018-05-04 12:00:00 -56.076504    3.098694  377.799011  5745.660430     ADDI   \n",
       "2018-05-04 18:00:00  -2.316101  407.866577  376.242157  5732.136821     ADDI   \n",
       "\n",
       "                             valid_time  level_0  index  lead time  landn  \n",
       "2018-04-05 00:00:00 2018-04-05 00:00:00      0.0    0.0        0.0    0.0  \n",
       "2018-04-05 06:00:00 2018-04-05 06:00:00      0.0    0.0        0.0    0.0  \n",
       "2018-04-05 12:00:00 2018-04-05 12:00:00      0.0    0.0        0.0    0.0  \n",
       "2018-04-05 18:00:00 2018-04-05 18:00:00      0.0    0.0        0.0    0.0  \n",
       "2018-04-06 00:00:00 2018-04-06 00:00:00      0.0    0.0        0.0    0.0  \n",
       "...                                 ...      ...    ...        ...    ...  \n",
       "2018-05-03 18:00:00 2018-05-03 18:00:00      0.0    0.0        0.0    0.0  \n",
       "2018-05-04 00:00:00 2018-05-04 00:00:00      0.0    0.0        0.0    0.0  \n",
       "2018-05-04 06:00:00 2018-05-04 06:00:00      0.0    0.0        0.0    0.0  \n",
       "2018-05-04 12:00:00 2018-05-04 12:00:00      0.0    0.0        0.0    0.0  \n",
       "2018-05-04 18:00:00 2018-05-04 18:00:00      0.0    0.0        0.0    0.0  \n",
       "\n",
       "[117 rows x 26 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_hr = 6\n",
    "stations = [\"a\", \"b\", \"c\", \"d\"]\n",
    "X = df.iloc[0:10].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X\n",
    "x.shape\n",
    "x[: int(forecast_hr / 3), -10:] = x[int(forecast_hr / 3), -int(10) :]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[: int(forecast_hr / 3), -10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[int(forecast_hr / 3), -int(10) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_nysm_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs_df = read_gfs_data(\"003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs_df[\"station\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"station\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df = df.rename(columns={\"time_1H\": \"valid_time\"})\n",
    "mytimes = hrrr_df[\"valid_time\"].tolist()\n",
    "# nysm_df = df[df['valid_time'].isin(mytimes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrrr_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_cats_path = \"/home/aevans/nwp_bias/src/landtype/data/nysm.csv\"\n",
    "nlcd_path = \"/home/aevans/nwp_bias/src/correlation/data/nlcd_nam.csv\"\n",
    "aspect_path = \"/home/aevans/nwp_bias/src/correlation/data/aspect_nam.csv\"\n",
    "elev_path = \"/home/aevans/nwp_bias/src/correlation/data/elev_nam.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlcd_df = pd.read_csv(nlcd_path)\n",
    "aspect_df = pd.read_csv(aspect_path)\n",
    "elev_df = pd.read_csv(elev_path)\n",
    "nysm_cats_df = pd.read_csv(nysm_cats_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_cats_df[\"climate_division_name\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = nysm_cats_df[\"climate_division\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_cats_df1 = nysm_cats_df[nysm_cats_df[\"climate_division\"] == cats[0]]\n",
    "category_name = nysm_cats_df1[\"climate_division_name\"].unique()[0]\n",
    "stations = nysm_cats_df1[\"stid\"].tolist()\n",
    "hrrr_df1 = hrrr_df[hrrr_df[\"station\"].isin(stations)]\n",
    "nysm_df1 = df[df[\"station\"].isin(stations)]\n",
    "\n",
    "master_df = hrrr_df1.merge(nysm_df1, on=\"valid_time\", suffixes=(None, \"_nysm\"))\n",
    "# master_df['day_of_year'] = master_df['valid_time'].dt.dayofyear\n",
    "# master_df = encode(master_df, 'day_of_year', 366)\n",
    "# master_df = add_tabular(master_df, nlcd_df, 'nlcd')\n",
    "# master_df = add_tabular(master_df, aspect_df, 'aspect')\n",
    "# master_df = add_tabular(master_df, elev_df, 'elev')\n",
    "\n",
    "# master_df.to_parquet(f'/home/aevans/nwp_bias/src/machine_learning/data/rough_parquets/rough_lstm_nysmcat_{category_name}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrrr = pd.read_parquet(\"/home/aevans/ai2es/lstm/fh_04/2022/20220101_hrrr_fh04.parquet\")\n",
    "hrrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.drop_duplicates(\n",
    "    subset=[\"valid_time\", \"station\", \"t2m\"], keep=\"first\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hrrr_df = read_hrrr_data()\n",
    "hrrr_df[\"day_of_year\"] = hrrr_df[\"valid_time\"].dt.dayofyear\n",
    "hrrr_df = encode(hrrr_df, \"day_of_year\", 366)\n",
    "hrrr_df = add_tabular(hrrr_df, nlcd_df, \"nlcd\")\n",
    "hrrr_df = add_tabular(hrrr_df, aspect_df, \"aspect\")\n",
    "hrrr_df = add_tabular(hrrr_df, elev_df, \"elev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_cats_df[\"climate_division_name\"].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_parquet(\n",
    "    \"/home/aevans/nwp_bias/src/machine_learning/data/rough_lstm_nysmcat_Western Plateau.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_keys = new_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in the_keys:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44818f36aeaf89db1a1d21a2bee6031a28b4e41595a65903b38b9b0c4417365f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
