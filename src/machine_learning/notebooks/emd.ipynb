{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "# instead of creating a package using setup.py or building from a docker/singularity file,\n",
    "# import the sister directory of src code to be called on in notebook.\n",
    "# This keeps the notebook free from code to only hold visualizations and is easier to test\n",
    "# It also helps keep the state of variables clean such that cells aren't run out of order with a mysterious state\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import emd\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from statistics import mean\n",
    "import statistics\n",
    "from dateutil.parser import parse\n",
    "import statistics as st\n",
    "\n",
    "from src.data import nysm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df = nysm_data.load_nysm_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_cats_path = \"/home/aevans/nwp_bias/src/landtype/data/nysm.csv\"\n",
    "\n",
    "nysm_cats_df = pd.read_csv(nysm_cats_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangles = nysm_cats_df[nysm_cats_df[\"stid\"] == \"VOOR\"]\n",
    "triangles = triangles[\"stid\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangles = [\n",
    "#     \"BSPA\",\n",
    "#     \"BUFF\",\n",
    "#     \"CROG\",\n",
    "#     \"ESSX\",\n",
    "#     \"GROT\",\n",
    "#     \"HARP\",\n",
    "#     \"HERK\",\n",
    "#     \"POTS\",\n",
    "#     \"RAND\",\n",
    "#     \"STON\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_nysm = nysm_df[nysm_df[\"station\"].isin(triangles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_nysm = triangle_nysm[triangle_nysm[\"time_1H\"] > datetime(2020, 8, 26, 7, 0, 0)]\n",
    "triangle_nysm = triangle_nysm[triangle_nysm[\"time_1H\"] < datetime(2020, 8, 29, 3, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_nysm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangle_nysm.to_csv(\n",
    "#     \"/home/aevans/nwp_bias/src/machine_learning/notebooks/nwp_nysm.csv\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_df = pd.DataFrame()\n",
    "# for i in np.arange(0, 5):\n",
    "#     df = pd.read_csv(\n",
    "#         f\"/home/aevans/nwp_bias/src/machine_learning/notebooks/bkln/bkln_{i}.csv\"\n",
    "#     )\n",
    "#     exp_df = pd.concat([df, exp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_stations = exp_df[\"station\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_stations = np.delete(my_stations, 0)\n",
    "# my_stations = np.delete(my_stations, 6)\n",
    "# my_stations = np.delete(my_stations, -3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_stations = triangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_df = exp_df.sort_values(\"forecast_hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bkln_df = exp_df[exp_df[\"station\"] == \"BKLN\"]\n",
    "# want_df = exp_df[exp_df[\"station\"] == \"WANT\"]\n",
    "# tyro_df = exp_df[exp_df[\"station\"] == \"TYRO\"]\n",
    "# wall_df = exp_df[exp_df[\"station\"] == \"WALL\"]\n",
    "# medu_df = exp_df[exp_df[\"station\"] == \"MEDU\"]\n",
    "# addi_df = exp_df[exp_df[\"station\"] == \"ADDI\"]\n",
    "# fred_df = exp_df[exp_df[\"station\"] == \"FRED\"]\n",
    "# ches_df = exp_df[exp_df[\"station\"] == \"CHES\"]\n",
    "# oppe_df = exp_df[exp_df[\"station\"] == \"OPPE\"]\n",
    "# gabr_df = exp_df[exp_df[\"station\"] == \"GABR\"]\n",
    "# loui_df = exp_df[exp_df[\"station\"] == \"LOUI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(24, 9))\n",
    "# plt.title(\"Forecast Hour Drift\", fontsize=28)\n",
    "# plt.xlabel(\"HRRR Forecast Hour\", fontsize=18)\n",
    "# plt.ylabel(\"Min Test Loss\", fontsize=18)\n",
    "# plt.xticks(fontsize=12)\n",
    "# plt.yticks(fontsize=12)\n",
    "\n",
    "# # stations\n",
    "# plt.plot(\n",
    "#     bkln_df[\"forecast_hour\"],\n",
    "#     bkln_df[\"test_loss (Min)\"],\n",
    "#     c=\"indigo\",\n",
    "#     marker=\"d\",\n",
    "#     markersize=12,\n",
    "#     linewidth=2,\n",
    "#     label=\"Brooklyn\",\n",
    "#     zorder=7,\n",
    "# )\n",
    "# plt.plot(\n",
    "#     want_df[\"forecast_hour\"],\n",
    "#     want_df[\"test_loss (Min)\"],\n",
    "#     c=\"olive\",\n",
    "#     marker=\"v\",\n",
    "#     markersize=12,\n",
    "#     linewidth=2,\n",
    "#     label=\"Wantagh\",\n",
    "#     zorder=7,\n",
    "#     alpha=0.4,\n",
    "# )\n",
    "# plt.plot(\n",
    "#     tyro_df[\"forecast_hour\"],\n",
    "#     tyro_df[\"test_loss (Min)\"],\n",
    "#     c=\"forestgreen\",\n",
    "#     marker=\"o\",\n",
    "#     markersize=12,\n",
    "#     linewidth=2,\n",
    "#     label=\"Tyrone\",\n",
    "#     zorder=7,\n",
    "#     alpha=0.4,\n",
    "# )\n",
    "# plt.plot(\n",
    "#     wall_df[\"forecast_hour\"],\n",
    "#     wall_df[\"test_loss (Min)\"],\n",
    "#     c=\"goldenrod\",\n",
    "#     marker=\"s\",\n",
    "#     markersize=12,\n",
    "#     linewidth=2,\n",
    "#     label=\"Wallkill\",\n",
    "#     zorder=7,\n",
    "#     alpha=0.4,\n",
    "# )\n",
    "# plt.plot(\n",
    "#     medu_df[\"forecast_hour\"],\n",
    "#     medu_df[\"test_loss (Min)\"],\n",
    "#     c=\"teal\",\n",
    "#     marker=\"^\",\n",
    "#     markersize=12,\n",
    "#     linewidth=2,\n",
    "#     label=\"Medusa\",\n",
    "#     zorder=7,\n",
    "#     alpha=0.4,\n",
    "# )\n",
    "# plt.plot(\n",
    "#     addi_df[\"forecast_hour\"],\n",
    "#     addi_df[\"test_loss (Min)\"],\n",
    "#     c=\"darkred\",\n",
    "#     marker=\"X\",\n",
    "#     markersize=12,\n",
    "#     linewidth=2,\n",
    "#     label=\"Addison\",\n",
    "#     zorder=7,\n",
    "#     alpha=1.0,\n",
    "# )\n",
    "# plt.plot(\n",
    "#     fred_df[\"forecast_hour\"],\n",
    "#     fred_df[\"test_loss (Min)\"],\n",
    "#     c=\"sienna\",\n",
    "#     marker=\"p\",\n",
    "#     markersize=12,\n",
    "#     linewidth=2,\n",
    "#     label=\"Fredonia\",\n",
    "#     zorder=7,\n",
    "#     alpha=0.4,\n",
    "# )\n",
    "# plt.plot(\n",
    "#     ches_df[\"forecast_hour\"],\n",
    "#     ches_df[\"test_loss (Min)\"],\n",
    "#     c=\"darkorange\",\n",
    "#     marker=\"P\",\n",
    "#     markersize=12,\n",
    "#     linewidth=2,\n",
    "#     label=\"Chestertown\",\n",
    "#     zorder=7,\n",
    "#     alpha=1.0,\n",
    "# )\n",
    "\n",
    "# plt.plot(\n",
    "#     oppe_df[\"forecast_hour\"],\n",
    "#     oppe_df[\"test_loss (Min)\"],\n",
    "#     c=\"royalblue\",\n",
    "#     marker=\"<\",\n",
    "#     markersize=12,\n",
    "#     linewidth=2,\n",
    "#     label=\"Oppenheim\",\n",
    "#     zorder=7,\n",
    "#     alpha=1.0,\n",
    "# )\n",
    "# plt.plot(\n",
    "#     gabr_df[\"forecast_hour\"],\n",
    "#     gabr_df[\"test_loss (Min)\"],\n",
    "#     c=\"violet\",\n",
    "#     marker=\">\",\n",
    "#     markersize=12,\n",
    "#     linewidth=2,\n",
    "#     label=\"Gabriels\",\n",
    "#     zorder=7,\n",
    "# )\n",
    "# plt.plot(\n",
    "#     loui_df[\"forecast_hour\"],\n",
    "#     loui_df[\"test_loss (Min)\"],\n",
    "#     c=\"deeppink\",\n",
    "#     marker=\"D\",\n",
    "#     markersize=12,\n",
    "#     linewidth=2,\n",
    "#     label=\"Louisville\",\n",
    "#     zorder=7,\n",
    "# )\n",
    "# plt.legend(bbox_to_anchor=(1.1, 1), loc=\"upper left\", borderaxespad=0, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(2, 19, 2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_cats_path = \"/home/aevans/nwp_bias/src/landtype/data/nysm.csv\"\n",
    "\n",
    "nysm_cats_df = pd.read_csv(nysm_cats_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangles = [\"BRON\", \"BUFF\", \"ANDE\", \"WALL\"]\n",
    "triangle = nysm_cats_df[nysm_cats_df[\"stid\"].isin(triangles)]\n",
    "\n",
    "triangle\n",
    "# # nysm_cats_df = nysm_cats_df[nysm_cats_df[\"stid\"].isin(my_stations)]\n",
    "# nysm_cats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ = nysm_cats_df[nysm_cats_df[\"climate_division_name\"] == \"Western Plateau\"]\n",
    "# my_stations = df_[\"stid\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_stations\n",
    "df_ = triangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "nwps_all = [0, 1, 2]\n",
    "nwps_after = [0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "for num in np.arange(1, 13):\n",
    "    # colors = [\n",
    "    #     \"forestgreen\",\n",
    "    #     \"olive\",\n",
    "    #     \"goldenrod\",\n",
    "    #     \"teal\",\n",
    "    #     \"darkred\",\n",
    "    #     \"indigo\",\n",
    "    #     \"sienna\",\n",
    "    #     \"darkorange\",\n",
    "    #     \"royalblue\",\n",
    "    #     # \"deeppink\",\n",
    "    #     \"violet\",\n",
    "    # ]\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    ax = fig.add_subplot(\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        projection=ccrs.LambertConformal(\n",
    "            central_longitude=-75.0, standard_parallels=(49, 77)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Replace 'your_shapefile.shp' with the path to your shapefile\n",
    "    shapefile_path = \"/home/aevans/nwp_bias/src/machine_learning/notebooks/data/GIS.OFFICIAL_CLIM_DIVISIONS.shp\"\n",
    "\n",
    "    # Read the shapefile\n",
    "    gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "    # Load the boundaries of New York State (replace with your actual file path)\n",
    "    ny_state_boundaries_path = \"/home/aevans/nwp_bias/src/landtype/data/State.shx\"\n",
    "\n",
    "    # Read the shapefile and set the CRS explicitly\n",
    "    ny_state_boundaries_geo = gpd.read_file(ny_state_boundaries_path).to_crs(epsg=4326)\n",
    "\n",
    "    # Get the bounding box of New York State\n",
    "    ny_bbox = ny_state_boundaries_geo.total_bounds\n",
    "\n",
    "    # Filter the GeoDataFrame to include only polygons within New York State\n",
    "    gdf_filtered = gdf.cx[ny_bbox[0] : ny_bbox[2], ny_bbox[1] : ny_bbox[3]]\n",
    "    gdf_filtered = gdf_filtered.iloc[20:29]\n",
    "\n",
    "    # Create a categorical column for coloring\n",
    "    gdf_filtered[\"category\"] = np.arange(len(gdf_filtered))\n",
    "\n",
    "    # Plot the shapefile with multiple colors based on the 'category' column\n",
    "    gdf_filtered.plot(\n",
    "        ax=ax, transform=ccrs.PlateCarree(), column=\"category\", cmap=\"tab10\", alpha=0.3\n",
    "    )\n",
    "\n",
    "    # Set extent for the plot\n",
    "    ax.set_extent([-75.0, -72.0, 40.0, 44.0], crs=ccrs.PlateCarree())\n",
    "\n",
    "    nwp_dict = {0: \"green\", 1: \"red\", 2: \"blue\"}\n",
    "\n",
    "    lister = []\n",
    "\n",
    "    # Randomly assign values from nwps_all to the 'lister'\n",
    "    lister = [random.choice(nwps_all) for _ in df_[\"stid\"]]\n",
    "    df_[\"color\"] = [nwp_dict[value] for value in lister]\n",
    "\n",
    "    # Add map features\n",
    "    ax.add_feature(cfeature.BORDERS.with_scale(\"50m\"), linestyle=\":\", zorder=1)\n",
    "    ax.add_feature(cfeature.STATES.with_scale(\"50m\"), linestyle=\":\", zorder=1)\n",
    "    ax.add_feature(cfeature.LAKES.with_scale(\"50m\"), zorder=1)\n",
    "    ax.gridlines(\n",
    "        crs=ccrs.PlateCarree(),\n",
    "        draw_labels=True,\n",
    "        linewidth=2,\n",
    "        color=\"black\",\n",
    "        alpha=0.5,\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "    ax.xticklabels_top = False\n",
    "    ax.ylabels_right = False\n",
    "\n",
    "    # Annotate scatter points with station IDs\n",
    "    for i, row in df_.iterrows():\n",
    "        lon, lat = row[\"lon [degrees]\"], row[\"lat [degrees]\"]\n",
    "        ax.annotate(\n",
    "            row[\"stid\"],\n",
    "            (lon, lat),\n",
    "            textcoords=\"offset points\",\n",
    "            xytext=(0, 7),\n",
    "            ha=\"center\",\n",
    "            fontsize=12,\n",
    "            color=\"black\",\n",
    "            transform=ccrs.PlateCarree(),\n",
    "        )\n",
    "\n",
    "    # Plot scatter points\n",
    "    for j, s in enumerate(triangles):\n",
    "        # df = nysm_cats_df[nysm_cats_df[\"stid\"] == s]\n",
    "        ax.scatter(\n",
    "            df_[\"lon [degrees]\"],\n",
    "            df_[\"lat [degrees]\"],\n",
    "            c=df_[\"color\"],\n",
    "            s=250,\n",
    "            edgecolors=\"black\",\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            zorder=10,\n",
    "            label=s,\n",
    "        )\n",
    "        j += 1\n",
    "\n",
    "    # Create custom legend\n",
    "    nam_patch = mpatches.Patch(color=\"green\", label=\"NAM\")\n",
    "    gfs_patch = mpatches.Patch(color=\"blue\", label=\"GFS\")\n",
    "    hrrr_patch = mpatches.Patch(color=\"red\", label=\"HRRR\")\n",
    "\n",
    "    # Add legend to the plot\n",
    "    plt.legend(\n",
    "        handles=[nam_patch, hrrr_patch, gfs_patch], loc=\"upper left\", fontsize=15\n",
    "    )\n",
    "    plt.title(f\"Hudson Valley Forecast Hour {num}\", fontsize=28)\n",
    "    plt.savefig(\n",
    "        f\"/home/aevans/nwp_bias/src/machine_learning/data/xCITE_gif/fh_{num}_voor.png\"\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need 0 row\n",
    "gdf_filtered_1 = gdf_filtered.iloc[20:30]\n",
    "gdf_filtered_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    projection=ccrs.LambertConformal(\n",
    "        central_longitude=-75.0, standard_parallels=(49, 77)\n",
    "    ),\n",
    ")\n",
    "# Plot the shapefile with multiple colors based on the 'category' column\n",
    "gdf_filtered_1.plot(\n",
    "    ax=ax, transform=ccrs.PlateCarree(), column=\"category\", cmap=\"gist_ncar\", alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import cartopy.crs as crs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# Replace 'ny_dem.tif' with the path to your downloaded DEM file\n",
    "ny_dem = \"/home/aevans/nwp_bias/src/landtype/data/Map.tif\"\n",
    "colors = [\n",
    "    \"forestgreen\",\n",
    "    \"olive\",\n",
    "    \"goldenrod\",\n",
    "    \"teal\",\n",
    "    \"darkred\",\n",
    "    \"indigo\",\n",
    "    \"sienna\",\n",
    "    \"darkorange\",\n",
    "    \"royalblue\",\n",
    "    \"violet\",\n",
    "    \"deeppink\",\n",
    "]\n",
    "j = 0\n",
    "\n",
    "skip = 5\n",
    "\n",
    "# Open the DEM file using rasterio\n",
    "with rasterio.open(ny_dem) as src:\n",
    "    elevation_data = src.read(\n",
    "        1\n",
    "    )  # Read the first band (assuming it's the elevation data)\n",
    "    elevation_transform = src.transform\n",
    "# Get the number of rows and columns in the elevation data\n",
    "rows, cols = elevation_data.shape\n",
    "\n",
    "# Create 2D arrays of coordinates using numpy.meshgrid\n",
    "lons, lats = np.meshgrid(\n",
    "    np.linspace(\n",
    "        elevation_transform[2],\n",
    "        elevation_transform[2] + cols * elevation_transform[0],\n",
    "        cols,\n",
    "    ),\n",
    "    np.linspace(\n",
    "        elevation_transform[5],\n",
    "        elevation_transform[5] + rows * elevation_transform[4],\n",
    "        rows,\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    projection=crs.LambertConformal(\n",
    "        central_longitude=-75.0, standard_parallels=(49, 77)\n",
    "    ),\n",
    ")\n",
    "\n",
    "# ax.add_feature(cfeature.LAND.with_scale('50m'), zorder=3)\n",
    "ax.add_feature(cfeature.OCEAN.with_scale(\"50m\"), zorder=1)\n",
    "ax.add_feature(cfeature.BORDERS.with_scale(\"50m\"), linestyle=\":\", zorder=1)\n",
    "ax.add_feature(cfeature.STATES.with_scale(\"50m\"), linestyle=\":\", zorder=1)\n",
    "ax.add_feature(cfeature.LAKES.with_scale(\"50m\"), zorder=1)\n",
    "ax.gridlines(\n",
    "    crs=crs.PlateCarree(),\n",
    "    draw_labels=True,\n",
    "    linewidth=2,\n",
    "    color=\"black\",\n",
    "    alpha=0.5,\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "ax.xticklabels_top = False\n",
    "ax.ylabels_right = False\n",
    "\n",
    "plt.contourf(\n",
    "    lons[::skip, ::skip],\n",
    "    lats[::skip, ::skip],\n",
    "    elevation_data[::skip, ::skip],\n",
    "    transform=crs.PlateCarree(),\n",
    "    levels=np.arange(0, 1500, 100),\n",
    "    cmap=\"gist_earth_r\",\n",
    "    zorder=0,\n",
    ")\n",
    "for s in my_stations:\n",
    "    df = nysm_cats_df[nysm_cats_df[\"stid\"] == s]\n",
    "    plt.scatter(\n",
    "        df[\"lon [degrees]\"],\n",
    "        df[\"lat [degrees]\"],\n",
    "        c=colors[j],\n",
    "        s=250,\n",
    "        edgecolors=\"black\",\n",
    "        transform=crs.PlateCarree(),\n",
    "        zorder=10,\n",
    "        label=s,\n",
    "    )\n",
    "    j += 1\n",
    "\n",
    "ax.set_extent([-79.82, -72.0, 40.48, 44.9])\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.legend(bbox_to_anchor=(1.1, 1), loc=\"upper left\", borderaxespad=0, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nysm_data():\n",
    "    # these parquet files are created by running \"get_resampled_nysm_data.ipynb\"\n",
    "    nysm_path = \"/home/aevans/nwp_bias/data/nysm/\"\n",
    "\n",
    "    nysm_1H = []\n",
    "    for year in np.arange(2018, 2023):\n",
    "        df = pd.read_parquet(f\"{nysm_path}nysm_1H_obs_{year}.parquet\")\n",
    "        df.reset_index(inplace=True)\n",
    "        nysm_1H.append(df)\n",
    "    nysm_1H_obs = pd.concat(nysm_1H)\n",
    "    nysm_1H_obs[\"snow_depth\"] = nysm_1H_obs[\"snow_depth\"].fillna(0)\n",
    "    nysm_1H_obs.fillna(-999, inplace=True)\n",
    "    return nysm_1H_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df = load_nysm_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = [\"ANDE\", \"BRON\", \"BUFF\", \"WALL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df = nysm_df[nysm_df[\"station\"].isin(stations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df = nysm_df[nysm_df[\"time_1H\"] > datetime(2020, 8, 26, 0, 0, 0)]\n",
    "nysm_df = nysm_df[nysm_df[\"time_1H\"] < datetime(2020, 8, 29, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weather(df, var):\n",
    "    fig, ax = plt.subplots(figsize=(12, 9))\n",
    "    ax.set_xlabel(f\"Time\", fontsize=18)\n",
    "    ax.set_ylabel(f\"{var} [m/s]\", fontsize=18)\n",
    "    ax.set_title(f\"{df['station'].iloc[0]}\", fontsize=24)\n",
    "    plt.ylim([0, 20])\n",
    "\n",
    "    plt.plot(df[\"time_1H\"], df[var], c=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_1 = nysm_df[nysm_df[\"station\"] == \"ANDE\"]\n",
    "temp_2 = nysm_df[nysm_df[\"station\"] == \"BUFF\"]\n",
    "temp_3 = nysm_df[nysm_df[\"station\"] == \"BRON\"]\n",
    "temp_4 = nysm_df[nysm_df[\"station\"] == \"WALL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weather(temp_1, \"wmax_sonic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weather(temp_2, \"wmax_sonic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weather(temp_3, \"wmax_sonic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weather(temp_4, \"wmax_sonic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hrrr_data():\n",
    "    \"\"\"\n",
    "    Reads and concatenates parquet files containing forecast and error data for HRRR weather models\n",
    "    for the years 2018 to 2022.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: of hrrr weather forecast information for each NYSM site.\n",
    "    \"\"\"\n",
    "\n",
    "    years = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]\n",
    "    savedir = \"/home/aevans/ai2es/processed_data/HRRR/ny/\"\n",
    "\n",
    "    # create empty lists to hold dataframes for each model\n",
    "    hrrr_fcast_and_error = []\n",
    "\n",
    "    # loop over years and read in parquet files for each model\n",
    "    for year in years:\n",
    "        for month in np.arange(1, 13):\n",
    "            str_month = str(month).zfill(2)\n",
    "            if (\n",
    "                os.path.exists(\n",
    "                    f\"{savedir}HRRR_{year}_{str_month}_direct_compare_to_nysm_sites_mask_water.parquet\"\n",
    "                )\n",
    "                == True\n",
    "            ):\n",
    "                hrrr_fcast_and_error.append(\n",
    "                    pd.read_parquet(\n",
    "                        f\"{savedir}HRRR_{year}_{str_month}_direct_compare_to_nysm_sites_mask_water.parquet\"\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    # concatenate dataframes for each model\n",
    "    hrrr_fcast_and_error_df = pd.concat(hrrr_fcast_and_error)\n",
    "    hrrr_fcast_and_error_df = hrrr_fcast_and_error_df.reset_index().dropna()\n",
    "\n",
    "    # return dataframes for each model\n",
    "    return hrrr_fcast_and_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def format_climate_df(data_path):\n",
    "    \"\"\"\n",
    "    Formats a climate data file located at the specified `data_path` into a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): The file path for the climate data file.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the climate data, with the first column renamed to \"year\".\n",
    "    \"\"\"\n",
    "    raw_index = np.loadtxt(f\"{data_path}\")\n",
    "    cl_index = pd.DataFrame(raw_index)\n",
    "    cl_index = cl_index.rename(columns={0: \"year\"})\n",
    "    return cl_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_month(df, col):\n",
    "    df = df[df[col] > -999]\n",
    "    GB = df.groupby([(df.valid_time.dt.year), (df.valid_time.dt.month)])[col].mean()\n",
    "    the_list = GB.tolist()\n",
    "    fig, ax = plt.subplots(figsize=(21, 6))\n",
    "    plt.plot(the_list)\n",
    "    ax.set_xticklabels([2018, 2019, 2020, 2021, 2022])\n",
    "    ax.set_xticks(np.arange(0, len(the_list), int(len(the_list) / 5)))\n",
    "    return the_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_month_hrrr(df, col):\n",
    "    df = df[df[col] > -999]\n",
    "    GB = df.groupby([(df.time.dt.year), (df.time.dt.month)])[col].mean()\n",
    "    the_list = GB.tolist()\n",
    "    fig, ax = plt.subplots(figsize=(21, 6))\n",
    "    plt.plot(the_list)\n",
    "    ax.set_xticklabels([2018, 2019, 2020, 2021, 2022])\n",
    "    ax.set_xticks(np.arange(0, 60, 12))\n",
    "    return the_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anoms_detection_hrrr(df, means, col):\n",
    "    anoms = []\n",
    "\n",
    "    for i, _ in enumerate(df[\"time\"]):\n",
    "        t = df[\"time\"].iloc[i]\n",
    "        tair = df[col].iloc[i]\n",
    "        dt_object = parse(str(t))\n",
    "        year = dt_object.strftime(\"%Y\")\n",
    "        month = dt_object.strftime(\"%m\")\n",
    "\n",
    "        for m in np.arange(1, 13):\n",
    "            if year == str(2018) and month == str(m).zfill(2):\n",
    "                new_means = means[:12]\n",
    "                anom = tair - new_means[m - 1]\n",
    "                anoms.append(anom)\n",
    "            if year == str(2019) and month == str(m).zfill(2):\n",
    "                new_means = means[12:24]\n",
    "                anom = tair - new_means[m - 1]\n",
    "                anoms.append(anom)\n",
    "            if year == str(2020) and month == str(m).zfill(2):\n",
    "                new_means = means[24:36]\n",
    "                anom = tair - new_means[m - 1]\n",
    "                anoms.append(anom)\n",
    "            if year == str(2021) and month == str(m).zfill(2):\n",
    "                new_means = means[36:48]\n",
    "                anom = tair - new_means[m - 1]\n",
    "                anoms.append(anom)\n",
    "            if year == str(2022) and month == str(m).zfill(2):\n",
    "                new_means = means[48:60]\n",
    "                anom = tair - new_means[m - 1]\n",
    "                anoms.append(anom)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(21, 7))\n",
    "    plt.plot(anoms, c=\"red\")\n",
    "    print(len(anoms))\n",
    "    ax.set_xticklabels([2018, 2019, 2020, 2021, 2022])\n",
    "    ax.set_xticks(np.arange(0, len(anoms), (len(anoms) / 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anoms_detection(df, means, col):\n",
    "    times = []\n",
    "    anoms = []\n",
    "\n",
    "    df = df[df[\"valid_time\"] > datetime(2022, 7, 20, 0, 0, 0)]\n",
    "    df = df[df[\"valid_time\"] < datetime(2022, 8, 11, 0, 0, 0)]\n",
    "\n",
    "    for i, _ in enumerate(df[\"valid_time\"]):\n",
    "        t = df[\"valid_time\"].iloc[i]\n",
    "        tair = df[col].iloc[i]\n",
    "        dt_object = parse(str(t))\n",
    "        year = dt_object.strftime(\"%Y\")\n",
    "        month = dt_object.strftime(\"%m\")\n",
    "\n",
    "        for m in np.arange(1, 13):\n",
    "            new_means = st.mean(means)\n",
    "            anom = tair - new_means\n",
    "            anoms.append(anom)\n",
    "            times.append(t)\n",
    "\n",
    "            # if year == str(2018) and month == str(m).zfill(2):\n",
    "            #     new_means = means[:12]\n",
    "            #     anom = tair - new_means[m-1]\n",
    "            #     anoms.append(anom)\n",
    "            # if year == str(2019) and month == str(m).zfill(2):\n",
    "            #     new_means = means[12:24]\n",
    "            #     anom = tair - new_means[m-1]\n",
    "            #     anoms.append(anom)\n",
    "            # if year == str(2020) and month == str(m).zfill(2):\n",
    "            #     new_means = means[24:36]\n",
    "            #     anom = tair - new_means[m-1]\n",
    "            #     anoms.append(anom)\n",
    "            # if year == str(2021) and month == str(m).zfill(2):\n",
    "            #     new_means = means[36:48]\n",
    "            #     anom = tair - new_means[m-1]\n",
    "            #     anoms.append(anom)\n",
    "            # if year == str(2022) and month == str(m).zfill(2):\n",
    "            #     new_means = means[48:60]\n",
    "            #     anom = tair - new_means[m-1]\n",
    "            #     anoms.append(anom)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(21, 6))\n",
    "    plt.plot(times, anoms, c=\"red\")\n",
    "    print(len(anoms))\n",
    "    # ax.set_xticklabels([2018, 2019, 2020, 2021, 2022])\n",
    "    # ax.set_xticks(np.arange(0, len(anoms), (len(anoms) / 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = sorted(os.listdir(\"/home/aevans/nwp_bias/src/correlation/data/indexes\"))\n",
    "\n",
    "# # years = ['2018', '2019', '2020', '2021', '2022']\n",
    "# years = np.arange(2018, 2023)\n",
    "# for d in directory:\n",
    "#     if d != \"csv\":\n",
    "#         path = f\"/home/aevans/nwp_bias/src/correlation/data/indexes/{d}\"\n",
    "#         cldf = format_climate_df(path)\n",
    "#         cldf = cldf[cldf[\"year\"].isin(years)]\n",
    "#         filename = d\n",
    "\n",
    "#         # plot\n",
    "#         parts = filename.split(\".\")\n",
    "#         title = parts[0]\n",
    "#         cldf = cldf.drop(columns=[\"year\"])\n",
    "#         y = []\n",
    "#         for d, _ in enumerate(cldf[1]):\n",
    "#             vals = cldf.iloc[d]\n",
    "#             for v in vals:\n",
    "#                 y.append(v)\n",
    "\n",
    "#         x = np.arange(0, len(y))\n",
    "#         print(len(y))\n",
    "\n",
    "#         fig, ax = plt.subplots(figsize=(21, 7))\n",
    "#         plt.plot(\n",
    "#             x,\n",
    "#             y,\n",
    "#         )\n",
    "#         plt.title(f\"{title}\")\n",
    "#         ax.set_xticklabels([2018, 2019, 2020, 2021, 2022])\n",
    "#         ax.set_xticks(np.arange(0, len(y), (len(y) / 5)))\n",
    "#         ax.axhline(y=0, c=\"black\")\n",
    "#         ax.set_ylim(-3, 3)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrrr_df = read_hrrr_data()\n",
    "# hrrr_df = hrrr_df[hrrr_df[\"station\"] == \"OLEA\"]\n",
    "hrrr_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrrr_df = hrrr_df[hrrr_df[\"station\"] == \"BKLN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrrr_df\n",
    "# Filter for summer months (assuming summer is June, July, and August)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df = load_nysm_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df[\"station\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df = nysm_df[nysm_df[\"station\"] == \"BKLN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df = nysm_df[nysm_df[\"tair\"] > -100]\n",
    "nysm_df = nysm_df.rename(columns={\"time_1H\": \"valid_time\"})\n",
    "nysm_df.dropna(inplace=True)\n",
    "\n",
    "summer_df = nysm_df[\n",
    "    (nysm_df[\"valid_time\"].dt.month >= 5) & (nysm_df[\"valid_time\"].dt.month <= 9)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_parquet(\n",
    "#     \"/home/aevans/nwp_bias/src/machine_learning/data/lstm_eval_csvs/20231204/WANT/WANT_loss_0.05465654283761978_ml_output.parquet\"\n",
    "# )\n",
    "# df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nysm_df[39490:40960]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tcc_means = groupby_month_hrrr(hrrr_df, \"tcc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anoms_detection_hrrr(hrrr_df, tcc_means, \"tcc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in summer_df.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_means = groupby_month(summer_df, \"tair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = summer_df[summer_df[\"valid_time\"] > datetime(2022, 7, 7, 0, 0, 0)]\n",
    "df = df[df[\"valid_time\"] < datetime(2022, 8, 15, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(21, 6))\n",
    "\n",
    "# Plotting the temperature data\n",
    "ax.plot(df[\"valid_time\"], df[\"tair\"], color=\"darkorange\", label=\"Temperature\")\n",
    "\n",
    "# Plotting the horizontal line for the mean temperature\n",
    "mean_temp = st.mean(t2m_means)\n",
    "ax.axhline(\n",
    "    mean_temp,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Summer Average for BKLN = {round(mean_temp, 2)}\",\n",
    ")\n",
    "\n",
    "# Adding legend\n",
    "ax.legend()\n",
    "\n",
    "ax.set_title(\"Brooklyn NYSM 2 Meter Temperature\", fontsize=24)\n",
    "ax.set_ylabel(\"Degrees Celsius\", fontsize=12)\n",
    "ax.set_xlabel(\"Date\", fontsize=12)\n",
    "ax.set_ylim(21, 36)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relh_means = groupby_month(summer_df, \"relh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(21, 6))\n",
    "\n",
    "# Plotting the temperature data\n",
    "ax.plot(df[\"valid_time\"], df[\"relh\"], color=\"green\", label=\"Temperature\")\n",
    "\n",
    "# Plotting the horizontal line for the mean temperature\n",
    "mean_temp = st.mean(relh_means)\n",
    "ax.axhline(\n",
    "    mean_temp,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Summer Average for BKLN = {round(mean_temp, 2)}\",\n",
    ")\n",
    "\n",
    "# Adding legend\n",
    "ax.legend()\n",
    "\n",
    "ax.set_title(\"Brooklyn NYSM 2 Meter Temperature\", fontsize=24)\n",
    "ax.set_ylabel(\"% Humidity\", fontsize=12)\n",
    "ax.set_xlabel(\"Date\", fontsize=12)\n",
    "# ax.set_ylim(15, 40)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_means = groupby_month(summer_df, \"wmax_sonic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have 't2m_means' defined somewhere\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(21, 6))\n",
    "\n",
    "# Plotting the temperature data\n",
    "ax.plot(df[\"valid_time\"], df[\"wmax_sonic\"], color=\"blue\", label=\"Temperature\")\n",
    "\n",
    "# Plotting the horizontal line for the mean temperature\n",
    "mean_temp = st.mean(wind_means)\n",
    "ax.axhline(\n",
    "    mean_temp,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Summer Average for BKLN = {round(mean_temp, 2)}\",\n",
    ")\n",
    "\n",
    "# Adding legend\n",
    "ax.legend()\n",
    "\n",
    "ax.set_title(\"Brooklyn NYSM 2 Meter Temperature\", fontsize=24)\n",
    "ax.set_ylabel(\"Meters / Second\", fontsize=12)\n",
    "ax.set_xlabel(\"Date\", fontsize=12)\n",
    "# ax.set_ylim(15, 40)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_means = groupby_month(summer_df, \"precip_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have 't2m_means' defined somewhere\n",
    "fig, ax = plt.subplots(figsize=(21, 6))\n",
    "\n",
    "# Plotting the temperature data\n",
    "ax.plot(df[\"valid_time\"], df[\"precip_total\"], color=\"purple\", label=\"Temperature\")\n",
    "\n",
    "# Plotting the horizontal line for the mean temperature\n",
    "mean_temp = st.mean(p_means)\n",
    "ax.axhline(\n",
    "    mean_temp,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Summer Average for BKLN = {round(mean_temp, 2)}\",\n",
    ")\n",
    "\n",
    "# Adding legend\n",
    "ax.legend()\n",
    "\n",
    "ax.set_title(\"Brooklyn NYSM 2 Meter Temperature\", fontsize=24)\n",
    "ax.set_ylabel(\"Millimeters / Hour\", fontsize=12)\n",
    "ax.set_xlabel(\"Date\", fontsize=12)\n",
    "# ax.set_ylim(15, 40)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hi(T, RH):\n",
    "    _hi = (\n",
    "        -42.379\n",
    "        + 2.04901523 * T\n",
    "        + 10.14333127 * RH\n",
    "        - 0.22475541 * T * RH\n",
    "        - 0.00683783 * T * T\n",
    "        - 0.05481717 * RH * RH\n",
    "        + 0.00122874 * T * T * RH\n",
    "        + 0.00085282 * T * RH * RH\n",
    "        - 0.00000199 * T * T * RH * RH\n",
    "    )\n",
    "\n",
    "    return _hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_to_c(ls):\n",
    "    new_ls = []\n",
    "    for i in ls:\n",
    "        new = (i - 32) * (5 / 9)\n",
    "        new_ls.append(new)\n",
    "    return new_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat_index(df):\n",
    "    heat_index = []\n",
    "    for i, _ in enumerate(df[\"valid_time\"]):\n",
    "        T = df[\"tair\"].iloc[i]\n",
    "        T = T * (9 / 5) + 32\n",
    "        RH = df[\"relh\"].iloc[i]\n",
    "\n",
    "        hi = calc_hi(T, RH)\n",
    "        heat_index.append(hi)\n",
    "    new_heat = f_to_c(heat_index)\n",
    "    return new_heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_index = heat_index(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have 't2m_means' defined somewhere\n",
    "fig, ax = plt.subplots(figsize=(21, 6))\n",
    "\n",
    "# Plotting the temperature data\n",
    "ax.plot(df[\"valid_time\"], heat_index, color=\"maroon\", label=\"Temperature\")\n",
    "\n",
    "# Plotting the horizontal line for the mean temperature\n",
    "mean_temp = st.mean(heat_index)\n",
    "ax.axhline(\n",
    "    mean_temp,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Summer Average for BKLN = {round(mean_temp, 2)}\",\n",
    ")\n",
    "\n",
    "# Adding legend\n",
    "ax.legend()\n",
    "\n",
    "ax.set_title(\"Brooklyn NYSM Heat Index\", fontsize=24)\n",
    "ax.set_ylabel(\"Degrees Fahrenheit\", fontsize=12)\n",
    "ax.set_xlabel(\"Date\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_df = pd.read_csv(\n",
    "    \"/home/aevans/nwp_bias/data/model_data/nyc_electricity/nyc_elec_load_july_aug_2022.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_format = \"%m/%d/%Y %H:%M:%S\"\n",
    "\n",
    "dates = []\n",
    "\n",
    "for i, _ in enumerate(elec_df[\"Time Stamp\"]):\n",
    "    date_string = elec_df[\"Time Stamp\"].iloc[i]\n",
    "    # Convert the string to a datetime object\n",
    "    datetime_object = datetime.strptime(date_string, date_format)\n",
    "    dates.append(datetime_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_df[\"valid_time\"] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = elec_df[elec_df[\"valid_time\"] > datetime(2022, 7, 7, 0, 0, 0)]\n",
    "df2 = df2[df2[\"valid_time\"] < datetime(2022, 8, 15, 0, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum up the 'value' column for each hour\n",
    "hourly_sum = df2.groupby([(df2.valid_time.dt.hour)])[\"Load\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have 't2m_means' defined somewhere\n",
    "fig, ax = plt.subplots(figsize=(21, 6))\n",
    "\n",
    "\n",
    "# Plotting the temperature data\n",
    "ax.plot(df2[\"valid_time\"], df2[\"Load\"], color=\"black\", label=\"Electrical Load for NYC\")\n",
    "ax.plot(df[\"valid_time\"], heat_index, color=\"maroon\", label=\"Temperature\")\n",
    "# Plotting the temperature data\n",
    "ax.plot(df[\"valid_time\"], df[\"tair\"], color=\"darkorange\", label=\"Temperature\")\n",
    "\n",
    "# Plotting the horizontal line for the mean temperature\n",
    "mean_temp = st.mean(heat_index)\n",
    "ax.axhline(\n",
    "    5500, color=\"red\", linestyle=\"--\", label=f\"Average electricity load = 5500 MW\"\n",
    ")\n",
    "\n",
    "# Adding legend\n",
    "ax.legend()\n",
    "\n",
    "ax.set_title(\"NYC Electrical Load\", fontsize=24)\n",
    "ax.set_ylabel(\"Megawatts\", fontsize=12)\n",
    "ax.set_xlabel(\"Date\", fontsize=12)\n",
    "# ax.set_ylim(80, 105)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statistics as st\n",
    "\n",
    "# Assuming you have 't2m_means' and 'df2' defined somewhere\n",
    "fig, ax = plt.subplots(figsize=(21, 6))\n",
    "\n",
    "# Plotting the temperature data on the primary y-axis\n",
    "ax.plot(\n",
    "    df2[\"valid_time\"],\n",
    "    df2[\"Load\"],\n",
    "    color=\"black\",\n",
    "    label=\"Electrical Load for NYC\",\n",
    "    linewidth=3,\n",
    ")\n",
    "ax.set_ylabel(\"Megawatts\", fontsize=12)\n",
    "\n",
    "# Creating a second y-axis\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "# Plotting the first temperature data on the second y-axis\n",
    "ax2.plot(df[\"valid_time\"], df[\"tair\"], color=\"darkorange\", label=\"Temperature\")\n",
    "ax2.set_ylabel(\"Degrees Celsius\", fontsize=12)\n",
    "# Set the y-axis limits for ax2\n",
    "ax2.set_ylim(ymin=15, ymax=40)\n",
    "\n",
    "# Creating a third y-axis\n",
    "ax3 = ax.twinx()\n",
    "\n",
    "# Plotting the second temperature data on the third y-axis\n",
    "ax3.plot(df[\"valid_time\"], heat_index, color=\"blue\", label=\"Heat Index\")\n",
    "ax3.set_ylim(ymin=15, ymax=40)\n",
    "\n",
    "\n",
    "ax.axhline(\n",
    "    5500, color=\"red\", linestyle=\"--\", label=f\"Average electricity load = 5500 MW\"\n",
    ")\n",
    "\n",
    "# Adding legend\n",
    "lines, labels = ax.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "lines3, labels3 = ax3.get_legend_handles_labels()\n",
    "ax3.legend(lines + lines2 + lines3, labels + labels2 + labels3, loc=\"upper left\")\n",
    "\n",
    "ax.set_title(\"NYC Electrical Load and Temperature\", fontsize=24)\n",
    "ax.set_xlabel(\"Date\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_means = groupby_month(hrrr_df, \"d2m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms_td = anoms_detection(hrrr_df, td_means, \"d2m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relh_means = groupby_month(hrrr_df, \"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms_detection(hrrr_df, relh_means, \"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srad_means = groupby_month(hrrr_df, \"dswrf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms_detection(hrrr_df, srad_means, \"dswrf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_means = groupby_month(hrrr_df, \"mslma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms_detection(hrrr_df, pres_means, \"mslma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mslp_means = groupby_month(nysm_df, \"mslp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms_detection(nysm_df, mslp_means, \"mslp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wspd_means = groupby_month(hrrr_df, \"u_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms_detection(hrrr_df, wspd_means, \"u_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_means = groupby_month(hrrr_df, \"new_tp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms_detection(hrrr_df, precip_means, \"new_tp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_means = groupby_month(hrrr_df, \"asnow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms_detection(hrrr_df, snow_means, \"asnow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can estimate the IMFs for the signal\n",
    "x = nysm_df[\"tair\"]\n",
    "imf = emd.sift.sift(x)\n",
    "print(imf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and, from the IMFs, compute the instantaneous frequency, phase and amplitude using the Normalised Hilbert Transform Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP, IF, IA = emd.spectra.frequency_transform(imf, 23618, \"hilbert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the instantaneous frequency and amplitude, we can compute the Hilbert-Huang spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define frequency range (low_freq, high_freq, nsteps, spacing)\n",
    "freq_range = (0.1, 10, 80, \"log\")\n",
    "f, hht = emd.spectra.hilberthuang(IF, IA, freq_range, sum_time=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize\n",
    "# fig = plt.figure(figsize=(25, 3))\n",
    "# plt.plot(nysm_df[\"tair\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[:, 9:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the IMFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emd.plotting.plot_imfs(imf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 23618\n",
    "time_vect = np.linspace(0, sample_rate)\n",
    "fig = plt.figure(figsize=(15, 9))\n",
    "emd.plotting.plot_hilberthuang(hht, time_vect, f, fig=fig, log_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensemble sifting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nysm_df[\"wspd_sonic\"]\n",
    "imf_opts = {\"sd_thresh\": 0.05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imf = emd.sift.ensemble_sift(\n",
    "    x, nensembles=42, nprocesses=12, ensemble_noise=1, imf_opts=imf_opts\n",
    ")\n",
    "emd.plotting.plot_imfs(imf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now the Hilbert-Huang transform of this decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 23618\n",
    "\n",
    "time_vect = np.linspace(0, sample_rate - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "emd.plotting.plot_hilberthuang(hht, time_vect, f, fig=fig, log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "168fdf287636bbedc06224370453d1ea17ee31ef28776649e24f81e171f8fc2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
