{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "# instead of creating a package using setup.py or building from a docker/singularity file,\n",
    "# import the sister directory of src code to be called on in notebook.\n",
    "# This keeps the notebook free from code to only hold visualizations and is easier to test\n",
    "# It also helps keep the state of variables clean such that cells aren't run out of order with a mysterious state\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import hrrr_data, nam_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20180330_hrrr_fh01.parquet',\n",
       " '20180318_hrrr_fh01.parquet',\n",
       " '20180303_hrrr_fh01.parquet',\n",
       " '20180317_hrrr_fh01.parquet',\n",
       " '20180310_hrrr_fh01.parquet',\n",
       " '20180302_hrrr_fh01.parquet',\n",
       " '20180311_hrrr_fh01.parquet',\n",
       " '20180322_hrrr_fh01.parquet',\n",
       " '20180306_hrrr_fh01.parquet',\n",
       " '20180308_hrrr_fh01.parquet',\n",
       " '20180328_hrrr_fh01.parquet',\n",
       " '20180319_hrrr_fh01.parquet',\n",
       " '20180307_hrrr_fh01.parquet',\n",
       " '20180304_hrrr_fh01.parquet',\n",
       " '20180316_hrrr_fh01.parquet',\n",
       " '20180301_hrrr_fh01.parquet',\n",
       " '20180309_hrrr_fh01.parquet',\n",
       " '20180321_hrrr_fh01.parquet',\n",
       " '20180312_hrrr_fh01.parquet',\n",
       " '20180326_hrrr_fh01.parquet',\n",
       " '20180323_hrrr_fh01.parquet',\n",
       " '20180325_hrrr_fh01.parquet',\n",
       " '20180320_hrrr_fh01.parquet',\n",
       " '20180314_hrrr_fh01.parquet',\n",
       " '20180329_hrrr_fh01.parquet',\n",
       " '20180331_hrrr_fh01.parquet',\n",
       " '20180315_hrrr_fh01.parquet',\n",
       " '20180327_hrrr_fh01.parquet',\n",
       " '20180305_hrrr_fh01.parquet',\n",
       " '20180324_hrrr_fh01.parquet',\n",
       " '20180313_hrrr_fh01.parquet']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dirs = os.listdir(\"/home/aevans/ai2es/lstm/HRRR/fh_01/2018/03\")\n",
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180330_hrrr_fh01.parquet\n",
      "20180318_hrrr_fh01.parquet\n",
      "20180303_hrrr_fh01.parquet\n",
      "20180317_hrrr_fh01.parquet\n",
      "20180310_hrrr_fh01.parquet\n",
      "20180302_hrrr_fh01.parquet\n",
      "20180311_hrrr_fh01.parquet\n",
      "20180322_hrrr_fh01.parquet\n",
      "20180306_hrrr_fh01.parquet\n",
      "20180308_hrrr_fh01.parquet\n",
      "20180328_hrrr_fh01.parquet\n",
      "20180319_hrrr_fh01.parquet\n",
      "20180307_hrrr_fh01.parquet\n",
      "20180304_hrrr_fh01.parquet\n",
      "20180316_hrrr_fh01.parquet\n",
      "20180301_hrrr_fh01.parquet\n",
      "20180309_hrrr_fh01.parquet\n",
      "20180321_hrrr_fh01.parquet\n",
      "20180312_hrrr_fh01.parquet\n",
      "20180326_hrrr_fh01.parquet\n",
      "20180323_hrrr_fh01.parquet\n",
      "20180325_hrrr_fh01.parquet\n",
      "20180320_hrrr_fh01.parquet\n",
      "20180314_hrrr_fh01.parquet\n",
      "20180329_hrrr_fh01.parquet\n",
      "20180331_hrrr_fh01.parquet\n",
      "20180315_hrrr_fh01.parquet\n",
      "20180327_hrrr_fh01.parquet\n",
      "20180305_hrrr_fh01.parquet\n",
      "20180324_hrrr_fh01.parquet\n",
      "20180313_hrrr_fh01.parquet\n"
     ]
    }
   ],
   "source": [
    "for f in dirs:\n",
    "    print(f)\n",
    "    df = pd.read_parquet(f\"/home/aevans/ai2es/lstm/HRRR/fh_01/2018/03/{f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/aevans/ai2es/lstm/HRRR/fh_01/2018/02/20180217_hrrr_fh01.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m df1\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/site-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39mread(\n\u001b[1;32m    668\u001b[0m     path,\n\u001b[1;32m    669\u001b[0m     columns\u001b[39m=\u001b[39mcolumns,\n\u001b[1;32m    670\u001b[0m     filters\u001b[39m=\u001b[39mfilters,\n\u001b[1;32m    671\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[1;32m    672\u001b[0m     use_nullable_dtypes\u001b[39m=\u001b[39muse_nullable_dtypes,\n\u001b[1;32m    673\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    674\u001b[0m     filesystem\u001b[39m=\u001b[39mfilesystem,\n\u001b[1;32m    675\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    676\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/site-packages/pandas/io/parquet.py:402\u001b[0m, in \u001b[0;36mFastParquetImpl.read\u001b[0;34m(self, path, columns, filters, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m     path \u001b[39m=\u001b[39m handles\u001b[39m.\u001b[39mhandle\n\u001b[1;32m    401\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 402\u001b[0m     parquet_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mParquetFile(path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparquet_kwargs)\n\u001b[1;32m    403\u001b[0m     \u001b[39mreturn\u001b[39;00m parquet_file\u001b[39m.\u001b[39mto_pandas(columns\u001b[39m=\u001b[39mcolumns, filters\u001b[39m=\u001b[39mfilters, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    404\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/site-packages/fastparquet/api.py:135\u001b[0m, in \u001b[0;36mParquetFile.__init__\u001b[0;34m(self, fn, verify, open_with, root, sep, fs, pandas_nulls, dtypes)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(fn, \u001b[39m'\u001b[39m\u001b[39mread\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    133\u001b[0m     \u001b[39m# file-like\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_header(fn, verify)\n\u001b[1;32m    136\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_scheme \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39msimple\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mempty\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m    137\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCannot use file-like input \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    138\u001b[0m                          \u001b[39m'\u001b[39m\u001b[39mwith multi-file data\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/site-packages/fastparquet/api.py:215\u001b[0m, in \u001b[0;36mParquetFile._parse_header\u001b[0;34m(self, f, verify)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[39massert\u001b[39;00m f\u001b[39m.\u001b[39mread() \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPAR1\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    214\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_head_size \u001b[39m=\u001b[39m head_size\n\u001b[0;32m--> 215\u001b[0m     f\u001b[39m.\u001b[39mseek(\u001b[39m-\u001b[39m(head_size \u001b[39m+\u001b[39m \u001b[39m8\u001b[39m), \u001b[39m2\u001b[39m)\n\u001b[1;32m    216\u001b[0m     data \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread(head_size)\n\u001b[1;32m    217\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAssertionError\u001b[39;00m, struct\u001b[39m.\u001b[39merror):\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_parquet(\n",
    "    \"/home/aevans/ai2es/lstm/HRRR/fh_01/2018/02/20180217_hrrr_fh01.parquet\"\n",
    ")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_more_fh(fh, station, var, times):\n",
    "    hrrr_df_0 = hrrr_data.read_hrrr_data(str(fh + 2).zfill(2))\n",
    "    hrrr_df_1 = hrrr_data.read_hrrr_data(str(fh + 4).zfill(2))\n",
    "\n",
    "    hrrr_df_0 = hrrr_df_0[hrrr_df_0[\"station\"] == station]\n",
    "    hrrr_df_1 = hrrr_df_1[hrrr_df_1[\"station\"] == station]\n",
    "\n",
    "    hrrr_df_0 = hrrr_df_0[[\"valid_time\", var]]\n",
    "    hrrr_df_1 = hrrr_df_1[[\"valid_time\", var]]\n",
    "\n",
    "    # Create a DataFrame for valid times\n",
    "    df = pd.DataFrame({\"valid_time\": times})\n",
    "    df = df.merge(hrrr_df_0, on=\"valid_time\", suffixes=(None, f\"_{station}_+2\"))\n",
    "    df = df.merge(hrrr_df_1, on=\"valid_time\", suffixes=(None, f\"_{station}_+4\"))\n",
    "    df = df.rename(columns={\"t2m\": f\"{var}_{station}_+2\"})\n",
    "    # df.fillna(-999, inplace=True)\n",
    "\n",
    "    fh2 = df[f\"{var}_{station}_+2\"].values\n",
    "    fh4 = df[f\"{var}_{station}_+4\"].values\n",
    "\n",
    "    print(len(fh2))\n",
    "    print(len(fh4))\n",
    "\n",
    "    return fh2, fh4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nam_data(fh):\n",
    "    \"\"\"\n",
    "    Reads and concatenates parquet files containing forecast and error data for HRRR weather models\n",
    "    for the years 2018 to 2022.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: of hrrr weather forecast information for each NYSM site.\n",
    "    \"\"\"\n",
    "\n",
    "    years = [\"2022\", \"2023\"]\n",
    "    savedir = f\"/home/aevans/nwp_bias/src/machine_learning/data/nam_data/fh{fh}/\"\n",
    "\n",
    "    # create empty lists to hold dataframes for each model\n",
    "    nam_fcast_and_error = []\n",
    "\n",
    "    # loop over years and read in parquet files for each model\n",
    "    for year in years:\n",
    "        for month in np.arange(1, 13):\n",
    "            str_month = str(month).zfill(2)\n",
    "            if (\n",
    "                os.path.exists(\n",
    "                    f\"{savedir}NAM_{year}_{str_month}_direct_compare_to_nysm_sites_mask_water.parquet\"\n",
    "                )\n",
    "                == True\n",
    "            ):\n",
    "                print(\n",
    "                    f\"{savedir}NAM_{year}_{str_month}_direct_compare_to_nysm_sites_mask_water.parquet\"\n",
    "                )\n",
    "                nam_fcast_and_error.append(\n",
    "                    pd.read_parquet(\n",
    "                        f\"{savedir}NAM_{year}_{str_month}_direct_compare_to_nysm_sites_mask_water.parquet\"\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                continue\n",
    "            gc.collect()\n",
    "\n",
    "    # concatenate dataframes for each model\n",
    "    nam_fcast_and_error_df = pd.concat(nam_fcast_and_error)\n",
    "    nam_fcast_and_error_df = nam_fcast_and_error_df.dropna()\n",
    "\n",
    "    # return dataframes for each model\n",
    "    return nam_fcast_and_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = 6\n",
    "station = \"SOUT\"\n",
    "var = \"t2m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>t2m</th>\n",
       "      <th>sh2</th>\n",
       "      <th>d2m</th>\n",
       "      <th>r2</th>\n",
       "      <th>u10</th>\n",
       "      <th>v10</th>\n",
       "      <th>u_total</th>\n",
       "      <th>u_dir</th>\n",
       "      <th>...</th>\n",
       "      <th>cin</th>\n",
       "      <th>dswrf</th>\n",
       "      <th>dlwrf</th>\n",
       "      <th>gh</th>\n",
       "      <th>station</th>\n",
       "      <th>valid_time</th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>lead time</th>\n",
       "      <th>lsm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-04-01 00:00:00</th>\n",
       "      <td>42.040359</td>\n",
       "      <td>-77.237259</td>\n",
       "      <td>10.103218</td>\n",
       "      <td>0.007865</td>\n",
       "      <td>9.483641</td>\n",
       "      <td>96.349721</td>\n",
       "      <td>1.640804</td>\n",
       "      <td>0.421012</td>\n",
       "      <td>1.836858</td>\n",
       "      <td>254.633860</td>\n",
       "      <td>...</td>\n",
       "      <td>-51.194306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>341.605801</td>\n",
       "      <td>5502.463200</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>2022-04-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01 00:00:00</th>\n",
       "      <td>42.242489</td>\n",
       "      <td>-78.039581</td>\n",
       "      <td>5.369774</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>3.630354</td>\n",
       "      <td>88.805841</td>\n",
       "      <td>4.411272</td>\n",
       "      <td>0.107432</td>\n",
       "      <td>4.429688</td>\n",
       "      <td>269.082379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>331.982933</td>\n",
       "      <td>5482.838469</td>\n",
       "      <td>BELM</td>\n",
       "      <td>2022-04-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01 00:00:00</th>\n",
       "      <td>42.058430</td>\n",
       "      <td>-75.951042</td>\n",
       "      <td>12.888993</td>\n",
       "      <td>0.008826</td>\n",
       "      <td>11.316517</td>\n",
       "      <td>90.612892</td>\n",
       "      <td>-0.301365</td>\n",
       "      <td>3.275204</td>\n",
       "      <td>3.298334</td>\n",
       "      <td>175.079971</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.934617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>348.131055</td>\n",
       "      <td>5527.008490</td>\n",
       "      <td>BING</td>\n",
       "      <td>2022-04-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01 00:00:00</th>\n",
       "      <td>40.631763</td>\n",
       "      <td>-73.953674</td>\n",
       "      <td>14.533216</td>\n",
       "      <td>0.009694</td>\n",
       "      <td>13.456205</td>\n",
       "      <td>93.797555</td>\n",
       "      <td>-0.555687</td>\n",
       "      <td>8.000869</td>\n",
       "      <td>8.023277</td>\n",
       "      <td>175.928714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>387.901190</td>\n",
       "      <td>5599.040353</td>\n",
       "      <td>BKLN</td>\n",
       "      <td>2022-04-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01 00:00:00</th>\n",
       "      <td>41.439930</td>\n",
       "      <td>-73.576424</td>\n",
       "      <td>13.917935</td>\n",
       "      <td>0.009672</td>\n",
       "      <td>13.142769</td>\n",
       "      <td>95.666243</td>\n",
       "      <td>-0.584071</td>\n",
       "      <td>5.937920</td>\n",
       "      <td>5.969338</td>\n",
       "      <td>174.374824</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>381.762907</td>\n",
       "      <td>5576.003682</td>\n",
       "      <td>BREW</td>\n",
       "      <td>2022-04-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-29 06:00:00</th>\n",
       "      <td>42.896945</td>\n",
       "      <td>-77.864666</td>\n",
       "      <td>-2.382147</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>-3.703741</td>\n",
       "      <td>90.955078</td>\n",
       "      <td>2.849240</td>\n",
       "      <td>0.171882</td>\n",
       "      <td>2.854419</td>\n",
       "      <td>266.547791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>216.349182</td>\n",
       "      <td>5532.245605</td>\n",
       "      <td>YORK</td>\n",
       "      <td>2022-04-29 07:00:00</td>\n",
       "      <td>610627.0</td>\n",
       "      <td>1474296.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-29 18:00:00</th>\n",
       "      <td>42.896945</td>\n",
       "      <td>-77.864666</td>\n",
       "      <td>11.714075</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>-1.903876</td>\n",
       "      <td>38.704834</td>\n",
       "      <td>1.682588</td>\n",
       "      <td>-4.068793</td>\n",
       "      <td>4.402974</td>\n",
       "      <td>337.533203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>854.901855</td>\n",
       "      <td>254.066956</td>\n",
       "      <td>5581.283203</td>\n",
       "      <td>YORK</td>\n",
       "      <td>2022-04-29 19:00:00</td>\n",
       "      <td>610628.0</td>\n",
       "      <td>1501220.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-30 06:00:00</th>\n",
       "      <td>42.896945</td>\n",
       "      <td>-77.864666</td>\n",
       "      <td>0.462030</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>-3.267645</td>\n",
       "      <td>76.165352</td>\n",
       "      <td>1.267696</td>\n",
       "      <td>1.891173</td>\n",
       "      <td>2.276750</td>\n",
       "      <td>213.834854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>232.245041</td>\n",
       "      <td>5602.612305</td>\n",
       "      <td>YORK</td>\n",
       "      <td>2022-04-30 07:00:00</td>\n",
       "      <td>610629.0</td>\n",
       "      <td>1528144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-30 12:00:00</th>\n",
       "      <td>42.896945</td>\n",
       "      <td>-77.864666</td>\n",
       "      <td>8.174463</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>1.132318</td>\n",
       "      <td>61.323597</td>\n",
       "      <td>0.333627</td>\n",
       "      <td>-0.716639</td>\n",
       "      <td>0.790493</td>\n",
       "      <td>335.035980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004590</td>\n",
       "      <td>505.000000</td>\n",
       "      <td>246.259323</td>\n",
       "      <td>5624.912598</td>\n",
       "      <td>YORK</td>\n",
       "      <td>2022-04-30 13:00:00</td>\n",
       "      <td>610630.0</td>\n",
       "      <td>1541606.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-30 18:00:00</th>\n",
       "      <td>42.896945</td>\n",
       "      <td>-77.864666</td>\n",
       "      <td>13.804834</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>-0.485052</td>\n",
       "      <td>37.501873</td>\n",
       "      <td>-0.551718</td>\n",
       "      <td>-3.270831</td>\n",
       "      <td>3.317036</td>\n",
       "      <td>9.574409</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000732</td>\n",
       "      <td>864.496643</td>\n",
       "      <td>260.132263</td>\n",
       "      <td>5650.812500</td>\n",
       "      <td>YORK</td>\n",
       "      <td>2022-04-30 19:00:00</td>\n",
       "      <td>610631.0</td>\n",
       "      <td>1555068.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10912 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      latitude  longitude        t2m       sh2        d2m  \\\n",
       "time                                                                        \n",
       "2022-04-01 00:00:00  42.040359 -77.237259  10.103218  0.007865   9.483641   \n",
       "2022-04-01 00:00:00  42.242489 -78.039581   5.369774  0.005322   3.630354   \n",
       "2022-04-01 00:00:00  42.058430 -75.951042  12.888993  0.008826  11.316517   \n",
       "2022-04-01 00:00:00  40.631763 -73.953674  14.533216  0.009694  13.456205   \n",
       "2022-04-01 00:00:00  41.439930 -73.576424  13.917935  0.009672  13.142769   \n",
       "...                        ...        ...        ...       ...        ...   \n",
       "2022-04-29 06:00:00  42.896945 -77.864666  -2.382147  0.002916  -3.703741   \n",
       "2022-04-29 18:00:00  42.896945 -77.864666  11.714075  0.003342  -1.903876   \n",
       "2022-04-30 06:00:00  42.896945 -77.864666   0.462030  0.003015  -3.267645   \n",
       "2022-04-30 12:00:00  42.896945 -77.864666   8.174463  0.004167   1.132318   \n",
       "2022-04-30 18:00:00  42.896945 -77.864666  13.804834  0.003713  -0.485052   \n",
       "\n",
       "                            r2       u10       v10   u_total       u_dir  ...  \\\n",
       "time                                                                      ...   \n",
       "2022-04-01 00:00:00  96.349721  1.640804  0.421012  1.836858  254.633860  ...   \n",
       "2022-04-01 00:00:00  88.805841  4.411272  0.107432  4.429688  269.082379  ...   \n",
       "2022-04-01 00:00:00  90.612892 -0.301365  3.275204  3.298334  175.079971  ...   \n",
       "2022-04-01 00:00:00  93.797555 -0.555687  8.000869  8.023277  175.928714  ...   \n",
       "2022-04-01 00:00:00  95.666243 -0.584071  5.937920  5.969338  174.374824  ...   \n",
       "...                        ...       ...       ...       ...         ...  ...   \n",
       "2022-04-29 06:00:00  90.955078  2.849240  0.171882  2.854419  266.547791  ...   \n",
       "2022-04-29 18:00:00  38.704834  1.682588 -4.068793  4.402974  337.533203  ...   \n",
       "2022-04-30 06:00:00  76.165352  1.267696  1.891173  2.276750  213.834854  ...   \n",
       "2022-04-30 12:00:00  61.323597  0.333627 -0.716639  0.790493  335.035980  ...   \n",
       "2022-04-30 18:00:00  37.501873 -0.551718 -3.270831  3.317036    9.574409  ...   \n",
       "\n",
       "                           cin       dswrf       dlwrf           gh  station  \\\n",
       "time                                                                           \n",
       "2022-04-01 00:00:00 -51.194306    0.000000  341.605801  5502.463200     ADDI   \n",
       "2022-04-01 00:00:00  -0.020703    0.000000  331.982933  5482.838469     BELM   \n",
       "2022-04-01 00:00:00 -12.934617    0.000000  348.131055  5527.008490     BING   \n",
       "2022-04-01 00:00:00  -0.020703    0.000000  387.901190  5599.040353     BKLN   \n",
       "2022-04-01 00:00:00  -0.020703    0.000000  381.762907  5576.003682     BREW   \n",
       "...                        ...         ...         ...          ...      ...   \n",
       "2022-04-29 06:00:00   0.005566    0.000000  216.349182  5532.245605     YORK   \n",
       "2022-04-29 18:00:00   0.004883  854.901855  254.066956  5581.283203     YORK   \n",
       "2022-04-30 06:00:00  -0.041797    0.000000  232.245041  5602.612305     YORK   \n",
       "2022-04-30 12:00:00   0.004590  505.000000  246.259323  5624.912598     YORK   \n",
       "2022-04-30 18:00:00  -0.000732  864.496643  260.132263  5650.812500     YORK   \n",
       "\n",
       "                             valid_time   level_0      index  lead time  lsm  \n",
       "time                                                                          \n",
       "2022-04-01 00:00:00 2022-04-01 01:00:00       0.0        0.0        0.0  0.0  \n",
       "2022-04-01 00:00:00 2022-04-01 01:00:00       0.0        0.0        0.0  0.0  \n",
       "2022-04-01 00:00:00 2022-04-01 01:00:00       0.0        0.0        0.0  0.0  \n",
       "2022-04-01 00:00:00 2022-04-01 01:00:00       0.0        0.0        0.0  0.0  \n",
       "2022-04-01 00:00:00 2022-04-01 01:00:00       0.0        0.0        0.0  0.0  \n",
       "...                                 ...       ...        ...        ...  ...  \n",
       "2022-04-29 06:00:00 2022-04-29 07:00:00  610627.0  1474296.0        1.0  1.0  \n",
       "2022-04-29 18:00:00 2022-04-29 19:00:00  610628.0  1501220.0        1.0  1.0  \n",
       "2022-04-30 06:00:00 2022-04-30 07:00:00  610629.0  1528144.0        1.0  1.0  \n",
       "2022-04-30 12:00:00 2022-04-30 13:00:00  610630.0  1541606.0        1.0  1.0  \n",
       "2022-04-30 18:00:00 2022-04-30 19:00:00  610631.0  1555068.0        1.0  1.0  \n",
       "\n",
       "[10912 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\n",
    "    \"/home/aevans/nwp_bias/src/machine_learning/data/nam_data/fh001/NAM_2022_04_direct_compare_to_nysm_sites_mask_water.parquet\"\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nam_df \u001b[38;5;241m=\u001b[39m read_nam_data(\u001b[38;5;28mstr\u001b[39m(fh)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m3\u001b[39m))\n",
      "Cell \u001b[0;32mIn[10], line 37\u001b[0m, in \u001b[0;36mread_nam_data\u001b[0;34m(fh)\u001b[0m\n\u001b[1;32m     34\u001b[0m         gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# concatenate dataframes for each model\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m nam_fcast_and_error_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(nam_fcast_and_error)\n\u001b[1;32m     38\u001b[0m nam_fcast_and_error_df \u001b[38;5;241m=\u001b[39m nam_fcast_and_error_df\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# return dataframes for each model\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39melif\u001b[39;00m copy \u001b[39mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m    385\u001b[0m     ignore_index\u001b[39m=\u001b[39mignore_index,\n\u001b[1;32m    386\u001b[0m     join\u001b[39m=\u001b[39mjoin,\n\u001b[1;32m    387\u001b[0m     keys\u001b[39m=\u001b[39mkeys,\n\u001b[1;32m    388\u001b[0m     levels\u001b[39m=\u001b[39mlevels,\n\u001b[1;32m    389\u001b[0m     names\u001b[39m=\u001b[39mnames,\n\u001b[1;32m    390\u001b[0m     verify_integrity\u001b[39m=\u001b[39mverify_integrity,\n\u001b[1;32m    391\u001b[0m     copy\u001b[39m=\u001b[39mcopy,\n\u001b[1;32m    392\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[1;32m    395\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/site-packages/pandas/core/reshape/concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverify_integrity \u001b[39m=\u001b[39m verify_integrity\n\u001b[1;32m    443\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy \u001b[39m=\u001b[39m copy\n\u001b[0;32m--> 445\u001b[0m objs, keys \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[1;32m    447\u001b[0m \u001b[39m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    448\u001b[0m ndims \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/site-packages/pandas/core/reshape/concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    504\u001b[0m     objs_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[1;32m    506\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs_list) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 507\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    509\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     objs_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs_list))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "nam_df = read_nam_data(str(fh).zfill(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hrrr_df = hrrr_data.read_hrrr_data(str(fh).zfill(2))\n",
    "\n",
    "# # Filter NYSM data to match valid times from HRRR data\n",
    "# mytimes = hrrr_df[\"valid_time\"].tolist()\n",
    "# fh2_, fh4_ = get_more_fh(fh, station, var, mytimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(mytimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a100_mae = [\n",
    "    0.07,\n",
    "    0.17,\n",
    "]\n",
    "a100_mse = [\n",
    "    0.07,\n",
    "    0.22,\n",
    "]\n",
    "a100_batch = [\n",
    "    1000,\n",
    "    5000,\n",
    "]\n",
    "a100_gpu = [8, 30]\n",
    "a100_runtime = [\n",
    "    timedelta(seconds=24, minutes=16, hours=0),\n",
    "    timedelta(seconds=5, minutes=16, hours=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh200_mae = [0.06, 0.06]\n",
    "gh200_mse = [0.06, 0.07]\n",
    "gh200_batch = [1000, 10000]\n",
    "gh200_gpu = [8, 64]\n",
    "gh200_runtime = [\n",
    "    timedelta(seconds=22, minutes=6, hours=0),\n",
    "    timedelta(seconds=51, minutes=6, hours=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "def plot_runtime_bar_chart(a100_batch, a100_run_time):\n",
    "    # Convert timedelta objects to total minutes\n",
    "    run_time_minutes = [rt.total_seconds() / 60 for rt in a100_run_time]\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot the bar chart\n",
    "    ax.bar(a100_batch, run_time_minutes, 1000, color=\"orange\", label=\"Run Time\")\n",
    "\n",
    "    # Adding scatter points with large X markers on top of bars\n",
    "    # ax.scatter(a100_batch, run_time_minutes, color='red', marker='x', s=100, label='Run Time Points')\n",
    "\n",
    "    # Adding labels and title\n",
    "    ax.set_xlabel(\"Batch Size\")\n",
    "    ax.set_ylabel(\"Run Time (minutes)\")\n",
    "    ax.set_title(\"Run Time by Batch Size gh200\")\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_metrics_bar(a100_mae, a100_mse, a100_batch):\n",
    "    # Number of bars\n",
    "    n = len(a100_mae)\n",
    "\n",
    "    # Create an array for the positions of the bars\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(n)\n",
    "\n",
    "    # Plotting the bars\n",
    "    fig, ax = plt.subplots()\n",
    "    bar1 = ax.bar(\n",
    "        index,\n",
    "        a100_mae,\n",
    "        bar_width,\n",
    "    )\n",
    "    # bar2 = ax.bar(index + bar_width, a100_mse, bar_width, label='MSE')\n",
    "\n",
    "    # Adding labels and title\n",
    "    ax.set_xlabel(\"Batch Size\")\n",
    "    ax.set_ylabel(\"GPU Memory\")\n",
    "    ax.set_ylim(0, 90)\n",
    "    ax.set_title(\"GPU Memory by Batch Size for a100\")\n",
    "    ax.set_xticks(index)\n",
    "    ax.set_xticklabels(a100_batch)\n",
    "    ax.legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_runtime_bar_chart(a100_batch, a100_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_runtime_bar_chart(gh200_batch, gh200_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_bar(a100_gpu, a100_mse, a100_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_bar(gh200_gpu, gh200_mse, gh200_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "168fdf287636bbedc06224370453d1ea17ee31ef28776649e24f81e171f8fc2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
