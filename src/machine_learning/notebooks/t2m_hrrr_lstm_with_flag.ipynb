{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop all cols with strings and unvaluable info like index\n",
    "Always make sure it is sorted correctly by time and station\n",
    "edit time of year with cos/sin \"encode\"\n",
    "df['day_of_year'] = df['valid_time'].dt.dayofyear\n",
    "?? subrtract a row in setting forecast hours ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "# instead of creating a package using setup.py or building from a docker/singularity file,\n",
    "# import the sister directory of src code to be called on in notebook.\n",
    "# This keeps the notebook free from code to only hold visualizations and is easier to test\n",
    "# It also helps keep the state of variables clean such that cells aren't run out of order with a mysterious state\n",
    "sys.path.append(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import log_model\n",
    "from comet_ml import Optimizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import os\n",
    "import datetime as dt\n",
    "from dateutil.parser import parse\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import emd\n",
    "import statistics as st\n",
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_drop(df):\n",
    "    df = df.drop(\n",
    "        columns=[\n",
    "            \"day_of_year\",\n",
    "            \"flag\",\n",
    "            \"station\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "            \"t2m\",\n",
    "            \"sh2\",\n",
    "            \"d2m\",\n",
    "            \"r2\",\n",
    "            \"u10\",\n",
    "            \"v10\",\n",
    "            \"tp\",\n",
    "            \"mslma\",\n",
    "            \"orog\",\n",
    "            \"tcc\",\n",
    "            \"asnow\",\n",
    "            \"cape\",\n",
    "            \"dswrf\",\n",
    "            \"dlwrf\",\n",
    "            \"gh\",\n",
    "            \"u_total\",\n",
    "            \"u_dir\",\n",
    "            \"new_tp\",\n",
    "            \"lat\",\n",
    "            \"lon\",\n",
    "            \"elev\",\n",
    "            \"tair\",\n",
    "            \"ta9m\",\n",
    "            \"td\",\n",
    "            \"relh\",\n",
    "            \"srad\",\n",
    "            \"pres\",\n",
    "            \"mslp\",\n",
    "            \"wspd_sonic\",\n",
    "            \"wmax_sonic\",\n",
    "            \"wdir_sonic\",\n",
    "            \"precip_total\",\n",
    "            \"snow_depth\",\n",
    "            \"day_of_year\",\n",
    "            \"day_of_year_sin\",\n",
    "            \"day_of_year_cos\",\n",
    "            \"11_nlcd\",\n",
    "            \"21_nlcd\",\n",
    "            \"22_nlcd\",\n",
    "            \"23_nlcd\",\n",
    "            \"24_nlcd\",\n",
    "            \"31_nlcd\",\n",
    "            \"41_nlcd\",\n",
    "            \"42_nlcd\",\n",
    "            \"43_nlcd\",\n",
    "            \"52_nlcd\",\n",
    "            \"71_nlcd\",\n",
    "            \"81_nlcd\",\n",
    "            \"82_nlcd\",\n",
    "            \"90_nlcd\",\n",
    "            \"95_nlcd\",\n",
    "            \"19_aspect\",\n",
    "            \"21_aspect\",\n",
    "            \"24_aspect\",\n",
    "            \"27_aspect\",\n",
    "            \"28_aspect\",\n",
    "            \"22_aspect\",\n",
    "            \"23_aspect\",\n",
    "            \"25_aspect\",\n",
    "            \"26_aspect\",\n",
    "            \"31_aspect\",\n",
    "            \"33_aspect\",\n",
    "            \"32_aspect\",\n",
    "            \"34_aspect\",\n",
    "            \"38_aspect\",\n",
    "            \"std_elev\",\n",
    "            \"variance_elev\",\n",
    "            \"skew_elev\",\n",
    "            \"med_dist_elev\",\n",
    "        ]\n",
    "    )\n",
    "    df = df[df.columns.drop(list(df.filter(regex=\"time\")))]\n",
    "    df = df[df.columns.drop(list(df.filter(regex=\"station\")))]\n",
    "    df = df[df.columns.drop(list(df.filter(regex=\"tair\")))]\n",
    "    df = df[df.columns.drop(list(df.filter(regex=\"ta9m\")))]\n",
    "    df = df[df.columns.drop(list(df.filter(regex=\"td\")))]\n",
    "    df = df[df.columns.drop(list(df.filter(regex=\"relh\")))]\n",
    "    df = df[df.columns.drop(list(df.filter(regex=\"srad\")))]\n",
    "    df = df[df.columns.drop(list(df.filter(regex=\"pres\")))]\n",
    "    df = df[df.columns.drop(list(df.filter(regex=\"wspd\")))]\n",
    "    df = df[df.columns.drop(list(df.filter(regex=\"wmax\")))]\n",
    "    df = df[df.columns.drop(list(df.filter(regex=\"wdir\")))]\n",
    "    df = df[df.columns.drop(list(df.filter(regex=\"precip_total\")))]\n",
    "    df = df[df.columns.drop(list(df.filter(regex=\"snow_depth\")))]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flag(hrrr_df):\n",
    "    \"\"\"\n",
    "    Create a flag column in the input DataFrame indicating consecutive hourly time intervals.\n",
    "\n",
    "    This function takes a DataFrame containing weather data for different stations, with a 'station' column\n",
    "    representing the station ID and a 'valid_time' column containing timestamps of the weather data.\n",
    "    It calculates the time difference between consecutive timestamps for each station and marks it as 'True'\n",
    "    in a new 'flag' column if the difference is exactly one hour, indicating consecutive hourly time intervals.\n",
    "    Otherwise, it marks the 'flag' as 'False'.\n",
    "\n",
    "    Parameters:\n",
    "    hrrr_df (pandas.DataFrame): Input DataFrame containing weather data for different stations.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The input DataFrame with an additional 'flag' column indicating consecutive hourly time intervals.\n",
    "\n",
    "    Example:\n",
    "      station           valid_time   flag\n",
    "    0        1 2023-08-01 00:00:00   True\n",
    "    1        1 2023-08-01 01:00:00   False\n",
    "    2        1 2023-08-01 03:00:00   False\n",
    "    3        2 2023-08-01 08:00:00   True\n",
    "    4        2 2023-08-01 09:00:00   False\n",
    "    5        2 2023-08-01 11:00:00   True\n",
    "    \"\"\"\n",
    "\n",
    "    # Get unique station IDs\n",
    "    stations_ls = hrrr_df[\"station\"].unique()\n",
    "\n",
    "    # Define a time interval of one hour\n",
    "    one_hour = dt.timedelta(hours=1)\n",
    "\n",
    "    # Initialize a list to store flags for each time interval\n",
    "    flag_ls = []\n",
    "\n",
    "    # Loop through each station and calculate flags for consecutive hourly time intervals\n",
    "    for station in stations_ls:\n",
    "        # Filter DataFrame for the current station\n",
    "        df = hrrr_df[hrrr_df[\"station\"] == station]\n",
    "\n",
    "        # Get the list of valid_time timestamps for the current station\n",
    "        time_ls = df[\"valid_time\"].tolist()\n",
    "\n",
    "        # Compare each timestamp with the next one to determine consecutive intervals\n",
    "        for now, then in zip(time_ls, time_ls[1:]):\n",
    "            if now + one_hour == then:\n",
    "                flag_ls.append(True)\n",
    "            else:\n",
    "                flag_ls.append(False)\n",
    "\n",
    "    # Append an extra True to indicate the last time interval (since it has no next timestamp for comparison)\n",
    "    flag_ls.append(True)\n",
    "\n",
    "    # Add the 'flag' column to the DataFrame\n",
    "    hrrr_df[\"flag\"] = flag_ls\n",
    "\n",
    "    return hrrr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nwp_error(target, station, df):\n",
    "    vars_dict = {\n",
    "        \"t2m\": \"tair\",\n",
    "        \"mslma\": \"pres\",\n",
    "    }\n",
    "    nysm_var = vars_dict.get(target)\n",
    "\n",
    "    df[\"target_error\"] = df[f\"{target}_{station}\"] - df[f\"{nysm_var}_{station}\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data, col, max_val, valid_times):\n",
    "    data[\"valid_time\"] = valid_times\n",
    "    data = data[data.columns.drop(list(data.filter(regex=\"day\")))]\n",
    "    data[\"day_of_year\"] = data[\"valid_time\"].dt.dayofyear\n",
    "    data[col + \"_sin\"] = np.sin(2 * np.pi * data[col] / max_val).astype(float)\n",
    "    data[col + \"_cos\"] = np.cos(2 * np.pi * data[col] / max_val)\n",
    "    data = data.drop(columns=[\"valid_time\", \"day_of_year\"]).astype(float)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_climate_df(data_path):\n",
    "    \"\"\"\n",
    "    Formats a climate data file located at the specified `data_path` into a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): The file path for the climate data file.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the climate data, with the first column renamed to \"year\".\n",
    "    \"\"\"\n",
    "    raw_index = np.loadtxt(f\"{data_path}\")\n",
    "    cl_index = pd.DataFrame(raw_index)\n",
    "    cl_index = cl_index.rename(columns={0: \"year\"})\n",
    "    return cl_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clim_indexes(df, valid_times):\n",
    "    \"\"\"\n",
    "    Fetch climate indexes data and add corresponding index values to the input DataFrame.\n",
    "\n",
    "    This function takes a DataFrame (`df`) containing weather data with a 'valid_time' column representing\n",
    "    timestamps. It reads climate indexes data from text files in the specified directory and extracts index\n",
    "    values corresponding to the month and year of each timestamp in the DataFrame. The extracted index values\n",
    "    are then added to the DataFrame with new columns named after each index.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame containing weather data with a 'valid_time' column.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The input DataFrame with additional columns for each climate index containing their values.\n",
    "    \"\"\"\n",
    "\n",
    "    clim_df_path = \"/home/aevans/nwp_bias/src/correlation/data/indexes/\"\n",
    "    directory = os.listdir(clim_df_path)\n",
    "    df[\"valid_time\"] = valid_times\n",
    "\n",
    "    # Loop through each file in the specified directory\n",
    "    for d in directory:\n",
    "        if d.endswith(\".txt\"):\n",
    "            # Read the climate index data from the file and format it into a DataFrame\n",
    "            clim_df = format_climate_df(f\"{clim_df_path}{d}\")\n",
    "            index_name = d.split(\".\")[0]\n",
    "\n",
    "            clim_ind_ls = []\n",
    "            for t, _ in enumerate(df[\"valid_time\"]):\n",
    "                time_obj = df[\"valid_time\"].iloc[t]\n",
    "                dt_object = parse(str(time_obj))\n",
    "                year = dt_object.strftime(\"%Y\")\n",
    "                month = dt_object.strftime(\"%m\")\n",
    "                # Filter the climate DataFrame to get data for the specific year\n",
    "                df1 = clim_df.loc[clim_df[\"year\"] == int(year)]\n",
    "                df1 = df1.drop(columns=\"year\")\n",
    "                row_list = df1.values\n",
    "                keys = df1.keys()\n",
    "                key_vals = keys.tolist()\n",
    "\n",
    "                # Extract the index value corresponding to the month of the timestamp\n",
    "                the_list = []\n",
    "                for n, _ in enumerate(key_vals):\n",
    "                    val1 = key_vals[n]\n",
    "                    val2 = row_list[0, n]\n",
    "                    tup = (val1, val2)\n",
    "                    the_list.append(tup)\n",
    "                for k, r in the_list:\n",
    "                    if str(k).zfill(2) == month:\n",
    "                        clim_ind_ls.append(r)\n",
    "\n",
    "            # Add the climate index values as a new column in the DataFrame\n",
    "            df[index_name] = clim_ind_ls\n",
    "\n",
    "    df = df.drop(columns=\"valid_time\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\n",
    "    \"/home/aevans/nwp_bias/src/machine_learning/data/clean_parquets/nysm_cats/cleaned_rough_lstm_nysmcat_Western Plateau.parquet\"\n",
    ")\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_times = df[\"valid_time\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valid_time</th>\n",
       "      <th>time</th>\n",
       "      <th>station_ADDI</th>\n",
       "      <th>latitude_ADDI</th>\n",
       "      <th>longitude_ADDI</th>\n",
       "      <th>t2m_ADDI</th>\n",
       "      <th>sh2_ADDI</th>\n",
       "      <th>d2m_ADDI</th>\n",
       "      <th>r2_ADDI</th>\n",
       "      <th>u10_ADDI</th>\n",
       "      <th>...</th>\n",
       "      <th>26_aspect_RAND</th>\n",
       "      <th>31_aspect_RAND</th>\n",
       "      <th>33_aspect_RAND</th>\n",
       "      <th>32_aspect_RAND</th>\n",
       "      <th>34_aspect_RAND</th>\n",
       "      <th>38_aspect_RAND</th>\n",
       "      <th>std_elev_RAND</th>\n",
       "      <th>variance_elev_RAND</th>\n",
       "      <th>skew_elev_RAND</th>\n",
       "      <th>med_dist_elev_RAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>42.045955</td>\n",
       "      <td>-77.218867</td>\n",
       "      <td>-19.199194</td>\n",
       "      <td>0.00068</td>\n",
       "      <td>-21.993216</td>\n",
       "      <td>76.800003</td>\n",
       "      <td>3.321081</td>\n",
       "      <td>...</td>\n",
       "      <td>5.217391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.124478</td>\n",
       "      <td>5896.461701</td>\n",
       "      <td>0.569549</td>\n",
       "      <td>405.940002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>42.045955</td>\n",
       "      <td>-77.218867</td>\n",
       "      <td>-19.118689</td>\n",
       "      <td>0.00068</td>\n",
       "      <td>-21.918570</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>3.298830</td>\n",
       "      <td>...</td>\n",
       "      <td>5.217391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.124478</td>\n",
       "      <td>5896.461701</td>\n",
       "      <td>0.569549</td>\n",
       "      <td>405.940002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 05:00:00</td>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>42.045955</td>\n",
       "      <td>-77.218867</td>\n",
       "      <td>-19.439062</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>-22.570868</td>\n",
       "      <td>73.800003</td>\n",
       "      <td>2.992857</td>\n",
       "      <td>...</td>\n",
       "      <td>5.217391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.124478</td>\n",
       "      <td>5896.461701</td>\n",
       "      <td>0.569549</td>\n",
       "      <td>405.940002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 06:00:00</td>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>42.045955</td>\n",
       "      <td>-77.218867</td>\n",
       "      <td>-19.760291</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>-22.821158</td>\n",
       "      <td>74.400002</td>\n",
       "      <td>3.115693</td>\n",
       "      <td>...</td>\n",
       "      <td>5.217391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.124478</td>\n",
       "      <td>5896.461701</td>\n",
       "      <td>0.569549</td>\n",
       "      <td>405.940002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 07:00:00</td>\n",
       "      <td>2018-01-01 05:00:00</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>42.045955</td>\n",
       "      <td>-77.218867</td>\n",
       "      <td>-19.860175</td>\n",
       "      <td>0.00062</td>\n",
       "      <td>-22.993704</td>\n",
       "      <td>74.099998</td>\n",
       "      <td>3.268302</td>\n",
       "      <td>...</td>\n",
       "      <td>5.217391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.124478</td>\n",
       "      <td>5896.461701</td>\n",
       "      <td>0.569549</td>\n",
       "      <td>405.940002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22486</th>\n",
       "      <td>2022-12-31 19:00:00</td>\n",
       "      <td>2022-12-31 17:00:00</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>42.045955</td>\n",
       "      <td>-77.218867</td>\n",
       "      <td>11.485986</td>\n",
       "      <td>0.00710</td>\n",
       "      <td>8.142847</td>\n",
       "      <td>80.300003</td>\n",
       "      <td>0.073768</td>\n",
       "      <td>...</td>\n",
       "      <td>5.217391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.124478</td>\n",
       "      <td>5896.461701</td>\n",
       "      <td>0.569549</td>\n",
       "      <td>405.940002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22487</th>\n",
       "      <td>2022-12-31 20:00:00</td>\n",
       "      <td>2022-12-31 18:00:00</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>42.045955</td>\n",
       "      <td>-77.218867</td>\n",
       "      <td>10.447198</td>\n",
       "      <td>0.00676</td>\n",
       "      <td>7.376611</td>\n",
       "      <td>80.400002</td>\n",
       "      <td>-0.416093</td>\n",
       "      <td>...</td>\n",
       "      <td>5.217391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.124478</td>\n",
       "      <td>5896.461701</td>\n",
       "      <td>0.569549</td>\n",
       "      <td>405.940002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22488</th>\n",
       "      <td>2022-12-31 21:00:00</td>\n",
       "      <td>2022-12-31 19:00:00</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>42.045955</td>\n",
       "      <td>-77.218867</td>\n",
       "      <td>9.658258</td>\n",
       "      <td>0.00709</td>\n",
       "      <td>8.101648</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.234075</td>\n",
       "      <td>...</td>\n",
       "      <td>5.217391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.124478</td>\n",
       "      <td>5896.461701</td>\n",
       "      <td>0.569549</td>\n",
       "      <td>405.940002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22489</th>\n",
       "      <td>2022-12-31 22:00:00</td>\n",
       "      <td>2022-12-31 20:00:00</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>42.045955</td>\n",
       "      <td>-77.218867</td>\n",
       "      <td>9.118555</td>\n",
       "      <td>0.00711</td>\n",
       "      <td>8.145227</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>0.285457</td>\n",
       "      <td>...</td>\n",
       "      <td>5.217391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.124478</td>\n",
       "      <td>5896.461701</td>\n",
       "      <td>0.569549</td>\n",
       "      <td>405.940002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22490</th>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>2022-12-31 21:00:00</td>\n",
       "      <td>ADDI</td>\n",
       "      <td>42.045955</td>\n",
       "      <td>-77.218867</td>\n",
       "      <td>8.866113</td>\n",
       "      <td>0.00724</td>\n",
       "      <td>8.439722</td>\n",
       "      <td>94.900002</td>\n",
       "      <td>0.120182</td>\n",
       "      <td>...</td>\n",
       "      <td>5.217391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.124478</td>\n",
       "      <td>5896.461701</td>\n",
       "      <td>0.569549</td>\n",
       "      <td>405.940002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22491 rows Ã— 731 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               valid_time                time station_ADDI  latitude_ADDI  \\\n",
       "0     2018-01-01 03:00:00 2018-01-01 01:00:00         ADDI      42.045955   \n",
       "1     2018-01-01 04:00:00 2018-01-01 02:00:00         ADDI      42.045955   \n",
       "2     2018-01-01 05:00:00 2018-01-01 03:00:00         ADDI      42.045955   \n",
       "3     2018-01-01 06:00:00 2018-01-01 04:00:00         ADDI      42.045955   \n",
       "4     2018-01-01 07:00:00 2018-01-01 05:00:00         ADDI      42.045955   \n",
       "...                   ...                 ...          ...            ...   \n",
       "22486 2022-12-31 19:00:00 2022-12-31 17:00:00         ADDI      42.045955   \n",
       "22487 2022-12-31 20:00:00 2022-12-31 18:00:00         ADDI      42.045955   \n",
       "22488 2022-12-31 21:00:00 2022-12-31 19:00:00         ADDI      42.045955   \n",
       "22489 2022-12-31 22:00:00 2022-12-31 20:00:00         ADDI      42.045955   \n",
       "22490 2022-12-31 23:00:00 2022-12-31 21:00:00         ADDI      42.045955   \n",
       "\n",
       "       longitude_ADDI   t2m_ADDI  sh2_ADDI   d2m_ADDI    r2_ADDI  u10_ADDI  \\\n",
       "0          -77.218867 -19.199194   0.00068 -21.993216  76.800003  3.321081   \n",
       "1          -77.218867 -19.118689   0.00068 -21.918570  76.500000  3.298830   \n",
       "2          -77.218867 -19.439062   0.00065 -22.570868  73.800003  2.992857   \n",
       "3          -77.218867 -19.760291   0.00063 -22.821158  74.400002  3.115693   \n",
       "4          -77.218867 -19.860175   0.00062 -22.993704  74.099998  3.268302   \n",
       "...               ...        ...       ...        ...        ...       ...   \n",
       "22486      -77.218867  11.485986   0.00710   8.142847  80.300003  0.073768   \n",
       "22487      -77.218867  10.447198   0.00676   7.376611  80.400002 -0.416093   \n",
       "22488      -77.218867   9.658258   0.00709   8.101648  88.000000  0.234075   \n",
       "22489      -77.218867   9.118555   0.00711   8.145227  92.000000  0.285457   \n",
       "22490      -77.218867   8.866113   0.00724   8.439722  94.900002  0.120182   \n",
       "\n",
       "       ...  26_aspect_RAND  31_aspect_RAND  33_aspect_RAND  32_aspect_RAND  \\\n",
       "0      ...        5.217391             0.0             0.0             0.0   \n",
       "1      ...        5.217391             0.0             0.0             0.0   \n",
       "2      ...        5.217391             0.0             0.0             0.0   \n",
       "3      ...        5.217391             0.0             0.0             0.0   \n",
       "4      ...        5.217391             0.0             0.0             0.0   \n",
       "...    ...             ...             ...             ...             ...   \n",
       "22486  ...        5.217391             0.0             0.0             0.0   \n",
       "22487  ...        5.217391             0.0             0.0             0.0   \n",
       "22488  ...        5.217391             0.0             0.0             0.0   \n",
       "22489  ...        5.217391             0.0             0.0             0.0   \n",
       "22490  ...        5.217391             0.0             0.0             0.0   \n",
       "\n",
       "       34_aspect_RAND  38_aspect_RAND  std_elev_RAND  variance_elev_RAND  \\\n",
       "0                 0.0             0.0      77.124478         5896.461701   \n",
       "1                 0.0             0.0      77.124478         5896.461701   \n",
       "2                 0.0             0.0      77.124478         5896.461701   \n",
       "3                 0.0             0.0      77.124478         5896.461701   \n",
       "4                 0.0             0.0      77.124478         5896.461701   \n",
       "...               ...             ...            ...                 ...   \n",
       "22486             0.0             0.0      77.124478         5896.461701   \n",
       "22487             0.0             0.0      77.124478         5896.461701   \n",
       "22488             0.0             0.0      77.124478         5896.461701   \n",
       "22489             0.0             0.0      77.124478         5896.461701   \n",
       "22490             0.0             0.0      77.124478         5896.461701   \n",
       "\n",
       "       skew_elev_RAND  med_dist_elev_RAND  \n",
       "0            0.569549          405.940002  \n",
       "1            0.569549          405.940002  \n",
       "2            0.569549          405.940002  \n",
       "3            0.569549          405.940002  \n",
       "4            0.569549          405.940002  \n",
       "...               ...                 ...  \n",
       "22486        0.569549          405.940002  \n",
       "22487        0.569549          405.940002  \n",
       "22488        0.569549          405.940002  \n",
       "22489        0.569549          405.940002  \n",
       "22490        0.569549          405.940002  \n",
       "\n",
       "[22491 rows x 731 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_time\n",
      "time\n",
      "station_ADDI\n",
      "latitude_ADDI\n",
      "longitude_ADDI\n",
      "t2m_ADDI\n",
      "sh2_ADDI\n",
      "d2m_ADDI\n",
      "r2_ADDI\n",
      "u10_ADDI\n",
      "v10_ADDI\n",
      "tp_ADDI\n",
      "mslma_ADDI\n",
      "orog_ADDI\n",
      "tcc_ADDI\n",
      "asnow_ADDI\n",
      "cape_ADDI\n",
      "dswrf_ADDI\n",
      "dlwrf_ADDI\n",
      "gh_ADDI\n",
      "u_total_ADDI\n",
      "u_dir_ADDI\n",
      "new_tp_ADDI\n",
      "lat_ADDI\n",
      "lon_ADDI\n",
      "elev_ADDI\n",
      "tair_ADDI\n",
      "ta9m_ADDI\n",
      "td_ADDI\n",
      "relh_ADDI\n",
      "srad_ADDI\n",
      "pres_ADDI\n",
      "mslp_ADDI\n",
      "wspd_sonic_ADDI\n",
      "wmax_sonic_ADDI\n",
      "wdir_sonic_ADDI\n",
      "precip_total_ADDI\n",
      "snow_depth_ADDI\n",
      "day_of_year_ADDI\n",
      "day_of_year_sin_ADDI\n",
      "day_of_year_cos_ADDI\n",
      "11_nlcd_ADDI\n",
      "21_nlcd_ADDI\n",
      "22_nlcd_ADDI\n",
      "23_nlcd_ADDI\n",
      "24_nlcd_ADDI\n",
      "31_nlcd_ADDI\n",
      "41_nlcd_ADDI\n",
      "42_nlcd_ADDI\n",
      "43_nlcd_ADDI\n",
      "52_nlcd_ADDI\n",
      "71_nlcd_ADDI\n",
      "81_nlcd_ADDI\n",
      "82_nlcd_ADDI\n",
      "90_nlcd_ADDI\n",
      "95_nlcd_ADDI\n",
      "19_aspect_ADDI\n",
      "21_aspect_ADDI\n",
      "24_aspect_ADDI\n",
      "27_aspect_ADDI\n",
      "28_aspect_ADDI\n",
      "22_aspect_ADDI\n",
      "23_aspect_ADDI\n",
      "25_aspect_ADDI\n",
      "26_aspect_ADDI\n",
      "31_aspect_ADDI\n",
      "33_aspect_ADDI\n",
      "32_aspect_ADDI\n",
      "34_aspect_ADDI\n",
      "38_aspect_ADDI\n",
      "std_elev_ADDI\n",
      "variance_elev_ADDI\n",
      "skew_elev_ADDI\n",
      "med_dist_elev_ADDI\n",
      "time_ADDI\n",
      "station\n",
      "latitude\n",
      "longitude\n",
      "t2m\n",
      "sh2\n",
      "d2m\n",
      "r2\n",
      "u10\n",
      "v10\n",
      "tp\n",
      "mslma\n",
      "orog\n",
      "tcc\n",
      "asnow\n",
      "cape\n",
      "dswrf\n",
      "dlwrf\n",
      "gh\n",
      "u_total\n",
      "u_dir\n",
      "new_tp\n",
      "lat\n",
      "lon\n",
      "elev\n",
      "tair\n",
      "ta9m\n",
      "td\n",
      "relh\n",
      "srad\n",
      "pres\n",
      "mslp\n",
      "wspd_sonic\n",
      "wmax_sonic\n",
      "wdir_sonic\n",
      "precip_total\n",
      "snow_depth\n",
      "day_of_year\n",
      "day_of_year_sin\n",
      "day_of_year_cos\n",
      "11_nlcd\n",
      "21_nlcd\n",
      "22_nlcd\n",
      "23_nlcd\n",
      "24_nlcd\n",
      "31_nlcd\n",
      "41_nlcd\n",
      "42_nlcd\n",
      "43_nlcd\n",
      "52_nlcd\n",
      "71_nlcd\n",
      "81_nlcd\n",
      "82_nlcd\n",
      "90_nlcd\n",
      "95_nlcd\n",
      "19_aspect\n",
      "21_aspect\n",
      "24_aspect\n",
      "27_aspect\n",
      "28_aspect\n",
      "22_aspect\n",
      "23_aspect\n",
      "25_aspect\n",
      "26_aspect\n",
      "31_aspect\n",
      "33_aspect\n",
      "32_aspect\n",
      "34_aspect\n",
      "38_aspect\n",
      "std_elev\n",
      "variance_elev\n",
      "skew_elev\n",
      "med_dist_elev\n",
      "time_BELM\n",
      "station_BELM\n",
      "latitude_BELM\n",
      "longitude_BELM\n",
      "t2m_BELM\n",
      "sh2_BELM\n",
      "d2m_BELM\n",
      "r2_BELM\n",
      "u10_BELM\n",
      "v10_BELM\n",
      "tp_BELM\n",
      "mslma_BELM\n",
      "orog_BELM\n",
      "tcc_BELM\n",
      "asnow_BELM\n",
      "cape_BELM\n",
      "dswrf_BELM\n",
      "dlwrf_BELM\n",
      "gh_BELM\n",
      "u_total_BELM\n",
      "u_dir_BELM\n",
      "new_tp_BELM\n",
      "lat_BELM\n",
      "lon_BELM\n",
      "elev_BELM\n",
      "tair_BELM\n",
      "ta9m_BELM\n",
      "td_BELM\n",
      "relh_BELM\n",
      "srad_BELM\n",
      "pres_BELM\n",
      "mslp_BELM\n",
      "wspd_sonic_BELM\n",
      "wmax_sonic_BELM\n",
      "wdir_sonic_BELM\n",
      "precip_total_BELM\n",
      "snow_depth_BELM\n",
      "day_of_year_BELM\n",
      "day_of_year_sin_BELM\n",
      "day_of_year_cos_BELM\n",
      "11_nlcd_BELM\n",
      "21_nlcd_BELM\n",
      "22_nlcd_BELM\n",
      "23_nlcd_BELM\n",
      "24_nlcd_BELM\n",
      "31_nlcd_BELM\n",
      "41_nlcd_BELM\n",
      "42_nlcd_BELM\n",
      "43_nlcd_BELM\n",
      "52_nlcd_BELM\n",
      "71_nlcd_BELM\n",
      "81_nlcd_BELM\n",
      "82_nlcd_BELM\n",
      "90_nlcd_BELM\n",
      "95_nlcd_BELM\n",
      "19_aspect_BELM\n",
      "21_aspect_BELM\n",
      "24_aspect_BELM\n",
      "27_aspect_BELM\n",
      "28_aspect_BELM\n",
      "22_aspect_BELM\n",
      "23_aspect_BELM\n",
      "25_aspect_BELM\n",
      "26_aspect_BELM\n",
      "31_aspect_BELM\n",
      "33_aspect_BELM\n",
      "32_aspect_BELM\n",
      "34_aspect_BELM\n",
      "38_aspect_BELM\n",
      "std_elev_BELM\n",
      "variance_elev_BELM\n",
      "skew_elev_BELM\n",
      "med_dist_elev_BELM\n",
      "time_COHO\n",
      "station_COHO\n",
      "latitude_COHO\n",
      "longitude_COHO\n",
      "t2m_COHO\n",
      "sh2_COHO\n",
      "d2m_COHO\n",
      "r2_COHO\n",
      "u10_COHO\n",
      "v10_COHO\n",
      "tp_COHO\n",
      "mslma_COHO\n",
      "orog_COHO\n",
      "tcc_COHO\n",
      "asnow_COHO\n",
      "cape_COHO\n",
      "dswrf_COHO\n",
      "dlwrf_COHO\n",
      "gh_COHO\n",
      "u_total_COHO\n",
      "u_dir_COHO\n",
      "new_tp_COHO\n",
      "lat_COHO\n",
      "lon_COHO\n",
      "elev_COHO\n",
      "tair_COHO\n",
      "ta9m_COHO\n",
      "td_COHO\n",
      "relh_COHO\n",
      "srad_COHO\n",
      "pres_COHO\n",
      "mslp_COHO\n",
      "wspd_sonic_COHO\n",
      "wmax_sonic_COHO\n",
      "wdir_sonic_COHO\n",
      "precip_total_COHO\n",
      "snow_depth_COHO\n",
      "day_of_year_COHO\n",
      "day_of_year_sin_COHO\n",
      "day_of_year_cos_COHO\n",
      "11_nlcd_COHO\n",
      "21_nlcd_COHO\n",
      "22_nlcd_COHO\n",
      "23_nlcd_COHO\n",
      "24_nlcd_COHO\n",
      "31_nlcd_COHO\n",
      "41_nlcd_COHO\n",
      "42_nlcd_COHO\n",
      "43_nlcd_COHO\n",
      "52_nlcd_COHO\n",
      "71_nlcd_COHO\n",
      "81_nlcd_COHO\n",
      "82_nlcd_COHO\n",
      "90_nlcd_COHO\n",
      "95_nlcd_COHO\n",
      "19_aspect_COHO\n",
      "21_aspect_COHO\n",
      "24_aspect_COHO\n",
      "27_aspect_COHO\n",
      "28_aspect_COHO\n",
      "22_aspect_COHO\n",
      "23_aspect_COHO\n",
      "25_aspect_COHO\n",
      "26_aspect_COHO\n",
      "31_aspect_COHO\n",
      "33_aspect_COHO\n",
      "32_aspect_COHO\n",
      "34_aspect_COHO\n",
      "38_aspect_COHO\n",
      "std_elev_COHO\n",
      "variance_elev_COHO\n",
      "skew_elev_COHO\n",
      "med_dist_elev_COHO\n",
      "time_DELE\n",
      "station_DELE\n",
      "latitude_DELE\n",
      "longitude_DELE\n",
      "t2m_DELE\n",
      "sh2_DELE\n",
      "d2m_DELE\n",
      "r2_DELE\n",
      "u10_DELE\n",
      "v10_DELE\n",
      "tp_DELE\n",
      "mslma_DELE\n",
      "orog_DELE\n",
      "tcc_DELE\n",
      "asnow_DELE\n",
      "cape_DELE\n",
      "dswrf_DELE\n",
      "dlwrf_DELE\n",
      "gh_DELE\n",
      "u_total_DELE\n",
      "u_dir_DELE\n",
      "new_tp_DELE\n",
      "lat_DELE\n",
      "lon_DELE\n",
      "elev_DELE\n",
      "tair_DELE\n",
      "ta9m_DELE\n",
      "td_DELE\n",
      "relh_DELE\n",
      "srad_DELE\n",
      "pres_DELE\n",
      "mslp_DELE\n",
      "wspd_sonic_DELE\n",
      "wmax_sonic_DELE\n",
      "wdir_sonic_DELE\n",
      "precip_total_DELE\n",
      "snow_depth_DELE\n",
      "day_of_year_DELE\n",
      "day_of_year_sin_DELE\n",
      "day_of_year_cos_DELE\n",
      "11_nlcd_DELE\n",
      "21_nlcd_DELE\n",
      "22_nlcd_DELE\n",
      "23_nlcd_DELE\n",
      "24_nlcd_DELE\n",
      "31_nlcd_DELE\n",
      "41_nlcd_DELE\n",
      "42_nlcd_DELE\n",
      "43_nlcd_DELE\n",
      "52_nlcd_DELE\n",
      "71_nlcd_DELE\n",
      "81_nlcd_DELE\n",
      "82_nlcd_DELE\n",
      "90_nlcd_DELE\n",
      "95_nlcd_DELE\n",
      "19_aspect_DELE\n",
      "21_aspect_DELE\n",
      "24_aspect_DELE\n",
      "27_aspect_DELE\n",
      "28_aspect_DELE\n",
      "22_aspect_DELE\n",
      "23_aspect_DELE\n",
      "25_aspect_DELE\n",
      "26_aspect_DELE\n",
      "31_aspect_DELE\n",
      "33_aspect_DELE\n",
      "32_aspect_DELE\n",
      "34_aspect_DELE\n",
      "38_aspect_DELE\n",
      "std_elev_DELE\n",
      "variance_elev_DELE\n",
      "skew_elev_DELE\n",
      "med_dist_elev_DELE\n",
      "time_ELMI\n",
      "station_ELMI\n",
      "latitude_ELMI\n",
      "longitude_ELMI\n",
      "t2m_ELMI\n",
      "sh2_ELMI\n",
      "d2m_ELMI\n",
      "r2_ELMI\n",
      "u10_ELMI\n",
      "v10_ELMI\n",
      "tp_ELMI\n",
      "mslma_ELMI\n",
      "orog_ELMI\n",
      "tcc_ELMI\n",
      "asnow_ELMI\n",
      "cape_ELMI\n",
      "dswrf_ELMI\n",
      "dlwrf_ELMI\n",
      "gh_ELMI\n",
      "u_total_ELMI\n",
      "u_dir_ELMI\n",
      "new_tp_ELMI\n",
      "lat_ELMI\n",
      "lon_ELMI\n",
      "elev_ELMI\n",
      "tair_ELMI\n",
      "ta9m_ELMI\n",
      "td_ELMI\n",
      "relh_ELMI\n",
      "srad_ELMI\n",
      "pres_ELMI\n",
      "mslp_ELMI\n",
      "wspd_sonic_ELMI\n",
      "wmax_sonic_ELMI\n",
      "wdir_sonic_ELMI\n",
      "precip_total_ELMI\n",
      "snow_depth_ELMI\n",
      "day_of_year_ELMI\n",
      "day_of_year_sin_ELMI\n",
      "day_of_year_cos_ELMI\n",
      "11_nlcd_ELMI\n",
      "21_nlcd_ELMI\n",
      "22_nlcd_ELMI\n",
      "23_nlcd_ELMI\n",
      "24_nlcd_ELMI\n",
      "31_nlcd_ELMI\n",
      "41_nlcd_ELMI\n",
      "42_nlcd_ELMI\n",
      "43_nlcd_ELMI\n",
      "52_nlcd_ELMI\n",
      "71_nlcd_ELMI\n",
      "81_nlcd_ELMI\n",
      "82_nlcd_ELMI\n",
      "90_nlcd_ELMI\n",
      "95_nlcd_ELMI\n",
      "19_aspect_ELMI\n",
      "21_aspect_ELMI\n",
      "24_aspect_ELMI\n",
      "27_aspect_ELMI\n",
      "28_aspect_ELMI\n",
      "22_aspect_ELMI\n",
      "23_aspect_ELMI\n",
      "25_aspect_ELMI\n",
      "26_aspect_ELMI\n",
      "31_aspect_ELMI\n",
      "33_aspect_ELMI\n",
      "32_aspect_ELMI\n",
      "34_aspect_ELMI\n",
      "38_aspect_ELMI\n",
      "std_elev_ELMI\n",
      "variance_elev_ELMI\n",
      "skew_elev_ELMI\n",
      "med_dist_elev_ELMI\n",
      "time_GROV\n",
      "station_GROV\n",
      "latitude_GROV\n",
      "longitude_GROV\n",
      "t2m_GROV\n",
      "sh2_GROV\n",
      "d2m_GROV\n",
      "r2_GROV\n",
      "u10_GROV\n",
      "v10_GROV\n",
      "tp_GROV\n",
      "mslma_GROV\n",
      "orog_GROV\n",
      "tcc_GROV\n",
      "asnow_GROV\n",
      "cape_GROV\n",
      "dswrf_GROV\n",
      "dlwrf_GROV\n",
      "gh_GROV\n",
      "u_total_GROV\n",
      "u_dir_GROV\n",
      "new_tp_GROV\n",
      "lat_GROV\n",
      "lon_GROV\n",
      "elev_GROV\n",
      "tair_GROV\n",
      "ta9m_GROV\n",
      "td_GROV\n",
      "relh_GROV\n",
      "srad_GROV\n",
      "pres_GROV\n",
      "mslp_GROV\n",
      "wspd_sonic_GROV\n",
      "wmax_sonic_GROV\n",
      "wdir_sonic_GROV\n",
      "precip_total_GROV\n",
      "snow_depth_GROV\n",
      "day_of_year_GROV\n",
      "day_of_year_sin_GROV\n",
      "day_of_year_cos_GROV\n",
      "11_nlcd_GROV\n",
      "21_nlcd_GROV\n",
      "22_nlcd_GROV\n",
      "23_nlcd_GROV\n",
      "24_nlcd_GROV\n",
      "31_nlcd_GROV\n",
      "41_nlcd_GROV\n",
      "42_nlcd_GROV\n",
      "43_nlcd_GROV\n",
      "52_nlcd_GROV\n",
      "71_nlcd_GROV\n",
      "81_nlcd_GROV\n",
      "82_nlcd_GROV\n",
      "90_nlcd_GROV\n",
      "95_nlcd_GROV\n",
      "19_aspect_GROV\n",
      "21_aspect_GROV\n",
      "24_aspect_GROV\n",
      "27_aspect_GROV\n",
      "28_aspect_GROV\n",
      "22_aspect_GROV\n",
      "23_aspect_GROV\n",
      "25_aspect_GROV\n",
      "26_aspect_GROV\n",
      "31_aspect_GROV\n",
      "33_aspect_GROV\n",
      "32_aspect_GROV\n",
      "34_aspect_GROV\n",
      "38_aspect_GROV\n",
      "std_elev_GROV\n",
      "variance_elev_GROV\n",
      "skew_elev_GROV\n",
      "med_dist_elev_GROV\n",
      "time_HART\n",
      "station_HART\n",
      "latitude_HART\n",
      "longitude_HART\n",
      "t2m_HART\n",
      "sh2_HART\n",
      "d2m_HART\n",
      "r2_HART\n",
      "u10_HART\n",
      "v10_HART\n",
      "tp_HART\n",
      "mslma_HART\n",
      "orog_HART\n",
      "tcc_HART\n",
      "asnow_HART\n",
      "cape_HART\n",
      "dswrf_HART\n",
      "dlwrf_HART\n",
      "gh_HART\n",
      "u_total_HART\n",
      "u_dir_HART\n",
      "new_tp_HART\n",
      "lat_HART\n",
      "lon_HART\n",
      "elev_HART\n",
      "tair_HART\n",
      "ta9m_HART\n",
      "td_HART\n",
      "relh_HART\n",
      "srad_HART\n",
      "pres_HART\n",
      "mslp_HART\n",
      "wspd_sonic_HART\n",
      "wmax_sonic_HART\n",
      "wdir_sonic_HART\n",
      "precip_total_HART\n",
      "snow_depth_HART\n",
      "day_of_year_HART\n",
      "day_of_year_sin_HART\n",
      "day_of_year_cos_HART\n",
      "11_nlcd_HART\n",
      "21_nlcd_HART\n",
      "22_nlcd_HART\n",
      "23_nlcd_HART\n",
      "24_nlcd_HART\n",
      "31_nlcd_HART\n",
      "41_nlcd_HART\n",
      "42_nlcd_HART\n",
      "43_nlcd_HART\n",
      "52_nlcd_HART\n",
      "71_nlcd_HART\n",
      "81_nlcd_HART\n",
      "82_nlcd_HART\n",
      "90_nlcd_HART\n",
      "95_nlcd_HART\n",
      "19_aspect_HART\n",
      "21_aspect_HART\n",
      "24_aspect_HART\n",
      "27_aspect_HART\n",
      "28_aspect_HART\n",
      "22_aspect_HART\n",
      "23_aspect_HART\n",
      "25_aspect_HART\n",
      "26_aspect_HART\n",
      "31_aspect_HART\n",
      "33_aspect_HART\n",
      "32_aspect_HART\n",
      "34_aspect_HART\n",
      "38_aspect_HART\n",
      "std_elev_HART\n",
      "variance_elev_HART\n",
      "skew_elev_HART\n",
      "med_dist_elev_HART\n",
      "time_OLEA\n",
      "station_OLEA\n",
      "latitude_OLEA\n",
      "longitude_OLEA\n",
      "t2m_OLEA\n",
      "sh2_OLEA\n",
      "d2m_OLEA\n",
      "r2_OLEA\n",
      "u10_OLEA\n",
      "v10_OLEA\n",
      "tp_OLEA\n",
      "mslma_OLEA\n",
      "orog_OLEA\n",
      "tcc_OLEA\n",
      "asnow_OLEA\n",
      "cape_OLEA\n",
      "dswrf_OLEA\n",
      "dlwrf_OLEA\n",
      "gh_OLEA\n",
      "u_total_OLEA\n",
      "u_dir_OLEA\n",
      "new_tp_OLEA\n",
      "lat_OLEA\n",
      "lon_OLEA\n",
      "elev_OLEA\n",
      "tair_OLEA\n",
      "ta9m_OLEA\n",
      "td_OLEA\n",
      "relh_OLEA\n",
      "srad_OLEA\n",
      "pres_OLEA\n",
      "mslp_OLEA\n",
      "wspd_sonic_OLEA\n",
      "wmax_sonic_OLEA\n",
      "wdir_sonic_OLEA\n",
      "precip_total_OLEA\n",
      "snow_depth_OLEA\n",
      "day_of_year_OLEA\n",
      "day_of_year_sin_OLEA\n",
      "day_of_year_cos_OLEA\n",
      "11_nlcd_OLEA\n",
      "21_nlcd_OLEA\n",
      "22_nlcd_OLEA\n",
      "23_nlcd_OLEA\n",
      "24_nlcd_OLEA\n",
      "31_nlcd_OLEA\n",
      "41_nlcd_OLEA\n",
      "42_nlcd_OLEA\n",
      "43_nlcd_OLEA\n",
      "52_nlcd_OLEA\n",
      "71_nlcd_OLEA\n",
      "81_nlcd_OLEA\n",
      "82_nlcd_OLEA\n",
      "90_nlcd_OLEA\n",
      "95_nlcd_OLEA\n",
      "19_aspect_OLEA\n",
      "21_aspect_OLEA\n",
      "24_aspect_OLEA\n",
      "27_aspect_OLEA\n",
      "28_aspect_OLEA\n",
      "22_aspect_OLEA\n",
      "23_aspect_OLEA\n",
      "25_aspect_OLEA\n",
      "26_aspect_OLEA\n",
      "31_aspect_OLEA\n",
      "33_aspect_OLEA\n",
      "32_aspect_OLEA\n",
      "34_aspect_OLEA\n",
      "38_aspect_OLEA\n",
      "std_elev_OLEA\n",
      "variance_elev_OLEA\n",
      "skew_elev_OLEA\n",
      "med_dist_elev_OLEA\n",
      "time_RAND\n",
      "station_RAND\n",
      "latitude_RAND\n",
      "longitude_RAND\n",
      "t2m_RAND\n",
      "sh2_RAND\n",
      "d2m_RAND\n",
      "r2_RAND\n",
      "u10_RAND\n",
      "v10_RAND\n",
      "tp_RAND\n",
      "mslma_RAND\n",
      "orog_RAND\n",
      "tcc_RAND\n",
      "asnow_RAND\n",
      "cape_RAND\n",
      "dswrf_RAND\n",
      "dlwrf_RAND\n",
      "gh_RAND\n",
      "u_total_RAND\n",
      "u_dir_RAND\n",
      "new_tp_RAND\n",
      "lat_RAND\n",
      "lon_RAND\n",
      "elev_RAND\n",
      "tair_RAND\n",
      "ta9m_RAND\n",
      "td_RAND\n",
      "relh_RAND\n",
      "srad_RAND\n",
      "pres_RAND\n",
      "mslp_RAND\n",
      "wspd_sonic_RAND\n",
      "wmax_sonic_RAND\n",
      "wdir_sonic_RAND\n",
      "precip_total_RAND\n",
      "snow_depth_RAND\n",
      "day_of_year_RAND\n",
      "day_of_year_sin_RAND\n",
      "day_of_year_cos_RAND\n",
      "11_nlcd_RAND\n",
      "21_nlcd_RAND\n",
      "22_nlcd_RAND\n",
      "23_nlcd_RAND\n",
      "24_nlcd_RAND\n",
      "31_nlcd_RAND\n",
      "41_nlcd_RAND\n",
      "42_nlcd_RAND\n",
      "43_nlcd_RAND\n",
      "52_nlcd_RAND\n",
      "71_nlcd_RAND\n",
      "81_nlcd_RAND\n",
      "82_nlcd_RAND\n",
      "90_nlcd_RAND\n",
      "95_nlcd_RAND\n",
      "19_aspect_RAND\n",
      "21_aspect_RAND\n",
      "24_aspect_RAND\n",
      "27_aspect_RAND\n",
      "28_aspect_RAND\n",
      "22_aspect_RAND\n",
      "23_aspect_RAND\n",
      "25_aspect_RAND\n",
      "26_aspect_RAND\n",
      "31_aspect_RAND\n",
      "33_aspect_RAND\n",
      "32_aspect_RAND\n",
      "34_aspect_RAND\n",
      "38_aspect_RAND\n",
      "std_elev_RAND\n",
      "variance_elev_RAND\n",
      "skew_elev_RAND\n",
      "med_dist_elev_RAND\n"
     ]
    }
   ],
   "source": [
    "for k in df.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to reintigrate back into the df after model is done running\n",
    "cols_to_carry = cols_to_carry = [\n",
    "    \"valid_time\",\n",
    "    \"flag\",\n",
    "    \"day_of_year_sin\",\n",
    "    \"day_of_year_cos\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_flag(df)\n",
    "df = nwp_error(\"t2m\", \"ADDI\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_df(df, valid_times):\n",
    "    print(\"init normalizer\")\n",
    "    df = col_drop(df)\n",
    "    the_df = df.dropna()\n",
    "    for k, r in the_df.items():\n",
    "        if len(the_df[k].unique()) == 1:\n",
    "            org_str = str(k)\n",
    "            my_str = org_str[:-5]\n",
    "            vals = the_df.filter(regex=my_str)\n",
    "            vals = vals.loc[0].tolist()\n",
    "            means = st.mean(vals)\n",
    "            stdevs = st.pstdev(vals)\n",
    "            the_df[k] = (the_df[k] - means) / stdevs\n",
    "\n",
    "            the_df = the_df.fillna(0)\n",
    "            # |sh2|d2m|r2|u10|v10|tp|mslma|tcc|asnow|cape|dswrf|dlwrf|gh|utotal|u_dir|new_tp\n",
    "        if re.search(\n",
    "            \"t2m\",\n",
    "            k,\n",
    "        ):\n",
    "            ind_val = the_df.columns.get_loc(k)\n",
    "            x = the_df[k]\n",
    "            imf = emd.sift.sift(x)\n",
    "            the_df = the_df.drop(columns=k)\n",
    "            for i in range(imf.shape[1]):\n",
    "                imf_ls = imf[:, i].tolist()\n",
    "                # Inserting the column at the\n",
    "                # beginning in the DataFrame\n",
    "                my_loc = ind_val + i\n",
    "                the_df.insert(loc=(my_loc), column=f\"{k}_imf_{i}\", value=imf_ls)\n",
    "\n",
    "        else:\n",
    "            means = st.mean(the_df[k])\n",
    "            stdevs = st.pstdev(the_df[k])\n",
    "            the_df[k] = (the_df[k] - means) / stdevs\n",
    "\n",
    "    final_df = the_df.fillna(0)\n",
    "    print(\"!!! Dropping Columns !!!\")\n",
    "    final_df = final_df[final_df.columns.drop(list(final_df.filter(regex=\"latitude\")))]\n",
    "    final_df = final_df[final_df.columns.drop(list(final_df.filter(regex=\"longitude\")))]\n",
    "    final_df = final_df[final_df.columns.drop(list(final_df.filter(regex=\"u_total\")))]\n",
    "    final_df = final_df[final_df.columns.drop(list(final_df.filter(regex=\"mslp\")))]\n",
    "    final_df = final_df[final_df.columns.drop(list(final_df.filter(regex=\"orog\")))]\n",
    "\n",
    "    print(\"--- configuring data ---\")\n",
    "    final_df = encode(final_df, \"day_of_year\", 366, valid_times)\n",
    "    final_df = get_clim_indexes(final_df, valid_times)\n",
    "    new_features = list(final_df.columns.difference([\"target_error\"]))\n",
    "    print(\"---normalize successful---\")\n",
    "\n",
    "    return final_df, new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_df_station(df):\n",
    "    print(\"init normalizer\")\n",
    "    the_df = df.dropna()\n",
    "    for k, r in the_df.items():\n",
    "        if len(the_df[k].unique()) == 1:\n",
    "            org_str = str(k)\n",
    "            my_str = org_str[:-5]\n",
    "            vals = the_df.filter(regex=my_str)\n",
    "            vals = vals.loc[0].tolist()\n",
    "            means = st.mean(vals)\n",
    "            stdevs = st.pstdev(vals)\n",
    "            the_df[k] = (the_df[k] - means) / stdevs\n",
    "\n",
    "            the_df = the_df.fillna(0)\n",
    "        if not (len(the_df[k].unique()) == 1) and re.search(\"_ADDI\", k):\n",
    "            ind_val = the_df.columns.get_loc(k)\n",
    "            x = the_df[k]\n",
    "            imf = emd.sift.sift(x)\n",
    "            the_df = the_df.drop(columns=k)\n",
    "            for i in range(imf.shape[1]):\n",
    "                imf_ls = imf[:, i].tolist()\n",
    "                # Inserting the column at the\n",
    "                # beginning in the DataFrame\n",
    "                my_loc = ind_val + i\n",
    "                the_df.insert(loc=(my_loc), column=f\"{k}_imf_{i}\", value=imf_ls)\n",
    "\n",
    "        else:\n",
    "            means = st.mean(the_df[k])\n",
    "            stdevs = st.pstdev(the_df[k])\n",
    "            the_df[k] = (the_df[k] - means) / stdevs\n",
    "\n",
    "    final_df = the_df.fillna(0)\n",
    "    print(\"!!! Dropping Columns !!!\")\n",
    "    final_df = final_df[final_df.columns.drop(list(final_df.filter(regex=\"latitude\")))]\n",
    "    final_df = final_df[final_df.columns.drop(list(final_df.filter(regex=\"longitude\")))]\n",
    "    final_df = final_df[final_df.columns.drop(list(final_df.filter(regex=\"u_total\")))]\n",
    "    final_df = final_df[final_df.columns.drop(list(final_df.filter(regex=\"mslp\")))]\n",
    "    final_df = final_df[final_df.columns.drop(list(final_df.filter(regex=\"orog\")))]\n",
    "    new_features = list(final_df.columns.difference([\"target_error\"]))\n",
    "    print(\"---normalize successful---\")\n",
    "    return final_df, new_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init normalizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aevans/miniconda3/lib/python3.9/site-packages/emd/support.py:228: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  out_args[idx] = out_args[idx][:, np.newaxis]\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/home/aevans/miniconda3/lib/python3.9/site-packages/emd/support.py:228: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  out_args[idx] = out_args[idx][:, np.newaxis]\n",
      "/home/aevans/miniconda3/lib/python3.9/site-packages/emd/support.py:228: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  out_args[idx] = out_args[idx][:, np.newaxis]\n",
      "/home/aevans/miniconda3/lib/python3.9/site-packages/emd/support.py:228: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  out_args[idx] = out_args[idx][:, np.newaxis]\n",
      "/home/aevans/miniconda3/lib/python3.9/site-packages/emd/support.py:228: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  out_args[idx] = out_args[idx][:, np.newaxis]\n",
      "/home/aevans/miniconda3/lib/python3.9/site-packages/emd/support.py:228: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  out_args[idx] = out_args[idx][:, np.newaxis]\n",
      "/home/aevans/miniconda3/lib/python3.9/site-packages/emd/support.py:228: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  out_args[idx] = out_args[idx][:, np.newaxis]\n",
      "/home/aevans/miniconda3/lib/python3.9/site-packages/emd/support.py:228: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  out_args[idx] = out_args[idx][:, np.newaxis]\n",
      "/home/aevans/miniconda3/lib/python3.9/site-packages/emd/support.py:228: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  out_args[idx] = out_args[idx][:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! Dropping Columns !!!\n",
      "--- configuring data ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/tmp.gNAUv8vyfv/ipykernel_3491586/1737720168.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"day_of_year\"] = data[\"valid_time\"].dt.dayofyear\n",
      "/tmp/tmp.gNAUv8vyfv/ipykernel_3491586/1737720168.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col + \"_sin\"] = np.sin(2 * np.pi * data[col] / max_val).astype(float)\n",
      "/tmp/tmp.gNAUv8vyfv/ipykernel_3491586/1737720168.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[col + \"_cos\"] = np.cos(2 * np.pi * data[col] / max_val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---normalize successful---\n"
     ]
    }
   ],
   "source": [
    "target_sensor = \"target_error\"\n",
    "the_df, new_features = normalize_df(new_df, valid_times)\n",
    "\n",
    "forecast_lead = 30\n",
    "target = f\"{target_sensor}_lead_{forecast_lead}\"\n",
    "\n",
    "the_df[target] = the_df[target_sensor].shift(-forecast_lead)\n",
    "the_df = the_df.iloc[:-forecast_lead]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t2m_ADDI_imf_0\n",
      "t2m_ADDI_imf_1\n",
      "t2m_ADDI_imf_2\n",
      "t2m_ADDI_imf_3\n",
      "t2m_ADDI_imf_4\n",
      "t2m_ADDI_imf_5\n",
      "t2m_ADDI_imf_6\n",
      "t2m_ADDI_imf_7\n",
      "t2m_ADDI_imf_8\n",
      "t2m_ADDI_imf_9\n",
      "sh2_ADDI\n",
      "d2m_ADDI\n",
      "r2_ADDI\n",
      "u10_ADDI\n",
      "v10_ADDI\n",
      "tp_ADDI\n",
      "mslma_ADDI\n",
      "tcc_ADDI\n",
      "asnow_ADDI\n",
      "cape_ADDI\n",
      "dswrf_ADDI\n",
      "dlwrf_ADDI\n",
      "gh_ADDI\n",
      "u_dir_ADDI\n",
      "new_tp_ADDI\n",
      "lat_ADDI\n",
      "lon_ADDI\n",
      "elev_ADDI\n",
      "11_nlcd_ADDI\n",
      "21_nlcd_ADDI\n",
      "22_nlcd_ADDI\n",
      "23_nlcd_ADDI\n",
      "24_nlcd_ADDI\n",
      "31_nlcd_ADDI\n",
      "41_nlcd_ADDI\n",
      "42_nlcd_ADDI\n",
      "43_nlcd_ADDI\n",
      "52_nlcd_ADDI\n",
      "71_nlcd_ADDI\n",
      "81_nlcd_ADDI\n",
      "82_nlcd_ADDI\n",
      "90_nlcd_ADDI\n",
      "95_nlcd_ADDI\n",
      "19_aspect_ADDI\n",
      "21_aspect_ADDI\n",
      "24_aspect_ADDI\n",
      "27_aspect_ADDI\n",
      "28_aspect_ADDI\n",
      "22_aspect_ADDI\n",
      "23_aspect_ADDI\n",
      "25_aspect_ADDI\n",
      "26_aspect_ADDI\n",
      "31_aspect_ADDI\n",
      "33_aspect_ADDI\n",
      "32_aspect_ADDI\n",
      "34_aspect_ADDI\n",
      "38_aspect_ADDI\n",
      "variance_elev_ADDI\n",
      "skew_elev_ADDI\n",
      "med_dist_elev_ADDI\n",
      "t2m_BELM_imf_0\n",
      "t2m_BELM_imf_1\n",
      "t2m_BELM_imf_2\n",
      "t2m_BELM_imf_3\n",
      "t2m_BELM_imf_4\n",
      "t2m_BELM_imf_5\n",
      "t2m_BELM_imf_6\n",
      "t2m_BELM_imf_7\n",
      "t2m_BELM_imf_8\n",
      "t2m_BELM_imf_9\n",
      "sh2_BELM\n",
      "d2m_BELM\n",
      "r2_BELM\n",
      "u10_BELM\n",
      "v10_BELM\n",
      "tp_BELM\n",
      "mslma_BELM\n",
      "tcc_BELM\n",
      "asnow_BELM\n",
      "cape_BELM\n",
      "dswrf_BELM\n",
      "dlwrf_BELM\n",
      "gh_BELM\n",
      "u_dir_BELM\n",
      "new_tp_BELM\n",
      "lat_BELM\n",
      "lon_BELM\n",
      "elev_BELM\n",
      "11_nlcd_BELM\n",
      "21_nlcd_BELM\n",
      "22_nlcd_BELM\n",
      "23_nlcd_BELM\n",
      "24_nlcd_BELM\n",
      "31_nlcd_BELM\n",
      "41_nlcd_BELM\n",
      "42_nlcd_BELM\n",
      "43_nlcd_BELM\n",
      "52_nlcd_BELM\n",
      "71_nlcd_BELM\n",
      "81_nlcd_BELM\n",
      "82_nlcd_BELM\n",
      "90_nlcd_BELM\n",
      "95_nlcd_BELM\n",
      "19_aspect_BELM\n",
      "21_aspect_BELM\n",
      "24_aspect_BELM\n",
      "27_aspect_BELM\n",
      "28_aspect_BELM\n",
      "22_aspect_BELM\n",
      "23_aspect_BELM\n",
      "25_aspect_BELM\n",
      "26_aspect_BELM\n",
      "31_aspect_BELM\n",
      "33_aspect_BELM\n",
      "32_aspect_BELM\n",
      "34_aspect_BELM\n",
      "38_aspect_BELM\n",
      "variance_elev_BELM\n",
      "skew_elev_BELM\n",
      "med_dist_elev_BELM\n",
      "t2m_COHO_imf_0\n",
      "t2m_COHO_imf_1\n",
      "t2m_COHO_imf_2\n",
      "t2m_COHO_imf_3\n",
      "t2m_COHO_imf_4\n",
      "t2m_COHO_imf_5\n",
      "t2m_COHO_imf_6\n",
      "t2m_COHO_imf_7\n",
      "t2m_COHO_imf_8\n",
      "t2m_COHO_imf_9\n",
      "sh2_COHO\n",
      "d2m_COHO\n",
      "r2_COHO\n",
      "u10_COHO\n",
      "v10_COHO\n",
      "tp_COHO\n",
      "mslma_COHO\n",
      "tcc_COHO\n",
      "asnow_COHO\n",
      "cape_COHO\n",
      "dswrf_COHO\n",
      "dlwrf_COHO\n",
      "gh_COHO\n",
      "u_dir_COHO\n",
      "new_tp_COHO\n",
      "lat_COHO\n",
      "lon_COHO\n",
      "elev_COHO\n",
      "11_nlcd_COHO\n",
      "21_nlcd_COHO\n",
      "22_nlcd_COHO\n",
      "23_nlcd_COHO\n",
      "24_nlcd_COHO\n",
      "31_nlcd_COHO\n",
      "41_nlcd_COHO\n",
      "42_nlcd_COHO\n",
      "43_nlcd_COHO\n",
      "52_nlcd_COHO\n",
      "71_nlcd_COHO\n",
      "81_nlcd_COHO\n",
      "82_nlcd_COHO\n",
      "90_nlcd_COHO\n",
      "95_nlcd_COHO\n",
      "19_aspect_COHO\n",
      "21_aspect_COHO\n",
      "24_aspect_COHO\n",
      "27_aspect_COHO\n",
      "28_aspect_COHO\n",
      "22_aspect_COHO\n",
      "23_aspect_COHO\n",
      "25_aspect_COHO\n",
      "26_aspect_COHO\n",
      "31_aspect_COHO\n",
      "33_aspect_COHO\n",
      "32_aspect_COHO\n",
      "34_aspect_COHO\n",
      "38_aspect_COHO\n",
      "variance_elev_COHO\n",
      "skew_elev_COHO\n",
      "med_dist_elev_COHO\n",
      "t2m_DELE_imf_0\n",
      "t2m_DELE_imf_1\n",
      "t2m_DELE_imf_2\n",
      "t2m_DELE_imf_3\n",
      "t2m_DELE_imf_4\n",
      "t2m_DELE_imf_5\n",
      "t2m_DELE_imf_6\n",
      "t2m_DELE_imf_7\n",
      "t2m_DELE_imf_8\n",
      "t2m_DELE_imf_9\n",
      "sh2_DELE\n",
      "d2m_DELE\n",
      "r2_DELE\n",
      "u10_DELE\n",
      "v10_DELE\n",
      "tp_DELE\n",
      "mslma_DELE\n",
      "tcc_DELE\n",
      "asnow_DELE\n",
      "cape_DELE\n",
      "dswrf_DELE\n",
      "dlwrf_DELE\n",
      "gh_DELE\n",
      "u_dir_DELE\n",
      "new_tp_DELE\n",
      "lat_DELE\n",
      "lon_DELE\n",
      "elev_DELE\n",
      "11_nlcd_DELE\n",
      "21_nlcd_DELE\n",
      "22_nlcd_DELE\n",
      "23_nlcd_DELE\n",
      "24_nlcd_DELE\n",
      "31_nlcd_DELE\n",
      "41_nlcd_DELE\n",
      "42_nlcd_DELE\n",
      "43_nlcd_DELE\n",
      "52_nlcd_DELE\n",
      "71_nlcd_DELE\n",
      "81_nlcd_DELE\n",
      "82_nlcd_DELE\n",
      "90_nlcd_DELE\n",
      "95_nlcd_DELE\n",
      "19_aspect_DELE\n",
      "21_aspect_DELE\n",
      "24_aspect_DELE\n",
      "27_aspect_DELE\n",
      "28_aspect_DELE\n",
      "22_aspect_DELE\n",
      "23_aspect_DELE\n",
      "25_aspect_DELE\n",
      "26_aspect_DELE\n",
      "31_aspect_DELE\n",
      "33_aspect_DELE\n",
      "32_aspect_DELE\n",
      "34_aspect_DELE\n",
      "38_aspect_DELE\n",
      "variance_elev_DELE\n",
      "skew_elev_DELE\n",
      "med_dist_elev_DELE\n",
      "t2m_ELMI_imf_0\n",
      "t2m_ELMI_imf_1\n",
      "t2m_ELMI_imf_2\n",
      "t2m_ELMI_imf_3\n",
      "t2m_ELMI_imf_4\n",
      "t2m_ELMI_imf_5\n",
      "t2m_ELMI_imf_6\n",
      "t2m_ELMI_imf_7\n",
      "t2m_ELMI_imf_8\n",
      "t2m_ELMI_imf_9\n",
      "sh2_ELMI\n",
      "d2m_ELMI\n",
      "r2_ELMI\n",
      "u10_ELMI\n",
      "v10_ELMI\n",
      "tp_ELMI\n",
      "mslma_ELMI\n",
      "tcc_ELMI\n",
      "asnow_ELMI\n",
      "cape_ELMI\n",
      "dswrf_ELMI\n",
      "dlwrf_ELMI\n",
      "gh_ELMI\n",
      "u_dir_ELMI\n",
      "new_tp_ELMI\n",
      "lat_ELMI\n",
      "lon_ELMI\n",
      "elev_ELMI\n",
      "11_nlcd_ELMI\n",
      "21_nlcd_ELMI\n",
      "22_nlcd_ELMI\n",
      "23_nlcd_ELMI\n",
      "24_nlcd_ELMI\n",
      "31_nlcd_ELMI\n",
      "41_nlcd_ELMI\n",
      "42_nlcd_ELMI\n",
      "43_nlcd_ELMI\n",
      "52_nlcd_ELMI\n",
      "71_nlcd_ELMI\n",
      "81_nlcd_ELMI\n",
      "82_nlcd_ELMI\n",
      "90_nlcd_ELMI\n",
      "95_nlcd_ELMI\n",
      "19_aspect_ELMI\n",
      "21_aspect_ELMI\n",
      "24_aspect_ELMI\n",
      "27_aspect_ELMI\n",
      "28_aspect_ELMI\n",
      "22_aspect_ELMI\n",
      "23_aspect_ELMI\n",
      "25_aspect_ELMI\n",
      "26_aspect_ELMI\n",
      "31_aspect_ELMI\n",
      "33_aspect_ELMI\n",
      "32_aspect_ELMI\n",
      "34_aspect_ELMI\n",
      "38_aspect_ELMI\n",
      "variance_elev_ELMI\n",
      "skew_elev_ELMI\n",
      "med_dist_elev_ELMI\n",
      "t2m_GROV_imf_0\n",
      "t2m_GROV_imf_1\n",
      "t2m_GROV_imf_2\n",
      "t2m_GROV_imf_3\n",
      "t2m_GROV_imf_4\n",
      "t2m_GROV_imf_5\n",
      "t2m_GROV_imf_6\n",
      "t2m_GROV_imf_7\n",
      "t2m_GROV_imf_8\n",
      "t2m_GROV_imf_9\n",
      "sh2_GROV\n",
      "d2m_GROV\n",
      "r2_GROV\n",
      "u10_GROV\n",
      "v10_GROV\n",
      "tp_GROV\n",
      "mslma_GROV\n",
      "tcc_GROV\n",
      "asnow_GROV\n",
      "cape_GROV\n",
      "dswrf_GROV\n",
      "dlwrf_GROV\n",
      "gh_GROV\n",
      "u_dir_GROV\n",
      "new_tp_GROV\n",
      "lat_GROV\n",
      "lon_GROV\n",
      "elev_GROV\n",
      "11_nlcd_GROV\n",
      "21_nlcd_GROV\n",
      "22_nlcd_GROV\n",
      "23_nlcd_GROV\n",
      "24_nlcd_GROV\n",
      "31_nlcd_GROV\n",
      "41_nlcd_GROV\n",
      "42_nlcd_GROV\n",
      "43_nlcd_GROV\n",
      "52_nlcd_GROV\n",
      "71_nlcd_GROV\n",
      "81_nlcd_GROV\n",
      "82_nlcd_GROV\n",
      "90_nlcd_GROV\n",
      "95_nlcd_GROV\n",
      "19_aspect_GROV\n",
      "21_aspect_GROV\n",
      "24_aspect_GROV\n",
      "27_aspect_GROV\n",
      "28_aspect_GROV\n",
      "22_aspect_GROV\n",
      "23_aspect_GROV\n",
      "25_aspect_GROV\n",
      "26_aspect_GROV\n",
      "31_aspect_GROV\n",
      "33_aspect_GROV\n",
      "32_aspect_GROV\n",
      "34_aspect_GROV\n",
      "38_aspect_GROV\n",
      "variance_elev_GROV\n",
      "skew_elev_GROV\n",
      "med_dist_elev_GROV\n",
      "t2m_HART_imf_0\n",
      "t2m_HART_imf_1\n",
      "t2m_HART_imf_2\n",
      "t2m_HART_imf_3\n",
      "t2m_HART_imf_4\n",
      "t2m_HART_imf_5\n",
      "t2m_HART_imf_6\n",
      "t2m_HART_imf_7\n",
      "t2m_HART_imf_8\n",
      "t2m_HART_imf_9\n",
      "sh2_HART\n",
      "d2m_HART\n",
      "r2_HART\n",
      "u10_HART\n",
      "v10_HART\n",
      "tp_HART\n",
      "mslma_HART\n",
      "tcc_HART\n",
      "asnow_HART\n",
      "cape_HART\n",
      "dswrf_HART\n",
      "dlwrf_HART\n",
      "gh_HART\n",
      "u_dir_HART\n",
      "new_tp_HART\n",
      "lat_HART\n",
      "lon_HART\n",
      "elev_HART\n",
      "11_nlcd_HART\n",
      "21_nlcd_HART\n",
      "22_nlcd_HART\n",
      "23_nlcd_HART\n",
      "24_nlcd_HART\n",
      "31_nlcd_HART\n",
      "41_nlcd_HART\n",
      "42_nlcd_HART\n",
      "43_nlcd_HART\n",
      "52_nlcd_HART\n",
      "71_nlcd_HART\n",
      "81_nlcd_HART\n",
      "82_nlcd_HART\n",
      "90_nlcd_HART\n",
      "95_nlcd_HART\n",
      "19_aspect_HART\n",
      "21_aspect_HART\n",
      "24_aspect_HART\n",
      "27_aspect_HART\n",
      "28_aspect_HART\n",
      "22_aspect_HART\n",
      "23_aspect_HART\n",
      "25_aspect_HART\n",
      "26_aspect_HART\n",
      "31_aspect_HART\n",
      "33_aspect_HART\n",
      "32_aspect_HART\n",
      "34_aspect_HART\n",
      "38_aspect_HART\n",
      "variance_elev_HART\n",
      "skew_elev_HART\n",
      "med_dist_elev_HART\n",
      "t2m_OLEA_imf_0\n",
      "t2m_OLEA_imf_1\n",
      "t2m_OLEA_imf_2\n",
      "t2m_OLEA_imf_3\n",
      "t2m_OLEA_imf_4\n",
      "t2m_OLEA_imf_5\n",
      "t2m_OLEA_imf_6\n",
      "t2m_OLEA_imf_7\n",
      "t2m_OLEA_imf_8\n",
      "sh2_OLEA\n",
      "d2m_OLEA\n",
      "r2_OLEA\n",
      "u10_OLEA\n",
      "v10_OLEA\n",
      "tp_OLEA\n",
      "mslma_OLEA\n",
      "tcc_OLEA\n",
      "asnow_OLEA\n",
      "cape_OLEA\n",
      "dswrf_OLEA\n",
      "dlwrf_OLEA\n",
      "gh_OLEA\n",
      "u_dir_OLEA\n",
      "new_tp_OLEA\n",
      "lat_OLEA\n",
      "lon_OLEA\n",
      "elev_OLEA\n",
      "11_nlcd_OLEA\n",
      "21_nlcd_OLEA\n",
      "22_nlcd_OLEA\n",
      "23_nlcd_OLEA\n",
      "24_nlcd_OLEA\n",
      "31_nlcd_OLEA\n",
      "41_nlcd_OLEA\n",
      "42_nlcd_OLEA\n",
      "43_nlcd_OLEA\n",
      "52_nlcd_OLEA\n",
      "71_nlcd_OLEA\n",
      "81_nlcd_OLEA\n",
      "82_nlcd_OLEA\n",
      "90_nlcd_OLEA\n",
      "95_nlcd_OLEA\n",
      "19_aspect_OLEA\n",
      "21_aspect_OLEA\n",
      "24_aspect_OLEA\n",
      "27_aspect_OLEA\n",
      "28_aspect_OLEA\n",
      "22_aspect_OLEA\n",
      "23_aspect_OLEA\n",
      "25_aspect_OLEA\n",
      "26_aspect_OLEA\n",
      "31_aspect_OLEA\n",
      "33_aspect_OLEA\n",
      "32_aspect_OLEA\n",
      "34_aspect_OLEA\n",
      "38_aspect_OLEA\n",
      "variance_elev_OLEA\n",
      "skew_elev_OLEA\n",
      "med_dist_elev_OLEA\n",
      "t2m_RAND_imf_0\n",
      "t2m_RAND_imf_1\n",
      "t2m_RAND_imf_2\n",
      "t2m_RAND_imf_3\n",
      "t2m_RAND_imf_4\n",
      "t2m_RAND_imf_5\n",
      "t2m_RAND_imf_6\n",
      "t2m_RAND_imf_7\n",
      "t2m_RAND_imf_8\n",
      "t2m_RAND_imf_9\n",
      "sh2_RAND\n",
      "d2m_RAND\n",
      "r2_RAND\n",
      "u10_RAND\n",
      "v10_RAND\n",
      "tp_RAND\n",
      "mslma_RAND\n",
      "tcc_RAND\n",
      "asnow_RAND\n",
      "cape_RAND\n",
      "dswrf_RAND\n",
      "dlwrf_RAND\n",
      "gh_RAND\n",
      "u_dir_RAND\n",
      "new_tp_RAND\n",
      "lat_RAND\n",
      "lon_RAND\n",
      "elev_RAND\n",
      "11_nlcd_RAND\n",
      "21_nlcd_RAND\n",
      "22_nlcd_RAND\n",
      "23_nlcd_RAND\n",
      "24_nlcd_RAND\n",
      "31_nlcd_RAND\n",
      "41_nlcd_RAND\n",
      "42_nlcd_RAND\n",
      "43_nlcd_RAND\n",
      "52_nlcd_RAND\n",
      "71_nlcd_RAND\n",
      "81_nlcd_RAND\n",
      "82_nlcd_RAND\n",
      "90_nlcd_RAND\n",
      "95_nlcd_RAND\n",
      "19_aspect_RAND\n",
      "21_aspect_RAND\n",
      "24_aspect_RAND\n",
      "27_aspect_RAND\n",
      "28_aspect_RAND\n",
      "22_aspect_RAND\n",
      "23_aspect_RAND\n",
      "25_aspect_RAND\n",
      "26_aspect_RAND\n",
      "31_aspect_RAND\n",
      "33_aspect_RAND\n",
      "32_aspect_RAND\n",
      "34_aspect_RAND\n",
      "38_aspect_RAND\n",
      "variance_elev_RAND\n",
      "skew_elev_RAND\n",
      "med_dist_elev_RAND\n",
      "target_error\n",
      "day_of_year_sin\n",
      "day_of_year_cos\n",
      "amo\n",
      "amoc\n",
      "enso4\n",
      "enso_1_2\n",
      "pna\n",
      "enso3\n",
      "ao\n",
      "pdo\n",
      "nao\n",
      "target_error_lead_30\n"
     ]
    }
   ],
   "source": [
    "for k in the_df.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Fraction 0.25003339121143314\n"
     ]
    }
   ],
   "source": [
    "length = len(the_df)\n",
    "\n",
    "test_len = int(length * 0.75)\n",
    "\n",
    "df_train = the_df.iloc[:test_len].copy()\n",
    "df_test = the_df.iloc[test_len:].copy()\n",
    "\n",
    "print(\"Test Set Fraction\", len(df_test) / len(the_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cols_to_carry:\n",
    "    df_train[c] = df[c]\n",
    "    df_test[c] = df[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.fillna(0)\n",
    "df_test = df_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t2m_ADDI_imf_0</th>\n",
       "      <th>t2m_ADDI_imf_1</th>\n",
       "      <th>t2m_ADDI_imf_2</th>\n",
       "      <th>t2m_ADDI_imf_3</th>\n",
       "      <th>t2m_ADDI_imf_4</th>\n",
       "      <th>t2m_ADDI_imf_5</th>\n",
       "      <th>t2m_ADDI_imf_6</th>\n",
       "      <th>t2m_ADDI_imf_7</th>\n",
       "      <th>t2m_ADDI_imf_8</th>\n",
       "      <th>t2m_ADDI_imf_9</th>\n",
       "      <th>...</th>\n",
       "      <th>enso4</th>\n",
       "      <th>enso_1_2</th>\n",
       "      <th>pna</th>\n",
       "      <th>enso3</th>\n",
       "      <th>ao</th>\n",
       "      <th>pdo</th>\n",
       "      <th>nao</th>\n",
       "      <th>target_error_lead_30</th>\n",
       "      <th>valid_time</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16845</th>\n",
       "      <td>0.241526</td>\n",
       "      <td>0.297581</td>\n",
       "      <td>0.460891</td>\n",
       "      <td>2.755017</td>\n",
       "      <td>-1.468827</td>\n",
       "      <td>0.280847</td>\n",
       "      <td>-4.253160</td>\n",
       "      <td>5.165458</td>\n",
       "      <td>-1.203823</td>\n",
       "      <td>1.216701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-2.52</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.466901</td>\n",
       "      <td>2021-11-22 10:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>-0.164721</td>\n",
       "      <td>-0.042090</td>\n",
       "      <td>0.362151</td>\n",
       "      <td>2.474688</td>\n",
       "      <td>-1.453629</td>\n",
       "      <td>0.263343</td>\n",
       "      <td>-4.250228</td>\n",
       "      <td>5.158583</td>\n",
       "      <td>-1.203730</td>\n",
       "      <td>1.216437</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-2.52</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.799416</td>\n",
       "      <td>2021-11-22 11:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>0.105367</td>\n",
       "      <td>-0.486741</td>\n",
       "      <td>0.219456</td>\n",
       "      <td>2.184923</td>\n",
       "      <td>-1.436017</td>\n",
       "      <td>0.245770</td>\n",
       "      <td>-4.247241</td>\n",
       "      <td>5.151696</td>\n",
       "      <td>-1.203636</td>\n",
       "      <td>1.216173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-2.52</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.351758</td>\n",
       "      <td>2021-11-22 12:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16848</th>\n",
       "      <td>-0.017604</td>\n",
       "      <td>-0.715117</td>\n",
       "      <td>0.060210</td>\n",
       "      <td>1.887383</td>\n",
       "      <td>-1.416064</td>\n",
       "      <td>0.228130</td>\n",
       "      <td>-4.244199</td>\n",
       "      <td>5.144799</td>\n",
       "      <td>-1.203542</td>\n",
       "      <td>1.215909</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-2.52</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.158703</td>\n",
       "      <td>2021-11-22 13:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>-0.114607</td>\n",
       "      <td>-0.689329</td>\n",
       "      <td>-0.090533</td>\n",
       "      <td>1.583723</td>\n",
       "      <td>-1.393846</td>\n",
       "      <td>0.210426</td>\n",
       "      <td>-4.241100</td>\n",
       "      <td>5.137889</td>\n",
       "      <td>-1.203447</td>\n",
       "      <td>1.215644</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-2.52</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.263606</td>\n",
       "      <td>2021-11-22 14:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22456</th>\n",
       "      <td>-0.253649</td>\n",
       "      <td>-1.508868</td>\n",
       "      <td>0.229911</td>\n",
       "      <td>8.899499</td>\n",
       "      <td>4.637280</td>\n",
       "      <td>1.112167</td>\n",
       "      <td>-5.254929</td>\n",
       "      <td>-0.400453</td>\n",
       "      <td>0.520442</td>\n",
       "      <td>0.340615</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-2.719</td>\n",
       "      <td>-9.90</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.136727</td>\n",
       "      <td>2022-12-30 13:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22457</th>\n",
       "      <td>-0.029539</td>\n",
       "      <td>-0.930426</td>\n",
       "      <td>0.733629</td>\n",
       "      <td>8.857566</td>\n",
       "      <td>4.741251</td>\n",
       "      <td>1.117889</td>\n",
       "      <td>-5.254474</td>\n",
       "      <td>-0.401975</td>\n",
       "      <td>0.520271</td>\n",
       "      <td>0.340688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-2.719</td>\n",
       "      <td>-9.90</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.119368</td>\n",
       "      <td>2022-12-30 14:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22458</th>\n",
       "      <td>0.110616</td>\n",
       "      <td>-0.024843</td>\n",
       "      <td>1.202153</td>\n",
       "      <td>8.800177</td>\n",
       "      <td>4.844479</td>\n",
       "      <td>1.123339</td>\n",
       "      <td>-5.253991</td>\n",
       "      <td>-0.403489</td>\n",
       "      <td>0.520099</td>\n",
       "      <td>0.340761</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-2.719</td>\n",
       "      <td>-9.90</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.694242</td>\n",
       "      <td>2022-12-30 15:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22459</th>\n",
       "      <td>-0.078151</td>\n",
       "      <td>0.957164</td>\n",
       "      <td>1.602189</td>\n",
       "      <td>8.727438</td>\n",
       "      <td>4.946911</td>\n",
       "      <td>1.128514</td>\n",
       "      <td>-5.253480</td>\n",
       "      <td>-0.404995</td>\n",
       "      <td>0.519927</td>\n",
       "      <td>0.340834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-2.719</td>\n",
       "      <td>-9.90</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.717157</td>\n",
       "      <td>2022-12-30 16:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22460</th>\n",
       "      <td>0.103807</td>\n",
       "      <td>1.708539</td>\n",
       "      <td>1.900441</td>\n",
       "      <td>8.639453</td>\n",
       "      <td>5.048494</td>\n",
       "      <td>1.133411</td>\n",
       "      <td>-5.252941</td>\n",
       "      <td>-0.406491</td>\n",
       "      <td>0.519755</td>\n",
       "      <td>0.340908</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-2.719</td>\n",
       "      <td>-9.90</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.302390</td>\n",
       "      <td>2022-12-30 17:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5616 rows Ã— 554 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       t2m_ADDI_imf_0  t2m_ADDI_imf_1  t2m_ADDI_imf_2  t2m_ADDI_imf_3  \\\n",
       "16845        0.241526        0.297581        0.460891        2.755017   \n",
       "16846       -0.164721       -0.042090        0.362151        2.474688   \n",
       "16847        0.105367       -0.486741        0.219456        2.184923   \n",
       "16848       -0.017604       -0.715117        0.060210        1.887383   \n",
       "16849       -0.114607       -0.689329       -0.090533        1.583723   \n",
       "...               ...             ...             ...             ...   \n",
       "22456       -0.253649       -1.508868        0.229911        8.899499   \n",
       "22457       -0.029539       -0.930426        0.733629        8.857566   \n",
       "22458        0.110616       -0.024843        1.202153        8.800177   \n",
       "22459       -0.078151        0.957164        1.602189        8.727438   \n",
       "22460        0.103807        1.708539        1.900441        8.639453   \n",
       "\n",
       "       t2m_ADDI_imf_4  t2m_ADDI_imf_5  t2m_ADDI_imf_6  t2m_ADDI_imf_7  \\\n",
       "16845       -1.468827        0.280847       -4.253160        5.165458   \n",
       "16846       -1.453629        0.263343       -4.250228        5.158583   \n",
       "16847       -1.436017        0.245770       -4.247241        5.151696   \n",
       "16848       -1.416064        0.228130       -4.244199        5.144799   \n",
       "16849       -1.393846        0.210426       -4.241100        5.137889   \n",
       "...               ...             ...             ...             ...   \n",
       "22456        4.637280        1.112167       -5.254929       -0.400453   \n",
       "22457        4.741251        1.117889       -5.254474       -0.401975   \n",
       "22458        4.844479        1.123339       -5.253991       -0.403489   \n",
       "22459        4.946911        1.128514       -5.253480       -0.404995   \n",
       "22460        5.048494        1.133411       -5.252941       -0.406491   \n",
       "\n",
       "       t2m_ADDI_imf_8  t2m_ADDI_imf_9  ...  enso4  enso_1_2   pna  enso3  \\\n",
       "16845       -1.203823        1.216701  ...  -0.68     -1.12  0.68  -1.03   \n",
       "16846       -1.203730        1.216437  ...  -0.68     -1.12  0.68  -1.03   \n",
       "16847       -1.203636        1.216173  ...  -0.68     -1.12  0.68  -1.03   \n",
       "16848       -1.203542        1.215909  ...  -0.68     -1.12  0.68  -1.03   \n",
       "16849       -1.203447        1.215644  ...  -0.68     -1.12  0.68  -1.03   \n",
       "...               ...             ...  ...    ...       ...   ...    ...   \n",
       "22456        0.520442        0.340615  ...  -0.84     -0.46 -0.96  -0.81   \n",
       "22457        0.520271        0.340688  ...  -0.84     -0.46 -0.96  -0.81   \n",
       "22458        0.520099        0.340761  ...  -0.84     -0.46 -0.96  -0.81   \n",
       "22459        0.519927        0.340834  ...  -0.84     -0.46 -0.96  -0.81   \n",
       "22460        0.519755        0.340908  ...  -0.84     -0.46 -0.96  -0.81   \n",
       "\n",
       "          ao   pdo   nao  target_error_lead_30          valid_time  flag  \n",
       "16845  0.093 -2.52 -0.33              0.466901 2021-11-22 10:00:00  True  \n",
       "16846  0.093 -2.52 -0.33              0.799416 2021-11-22 11:00:00  True  \n",
       "16847  0.093 -2.52 -0.33             -0.351758 2021-11-22 12:00:00  True  \n",
       "16848  0.093 -2.52 -0.33             -0.158703 2021-11-22 13:00:00  True  \n",
       "16849  0.093 -2.52 -0.33             -0.263606 2021-11-22 14:00:00  True  \n",
       "...      ...   ...   ...                   ...                 ...   ...  \n",
       "22456 -2.719 -9.90 -0.22              0.136727 2022-12-30 13:00:00  True  \n",
       "22457 -2.719 -9.90 -0.22              0.119368 2022-12-30 14:00:00  True  \n",
       "22458 -2.719 -9.90 -0.22             -0.694242 2022-12-30 15:00:00  True  \n",
       "22459 -2.719 -9.90 -0.22             -0.717157 2022-12-30 16:00:00  True  \n",
       "22460 -2.719 -9.90 -0.22             -0.302390 2022-12-30 17:00:00  True  \n",
       "\n",
       "[5616 rows x 554 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# data = torch.tensor(df_train.values)\n",
    "\n",
    "\n",
    "# # Perform PCA\n",
    "# U, S, V = torch.pca_lowrank(data)\n",
    "\n",
    "# # Print the results\n",
    "# print(U)\n",
    "# print(S)\n",
    "# print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components=10)\n",
    "# pca.fit(df_train)\n",
    "# print(pca.components_) # Reformat and view results\n",
    "# loadings = pd.DataFrame(pca.components_.T,\n",
    "# columns=['PC%s' % _ for _ in range((pca.components_.shape[0]))],\n",
    "# index=df_train.columns)\n",
    "# print(loadings)\n",
    "\n",
    "# plt.plot(pca.explained_variance_ratio_)\n",
    "# plt.ylabel('Explained Variance')\n",
    "# plt.xlabel('Components')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(pca.components_)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, dataframe, target, features, sequence_length):\n",
    "        self.dataframe = dataframe\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.sequence_length = sequence_length\n",
    "        self.y = torch.tensor(dataframe[target].values).float()\n",
    "        self.X = torch.tensor(dataframe[features].values).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        keep_sample = self.dataframe.iloc[i][\"flag\"]\n",
    "        if i >= self.sequence_length - 1:\n",
    "            i_start = i - self.sequence_length + 1\n",
    "            x = self.X[i_start : (i + 1), :]\n",
    "        else:\n",
    "            padding = self.X[0].repeat(self.sequence_length - i - 1, 1)\n",
    "            x = self.X[0 : (i + 1), :]\n",
    "            x = torch.cat((padding, x), 0)\n",
    "\n",
    "        return x, self.y[i], keep_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class PeepholeLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(PeepholeLSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.W_i = nn.Linear(input_size, hidden_size)\n",
    "        self.W_f = nn.Linear(input_size, hidden_size)\n",
    "        self.W_o = nn.Linear(input_size, hidden_size)\n",
    "        self.W_c = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        self.U_i = nn.Linear(hidden_size, hidden_size)\n",
    "        self.U_f = nn.Linear(hidden_size, hidden_size)\n",
    "        self.U_o = nn.Linear(hidden_size, hidden_size)\n",
    "        self.U_c = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        i = torch.sigmoid(self.W_i(x) + self.U_i(h_prev) + self.W_c(c_prev))\n",
    "        f = torch.sigmoid(self.W_f(x) + self.U_f(h_prev) + self.W_c(c_prev))\n",
    "        c_tilde = torch.tanh(self.W_c(x) + self.U_c(h_prev))\n",
    "        c = f * c_prev + i * c_tilde\n",
    "        o = torch.sigmoid(self.W_o(x) + self.U_o(h_prev) + self.W_c(c))\n",
    "        h = o * torch.tanh(c)\n",
    "        return h, c\n",
    "\n",
    "\n",
    "class ShallowRegressionPeepholeLSTM(nn.Module):\n",
    "    def __init__(self, num_sensors, hidden_units):\n",
    "        super().__init__()\n",
    "        self.num_sensors = num_sensors\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = 3\n",
    "\n",
    "        # Create a list of LSTM cells\n",
    "        self.lstm_cells = nn.ModuleList([PeepholeLSTMCell(num_sensors, hidden_units)])\n",
    "\n",
    "        # # Add additional LSTM layers if needed\n",
    "        # for _ in range(1, self.num_layers):\n",
    "        #     self.lstm_cells.append(PeepholeLSTMCell(hidden_units, hidden_units))\n",
    "\n",
    "        self.linear = nn.Linear(in_features=hidden_units, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        h0 = torch.zeros(batch_size, self.hidden_units).requires_grad_()\n",
    "        c0 = torch.zeros(batch_size, self.hidden_units).requires_grad_()\n",
    "        h, c = h0, c0\n",
    "\n",
    "        # Forward pass through each LSTM cell\n",
    "        for lstm_cell in self.lstm_cells:\n",
    "            h, c = lstm_cell(x, h, c)\n",
    "\n",
    "        out = self.linear(h[0]).flatten()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_elements_from_batch(X, y, s):\n",
    "    cond = np.where(s)\n",
    "    return X[cond], y[cond], s[cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_loader, model, loss_function, optimizer):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
    "        for X, y, s in tepoch:\n",
    "            # X, y, s = remove_elements_from_batch(X, y, s)\n",
    "            output = model(X)\n",
    "            loss = loss_function(output, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    # loss\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Train loss: {avg_loss}\")\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def test_model(data_loader, model, loss_function):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
    "            for X, y, s in tepoch:\n",
    "                # X, y, s = remove_elements_from_batch(X, y, s)\n",
    "                output = model(X)\n",
    "                total_loss += loss_function(output, y).item()\n",
    "\n",
    "    # loss\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Test loss: {avg_loss}\")\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: torch.Size([400, 400, 550])\n",
      "Target shape: torch.Size([400])\n",
      "Untrained test\n",
      "--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14/15 [00:59<00:04,  4.24s/batch]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (400) must match the size of tensor b (16) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 52\u001b[0m\n\u001b[1;32m     48\u001b[0m early_stopper \u001b[38;5;241m=\u001b[39m EarlyStopper(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUntrained test\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m test_model(test_loader, model, loss_function)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ix_epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n",
      "Cell \u001b[0;32mIn[89], line 33\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(data_loader, model, loss_function)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(data_loader, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tepoch:\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m X, y, s \u001b[38;5;129;01min\u001b[39;00m tepoch:\n\u001b[1;32m     32\u001b[0m             \u001b[38;5;66;03m#X, y, s = remove_elements_from_batch(X, y, s)\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m             output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m             total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_function(output, y)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[86], line 53\u001b[0m, in \u001b[0;36mShallowRegressionPeepholeLSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Forward pass through each LSTM cell\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lstm_cell \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm_cells:\n\u001b[0;32m---> 53\u001b[0m     h, c \u001b[38;5;241m=\u001b[39m \u001b[43mlstm_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(h[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[86], line 21\u001b[0m, in \u001b[0;36mPeepholeLSTMCell.forward\u001b[0;34m(self, x, h_prev, c_prev)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, h_prev, c_prev):\n\u001b[0;32m---> 21\u001b[0m     i \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_i\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mU_i\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_prev\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_c(c_prev))\n\u001b[1;32m     22\u001b[0m     f \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_f(x) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU_f(h_prev) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_c(c_prev))\n\u001b[1;32m     23\u001b[0m     c_tilde \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_c(x) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU_c(h_prev))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (400) must match the size of tensor b (16) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(101)\n",
    "batch_size = 400\n",
    "sequence_length = 400\n",
    "learning_rate = 5e-4\n",
    "num_hidden_units = 550\n",
    "\n",
    "experiment = Experiment(\n",
    "    api_key=\"leAiWyR5Ck7tkdiHIT7n6QWNa\",\n",
    "    project_name=\"fh_2_hrrr\",\n",
    "    workspace=\"shmaronshmevans\",\n",
    ")\n",
    "# # Report multiple hyperparameters using a dictionary:\n",
    "# hyper_params = {\n",
    "#     \"num_layers\": num_layers,\n",
    "#     \"learning_rate\": learning_rate,\n",
    "#     \"sequence_length\": sequence_length,\n",
    "#     \"batch_size\": batch_size,\n",
    "#     \"num_hidden_units\": num_hidden_units,\n",
    "#     \"forecast_lead\": forecast_lead,\n",
    "# }\n",
    "\n",
    "batch_size = batch_size\n",
    "sequence_length = sequence_length\n",
    "\n",
    "train_dataset = SequenceDataset(\n",
    "    df_train, target=target, features=new_features, sequence_length=sequence_length\n",
    ")\n",
    "test_dataset = SequenceDataset(\n",
    "    df_test, target=target, features=new_features, sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "\n",
    "X, y, s = next(iter(train_loader))\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "\n",
    "learning_rate = learning_rate\n",
    "num_hidden_units = num_hidden_units\n",
    "\n",
    "model = ShallowRegressionPeepholeLSTM(\n",
    "    num_sensors=len(new_features), hidden_units=num_hidden_units\n",
    ")\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "early_stopper = EarlyStopper(patience=10, min_delta=0)\n",
    "\n",
    "\n",
    "print(\"Untrained test\\n--------\")\n",
    "test_model(test_loader, model, loss_function)\n",
    "print()\n",
    "\n",
    "for ix_epoch in range(3):\n",
    "    print(f\"Epoch {ix_epoch}\\n---------\")\n",
    "    train_loss = train_model(train_loader, model, loss_function, optimizer=optimizer)\n",
    "    val_loss = test_model(test_loader, model, loss_function)\n",
    "    print()\n",
    "    experiment.log_epoch_end(ix_epoch)\n",
    "    # experiment.log_parameters(hyper_params, step = ix_epoch)\n",
    "    if early_stopper.early_stop(val_loss):\n",
    "        break\n",
    "\n",
    "# Seamlessly log your Pytorch model\n",
    "log_model(experiment, model, model_name=\"exp1\")\n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_loader, model):\n",
    "    output = torch.tensor([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, _, s in data_loader:\n",
    "            y_star = model(X)\n",
    "            # print(y_star)\n",
    "            output = torch.cat((output, y_star), 0)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "train_eval_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "ystar_col = \"Model forecast\"\n",
    "df_train[ystar_col] = predict(train_eval_loader, model).numpy()\n",
    "df_test[ystar_col] = predict(test_loader, model).numpy()\n",
    "print(df_test[ystar_col])\n",
    "\n",
    "df_out = pd.concat((df_train, df_test))[[target, ystar_col]]\n",
    "\n",
    "for c in df_out.columns:\n",
    "    vals = df_out[c].values.tolist()\n",
    "    mean = st.mean(vals)\n",
    "    std = st.pstdev(vals)\n",
    "    df_out[c] = df_out[c] * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "plot_template = dict(\n",
    "    layout=go.Layout(\n",
    "        {\"font_size\": 18, \"xaxis_title_font_size\": 24, \"yaxis_title_font_size\": 24}\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig = px.line(df_out, labels=dict(created_at=\"Date\", value=\"Forecast Error\"))\n",
    "fig.add_vline(x=(length * 0.75), line_width=4, line_dash=\"dash\")\n",
    "fig.add_annotation(\n",
    "    xref=\"paper\", x=0.75, yref=\"paper\", y=0.8, text=\"Test set start\", showarrow=False\n",
    ")\n",
    "fig.update_layout(\n",
    "    template=plot_template, legend=dict(orientation=\"h\", y=1.02, title_text=\"\")\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "\n",
    "# # Use the training data for deep explainer => can use fewer instances\n",
    "# explainer = shap.DeepExplainer(model, X_train)\n",
    "# # explain the the testing instances (can use fewer instanaces)\n",
    "# # explaining each prediction requires 2 * background dataset size runs\n",
    "# shap_values = explainer.shap_values(X_test)\n",
    "# # init the JS visualization code\n",
    "# shap.initjs()\n",
    "# shap.force_plot(explainer.expected_value[0], shap_values[0][0], features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn related imports\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# pytorch relates imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# imports from captum library\n",
    "from captum.attr import LayerConductance, LayerActivation, LayerIntegratedGradients\n",
    "from captum.attr import (\n",
    "    IntegratedGradients,\n",
    "    DeepLift,\n",
    "    GradientShap,\n",
    "    NoiseTunnel,\n",
    "    FeatureAblation,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train).float()\n",
    "y_train = torch.tensor(y_train).view(-1, 1).float()\n",
    "\n",
    "X_test = torch.tensor(X_test).float()\n",
    "y_test = torch.tensor(y_test).view(-1, 1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "\n",
    "# # Use the training data for deep explainer => can use fewer instances\n",
    "# explainer = shap.DeepExplainer(model, y_train)\n",
    "# # explain the the testing instances (can use fewer instanaces)\n",
    "# # explaining each prediction requires 2 * background dataset size runs\n",
    "# shap_values = explainer.shap_values(X_test)\n",
    "# # init the JS visualization code\n",
    "# shap.initjs()\n",
    "# shap.force_plot(explainer.expected_value[0], shap_values[0][0], features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "outputs = model(X_test)\n",
    "err = np.sqrt(mean_squared_error(outputs.detach().numpy(), y_test.detach().numpy()))\n",
    "\n",
    "print(\"model err: \", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(model)\n",
    "ig_nt = NoiseTunnel(ig)\n",
    "dl = DeepLift(model)\n",
    "gs = GradientShap(model)\n",
    "fa = FeatureAblation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_nt_attr_test = ig_nt.attribute(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ig_attr_test_norm_sum.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.shape[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_nt_attr_test_norm_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 0\n",
    "e = 20\n",
    "n = 10\n",
    "# prepare attributions for visualization\n",
    "\n",
    "x_axis_data = np.arange(X_test.shape[1])\n",
    "x_axis_data_labels = list(map(lambda idx: new_features[idx], x_axis_data))\n",
    "\n",
    "while e < len(x_axis_data):\n",
    "    ig_nt_attr_test_sum = ig_nt_attr_test.detach().numpy().sum(0)\n",
    "    ig_nt_attr_test_norm_sum = ig_nt_attr_test_sum / np.linalg.norm(\n",
    "        ig_nt_attr_test_sum, ord=1\n",
    "    )\n",
    "\n",
    "    lin_weight = model.linear.weight[0].detach().numpy()\n",
    "    y_axis_lin_weight = lin_weight / np.linalg.norm(lin_weight, ord=1)\n",
    "\n",
    "    width = 0.14\n",
    "    legends = [\"Int Grads w/SmoothGrad\", \"Weights\"]\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    ax = plt.subplot()\n",
    "    ax.set_title(\n",
    "        \"Comparing input feature importances across multiple algorithms and learned weights\"\n",
    "    )\n",
    "    ax.set_ylabel(\"Attributions\")\n",
    "\n",
    "    FONT_SIZE = 16\n",
    "    plt.rc(\"font\", size=FONT_SIZE)  # fontsize of the text sizes\n",
    "    plt.rc(\"axes\", titlesize=FONT_SIZE)  # fontsize of the axes title\n",
    "    plt.rc(\"axes\", labelsize=FONT_SIZE)  # fontsize of the x and y labels\n",
    "    plt.rc(\"legend\", fontsize=FONT_SIZE - 4)  # fontsize of the legend\n",
    "\n",
    "    print(x_axis_data.shape)\n",
    "\n",
    "    ax.bar(\n",
    "        x_axis_data[b:e] + width,\n",
    "        ig_nt_attr_test_norm_sum[b:e, n],\n",
    "        width,\n",
    "        align=\"center\",\n",
    "        alpha=0.7,\n",
    "        color=\"#A90000\",\n",
    "    )\n",
    "    ax.bar(\n",
    "        x_axis_data[b:e] + 5 * width,\n",
    "        y_axis_lin_weight[b:e],\n",
    "        width,\n",
    "        align=\"center\",\n",
    "        alpha=1.0,\n",
    "        color=\"grey\",\n",
    "    )\n",
    "    ax.autoscale_view()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax.set_xticks(x_axis_data[b:e] + 0.5)\n",
    "    ax.set_xticklabels(x_axis_data_labels[b:e], rotation=90)\n",
    "\n",
    "    plt.legend(legends, loc=3)\n",
    "    plt.show()\n",
    "\n",
    "    b += 20\n",
    "    e += 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of feature columns = 50\n",
    "Compute LSTM Feature Importance\n",
    "After we train (or load) each fold model, we will compute LSTM feature importance for all of our features. We do this with a for-loop of size N where N is the number of features we have. \n",
    "\n",
    "For each feature we wish to evaluate, we infer our OOF with that feature column randomly shuffled. If this feature column is important to our LSTM model, then the OOF MAE will become worse for that for-loop step. After our for-loop, we display bars equal to the size of how much MAE worsened without each feature, which is the importance of each feature.\n",
    "\n",
    "Note that computing LSTM feature importance after each fold will add about 1 minute for every 5 features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44818f36aeaf89db1a1d21a2bee6031a28b4e41595a65903b38b9b0c4417365f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
