{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import shapely.geometry\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "import os\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.loadtxt(\n",
    "    \"/home/aevans/nwp_bias/src/machine_learning/frankenstein/data/error_dt/2018/01/01012018_03:00:00.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7443, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hrrr_data(year):\n",
    "    \"\"\"\n",
    "    Reads and concatenates parquet files containing forecast and error data for HRRR weather models\n",
    "    for the years 2018 to 2022.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: of hrrr weather forecast information for each NYSM site.\n",
    "    \"\"\"\n",
    "\n",
    "    savedir = \"/home/aevans/ai2es/processed_data/HRRR/ny/\"\n",
    "\n",
    "    # create empty lists to hold dataframes for each model\n",
    "    hrrr_fcast_and_error = []\n",
    "\n",
    "    # loop over years and read in parquet files for each model\n",
    "    for month in np.arange(1, 13):\n",
    "        str_month = str(month).zfill(2)\n",
    "        if (\n",
    "            os.path.exists(\n",
    "                f\"{savedir}HRRR_{year}_{str_month}_direct_compare_to_nysm_sites_mask_water.parquet\"\n",
    "            )\n",
    "            == True\n",
    "        ):\n",
    "            hrrr_fcast_and_error.append(\n",
    "                pd.read_parquet(\n",
    "                    f\"{savedir}HRRR_{year}_{str_month}_direct_compare_to_nysm_sites_mask_water.parquet\"\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # concatenate dataframes for each model\n",
    "    hrrr_fcast_and_error_df = pd.concat(hrrr_fcast_and_error)\n",
    "    hrrr_fcast_and_error_df = hrrr_fcast_and_error_df.reset_index().dropna()\n",
    "\n",
    "    # return dataframes for each model\n",
    "    return hrrr_fcast_and_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nysm_data(year):\n",
    "    # these parquet files are created by running \"get_resampled_nysm_data.ipynb\"\n",
    "    nysm_path = \"/home/aevans/nwp_bias/data/nysm/\"\n",
    "    nysm_1H = []\n",
    "    df = pd.read_parquet(f\"{nysm_path}nysm_1H_obs_{year}.parquet\")\n",
    "    df.reset_index(inplace=True)\n",
    "    nysm_1H.append(df)\n",
    "    nysm_1H_obs = pd.concat(nysm_1H)\n",
    "    return nysm_1H_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_suffix(df, stations):\n",
    "    cols = [\"valid_time\", \"time\"]\n",
    "    df = df.rename(\n",
    "        columns={c: c + f\"_{stations[0]}\" for c in df.columns if c not in cols}\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def columns_drop(df):\n",
    "    df = df.drop(\n",
    "        columns=[\n",
    "            \"level_0\",\n",
    "            \"index\",\n",
    "            \"lead time\",\n",
    "            \"lsm\",\n",
    "            \"index_nysm\",\n",
    "            \"station_nysm\",\n",
    "        ]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def columns_drop_v2(df):\n",
    "    df = df.drop(\n",
    "        columns=[\n",
    "            \"station\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "            \"t2m\",\n",
    "            \"sh2\",\n",
    "            \"d2m\",\n",
    "            \"r2\",\n",
    "            \"u10\",\n",
    "            \"v10\",\n",
    "            \"tp\",\n",
    "            \"mslma\",\n",
    "            \"orog\",\n",
    "            \"tcc\",\n",
    "            \"asnow\",\n",
    "            \"cape\",\n",
    "            \"dswrf\",\n",
    "            \"dlwrf\",\n",
    "            \"gh\",\n",
    "            \"u_total\",\n",
    "            \"u_dir\",\n",
    "            \"new_tp\",\n",
    "            \"lat\",\n",
    "            \"lon\",\n",
    "            \"elev\",\n",
    "            \"tair\",\n",
    "            \"ta9m\",\n",
    "            \"td\",\n",
    "            \"relh\",\n",
    "            \"srad\",\n",
    "            \"pres\",\n",
    "            \"mslp\",\n",
    "            \"wspd_sonic\",\n",
    "            \"wmax_sonic\",\n",
    "            \"wdir_sonic\",\n",
    "            \"precip_total\",\n",
    "            \"snow_depth\",\n",
    "            \"target_error\",\n",
    "        ]\n",
    "    )\n",
    "    df = df[df.columns.drop(list(df.filter(regex=\"new_tp\")))]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nwp_error(target, station, df):\n",
    "    vars_dict = {\n",
    "        \"t2m\": \"tair\",\n",
    "        \"mslma\": \"pres\",\n",
    "    }\n",
    "    nysm_var = vars_dict.get(target)\n",
    "\n",
    "    df[\"target_error\"] = df[f\"{target}\"] - df[f\"{nysm_var}\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_data(year):\n",
    "    print(\"-- loading data from nysm --\")\n",
    "    # read in hrrr and nysm data\n",
    "    nysm_df = load_nysm_data(year)\n",
    "    nysm_df.reset_index(inplace=True)\n",
    "    nysm_df.dropna(inplace=True)\n",
    "    print(\"-- loading data from hrrr --\")\n",
    "    hrrr_df = read_hrrr_data(year)\n",
    "    hrrr_df.dropna(inplace=True)\n",
    "    nysm_df = nysm_df.rename(columns={\"time_1H\": \"valid_time\"})\n",
    "    mytimes = hrrr_df[\"valid_time\"].tolist()\n",
    "    nysm_df = nysm_df[nysm_df[\"valid_time\"].isin(mytimes)]\n",
    "    stations = nysm_df[\"station\"].unique()\n",
    "    sorted_stations = sorted(stations)\n",
    "\n",
    "    master_df = hrrr_df.merge(nysm_df, on=\"valid_time\", suffixes=(None, \"_nysm\"))\n",
    "    master_df = master_df.drop_duplicates(\n",
    "        subset=[\"valid_time\", \"station\", \"t2m\"], keep=\"first\"\n",
    "    )\n",
    "    print(\"-- finalizing dataframe --\")\n",
    "    df = columns_drop(master_df)\n",
    "    master_df = df[df[\"station\"] == sorted_stations[0]]\n",
    "    master_df = nwp_error(\"t2m\", sorted_stations[0], master_df)\n",
    "    master_df = add_suffix(master_df, sorted_stations)\n",
    "    for station in sorted_stations:\n",
    "        df1 = df[df[\"station\"] == station]\n",
    "        # print(df1.keys())\n",
    "        df2 = nwp_error(\"t2m\", station, df1)\n",
    "        master_df = master_df.merge(\n",
    "            df2, on=\"valid_time\", suffixes=(None, f\"_{station}\")\n",
    "        )\n",
    "\n",
    "    master_df = columns_drop_v2(master_df)\n",
    "    the_df = master_df.copy()\n",
    "    return the_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44818f36aeaf89db1a1d21a2bee6031a28b4e41595a65903b38b9b0c4417365f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
